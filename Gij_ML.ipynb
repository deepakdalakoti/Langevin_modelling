{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to fit XGB and ANN models for Gij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "import os\n",
    "import time\n",
    "import operator\n",
    "import random\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer,QuantileTransformer, RobustScaler\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, GaussianNoise, Conv2D, MaxPooling2D, Flatten, Conv1D,MaxPooling1D\n",
    "from keras.losses import logcosh\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import glob\n",
    "from keras import optimizers\n",
    "from keras import Input, optimizers, layers\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the relevant data\n",
    "def read_data(loc,d,delU):\n",
    "    Gij = np.loadtxt(loc+'/Gij_'+d+'.dat')\n",
    "    Tij = np.loadtxt(loc+'/Tij_'+d+'.dat')\n",
    "    K   = np.loadtxt(loc+'/k-eps_'+d+'.dat')    \n",
    "    meanVelGrad = np.loadtxt(loc+'/mean_vel_grad_'+d+'.dat')\n",
    "    Lij = np.loadtxt(loc+'/lambda_'+d+'.dat')\n",
    "    Reyn = np.loadtxt(loc+'/Reyn_'+d+'.dat')\n",
    "    rho = np.loadtxt(loc+'/rho_'+d+'.dat')\n",
    "    mv = np.loadtxt(loc+'/mean_vel_'+d+'.dat')\n",
    "    \n",
    "    mvgg = np.loadtxt(loc+'/mvgg_'+d+'.dat')\n",
    "    \n",
    "    idel = [3, 6, 7, 12, 15, 16, 21, 24, 25]\n",
    "    \n",
    "    mvgg = np.delete(mvgg,idel,axis=1)\n",
    "    delta = np.ones(Reyn.shape[0])*np.sum(rho*(delU/2-mv[:,0])*(delU/2+mv[:,0]))*7.34e-6/(0.68*delU**2)\n",
    "    x = np.linspace(0,0.0423,576)\n",
    "    x = x-0.0423/2.0\n",
    "    eps = np.copy(K[:,1])\n",
    "    K   = K[:,0]\n",
    "    index = np.where(K>0.05*np.max(K))\n",
    "    t_time = np.zeros(576)\n",
    "    t_time[:] = int(d)*3.38e-7\n",
    "    \n",
    "    loend = index[0][0]\n",
    "    hiend = index[0][-1]\n",
    "\n",
    "    return Gij, Tij, meanVelGrad, eps, K, Lij, Reyn, delta,x,t_time,mvgg\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forms the input features as described in the paper\n",
    "def get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time):\n",
    "        # inputs\n",
    "        basis_vect = np.zeros((b.shape[0],3,3,24))\n",
    "        C = np.transpose(meanVelGrad,(0,2,1))\n",
    "\n",
    "        basis_vect[:,:,:,0] = b\n",
    "        basis_vect[:,:,:,1] = meanVelGrad\n",
    "        basis_vect[:,:,:,2] = C\n",
    "        basis_vect[:,:,:,3] = Lij\n",
    "        \n",
    "        basis_vect[:,:,:,4] = np.matmul(meanVelGrad,Lij)\n",
    "        basis_vect[:,:,:,5] = np.matmul(Lij,Lij)\n",
    "        \n",
    "        basis_vect[:,:,:,6] = np.matmul(Lij,meanVelGrad)\n",
    "        \n",
    "        basis_vect[:,:,:,7] = np.matmul(C,Lij)\n",
    "        basis_vect[:,:,:,8] = np.matmul(Lij,C)\n",
    "        \n",
    "        basis_vect[:,:,:,9] = np.matmul(C,b)\n",
    "        basis_vect[:,:,:,10] = np.matmul(b,C)\n",
    "        basis_vect[:,:,:,11] = np.matmul(b,Lij)\n",
    "        \n",
    "        \n",
    "        \n",
    "        basis_vect[:,:,:,12] = np.matmul(meanVelGrad,b)\n",
    "        basis_vect[:,:,:,13] = np.matmul(b,meanVelGrad)\n",
    "        \n",
    "                \n",
    "        basis_vect[:,:,:,14] = np.trace(np.matmul(b,b),axis1=1,axis2=2)[:,None,None]\n",
    "        \n",
    "        basis_vect[:,:,:,15] = np.trace(C,axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,16] = np.trace(np.matmul(C,C),axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,17] = np.trace(Lij,axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,18] = np.trace(np.matmul(Lij,Lij),axis1=1,axis2=2)[:,None,None]\n",
    "        \n",
    "        basis_vect[:,:,:,19] = np.trace(np.matmul(meanVelGrad,b),axis1=1,axis2=2)[:,None,None]\n",
    "    \n",
    "        basis_vect[:,:,:,20] = np.trace(np.matmul(b,Lij),axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,21] = np.trace(np.matmul(meanVelGrad,Lij),axis1=1,axis2=2)[:,None,None]\n",
    "        \n",
    "        basis_vect[:,:,:,22] = eps[:,None,None]\n",
    "        basis_vect[:,:,:,23] = K[:,None,None]\n",
    "        \n",
    "        \n",
    "        return basis_vect       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data for a single time instant\n",
    "def get_training_data_time(dir_loc,time,normalise=False,normalise_const=True,delU=100):\n",
    "\n",
    "    files = sorted(glob.glob(dir_loc+'accu*.dat'))\n",
    "    indexes = [F[-7:-4] for F in files]        \n",
    "    loindices = np.zeros(len(indexes)+1)\n",
    "    Gij, Tij , meanVelGrad , eps, K, Lij, Reyn, delta, x, t_time,mvgg = read_data(dir_loc,indexes[time],delU)\n",
    "    loindices[1] = K.shape[0]\n",
    "    \n",
    "    b = np.copy(Tij)\n",
    "    b[:,0] = b[:,0]-2.0*K/3.0\n",
    "    b[:,4] = b[:,4]-2.0*K/3.0\n",
    "    b[:,8] = b[:,8]-2.0*K/3.0\n",
    "    Gij = np.reshape(Gij,(Gij.shape[0],3,3))\n",
    "    Tij = np.reshape(Tij,(Tij.shape[0],3,3))\n",
    "    meanVelGrad = np.reshape(meanVelGrad,(meanVelGrad.shape[0],3,3))\n",
    "    b = np.reshape(b,(b.shape[0],3,3))\n",
    "    Lij = np.reshape(Lij,(Lij.shape[0],3,3))\n",
    "\n",
    "    Sij = np.zeros((b.shape[0],3,3))\n",
    "    omega = np.zeros((b.shape[0],3,3))\n",
    "    \n",
    "    for i in range(Sij.shape[0]):\n",
    "        Sij[i,:,:] = 0.5*(meanVelGrad[i,:,:]+np.transpose(meanVelGrad[i,:,:]))\n",
    "        omega[i,:,:] = 0.5*(meanVelGrad[i,:,:]-np.transpose(meanVelGrad[i,:,:]))\n",
    "        \n",
    "    b = b/(2.0*K[:,None,None])\n",
    "    if(normalise):    \n",
    "        Gij = Gij*K[:,None,None]/eps[:,None,None]\n",
    "        Tij = Tij/K[:,None,None]\n",
    "        meanVelGrad = meanVelGrad*K[:,None,None]/eps[:,None,None]\n",
    "        Sij = Sij*K[:,None,None]/eps[:,None,None]\n",
    "        omega = omega*K[:,None,None]/eps[:,None,None]\n",
    "        Lij = Lij*K[:,None,None]\n",
    "    \n",
    "    if(normalise_const):\n",
    "        \n",
    "        Gij = Gij*delta[:,None,None]/delU\n",
    "        #Gij = Gij*delta[:,None,None]/delU**3        \n",
    "        Tij = Tij/delU**2\n",
    "        meanVelGrad = meanVelGrad*delta[:,None,None]/delU\n",
    "        Sij = Sij*delta[:,None,None]/delU\n",
    "        omega = omega*delta[:,None,None]/delU\n",
    "        eps = eps*delta/delU**3\n",
    "        K = K/delU**2\n",
    "        Lij = Lij*delU**2\n",
    "        t_time = t_time*delU/delta\n",
    "\n",
    "    basis_vect = get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time)\n",
    "    basis_vect = np.moveaxis(basis_vect,0,-2)\n",
    "    Gij = np.moveaxis(Gij,0,-1)\n",
    "    Tij = np.moveaxis(Tij,0,-1)\n",
    "    Lij = np.moveaxis(Lij,0,-1)\n",
    "    b = np.moveaxis(b,0,-1)\n",
    "    meanVelGrad = np.moveaxis(meanVelGrad,0,-1)\n",
    "    Sij = np.moveaxis(Sij,0,-1)\n",
    "    omega = np.moveaxis(omega,0,-1)\n",
    "        \n",
    "    return Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K, basis_vect, loindices.astype(int), delta, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data for a range of time instants determined by the input parameters\n",
    "# Consider data directory consists of files numbered from 1 to 100\n",
    "# ist = index of first file to read\n",
    "# nt = how many files to read\n",
    "# stp = step size, i.e. next file will be ist+stp\n",
    "def get_data(direc,ist,nt,stp, delU,nfs,i1,j1):\n",
    "            Gij, _, _, _, _, _, Lij, _, _, basis_vect, _, _, _ = get_training_data_time(direc,ist,False,False,delU)\n",
    "            idxs = np.zeros(math.ceil((nt)/stp)+1)\n",
    "            idxs[0]=0\n",
    "            X = np.copy(basis_vect[i1,j1,:,0:nfs])\n",
    "            Y = np.copy(Gij[i1,j1,:])\n",
    "            j=1\n",
    "            for i in range(ist+stp,ist+nt,stp):\n",
    "                idxs[j] = idxs[j-1]+Gij.shape[2]\n",
    "                Gij, _, _, _, _, _, Lij, _, _, basis_vect, _, _, _ = get_training_data_time(direc,i,False,False,delU)\n",
    "                X = np.append(X,basis_vect[i1,j1,:,0:nfs],axis=0)\n",
    "                Y = np.append(Y,Gij[i1,j1,:],axis=0)\n",
    "                j=j+1\n",
    "            idxs[j] = X.shape[0]    \n",
    "            \n",
    "            return X,Y,idxs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns train, test and validation data for case S1, for a component i1, j1\n",
    "def get_train_test_val_S1_data(i1,j1,scale='std'):\n",
    "    \n",
    "    # Divide data into train, test and validation dataset\n",
    "    nfs=24\n",
    "    npts=576\n",
    "    np.random.seed(10)\n",
    "    # Randomly divide training dataset into train and validation\n",
    "    nT = [i for i in range(0,40)]\n",
    "    np.random.shuffle(nT)\n",
    "\n",
    "    \n",
    "    X, Y, _ = get_data('./data/CaseF_scaled/',0,80,2,100,nfs,i1,j1)\n",
    "\n",
    "    \n",
    "    npts=576\n",
    "    X_train = np.zeros((npts*30,nfs))\n",
    "    Y_train = np.zeros((npts*30,1))\n",
    "\n",
    "    X_val = np.zeros((npts*10,nfs))\n",
    "    Y_val = np.zeros((npts*10,1))\n",
    "\n",
    "    for i in range(0,30):\n",
    "        X_train[i*npts:(i+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_train[i*npts:(i+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "    j=0\n",
    "    for i in range(30,40):\n",
    "        X_val[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_val[j*npts:(j+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "        j=j+1\n",
    "   \n",
    "    Y_un = np.copy(Y_train)\n",
    "\n",
    "    X_test, Y_test, _ = get_data('./data/CaseF_scaled/',80,20,2,100,nfs,i1,j1)\n",
    "\n",
    "    \n",
    "\n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,scale)\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns train, test and validation data for case S2, for a component i1, j1\n",
    "def get_train_test_val_S2_data(i1,j1,scale='std'):\n",
    "    nfs=24\n",
    "    \n",
    "    \n",
    "    \n",
    "    npts=576\n",
    "    np.random.seed(10)\n",
    "    nT = [i for i in range(0,100)]\n",
    "    np.random.shuffle(nT)\n",
    "\n",
    "    X, Y, _ = get_data('./data/CaseF_scaled/',0,100,2,100,nfs,i1,j1)\n",
    "    X1, Y1, _ = get_data('./data/CaseC_scaled/',50,150,3,100,nfs,i1,j1)\n",
    "    \n",
    "    X = np.append(X,X1,axis=0)\n",
    "    Y = np.append(Y,Y1,axis=0)\n",
    "    \n",
    "    X_train = np.zeros((npts*80,nfs))\n",
    "    Y_train = np.zeros((npts*80,1))\n",
    "\n",
    "    X_val = np.zeros((npts*20,nfs))\n",
    "    Y_val = np.zeros((npts*20,1))\n",
    "    \n",
    "    for i in range(0,80):\n",
    "        X_train[i*npts:(i+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_train[i*npts:(i+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "    j=0\n",
    "    for i in range(80,100):\n",
    "        X_val[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_val[j*npts:(j+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "        j=j+1\n",
    "        \n",
    "    minY = np.min(Y_train)\n",
    "    maxY = np.max(Y_train)\n",
    "    stdY = np.std(Y_train)\n",
    "    meanY = np.mean(Y_train)\n",
    "    Y_un = np.copy(Y_train)\n",
    "\n",
    "    X_test, Y_test, _ = get_data('./data/50_new_scaled/',15,80,5,150,nfs,i1,j1)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,scale)\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un = get_train_test_val_S2_data(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various scaling strategies, usually std and minmax give the best results\n",
    "def scale_data(X_train,X_test, X_val, Y_train, Y_test, Y_val, which):\n",
    "    \n",
    "    if(which == 'std'):\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_val = sc.transform(X_val)\n",
    "        Y_train = sc.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = sc.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = sc.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'mean'):\n",
    "        meanX   = np.mean(X_train,axis=0)\n",
    "        stdX    = np.std(X_train,axis=0)\n",
    "    \n",
    "        meanY   = np.mean(Y_train)\n",
    "        stdY    = np.std(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train)/meanY\n",
    "        Y_test = (Y_test)/meanY\n",
    "        Y_val   = (Y_val)/meanY\n",
    "        \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/meanX[i]\n",
    "            X_test[:,i] = (X_test[:,i])/meanX[i]\n",
    "            X_val[:,i] = (X_val[:,i])/meanX[i]\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    \n",
    "    if(which=='minmax'):\n",
    "        minX   = np.min(X_train,axis=(0))\n",
    "        maxX    = np.max(X_train,axis=(0))\n",
    "    \n",
    "        minY   = np.min(Y_train)\n",
    "        maxY    = np.max(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train-minY)/(maxY-minY)\n",
    "        Y_test = (Y_test-minY)/(maxY-minY)\n",
    "        Y_val   = (Y_val-minY)/(maxY-minY)\n",
    "        #Y_train = (Y_train)/(maxY-minY)\n",
    "        #Y_test = (Y_test)/(maxY-minY)\n",
    "        #Y_val   = (Y_val)/(maxY-minY)\n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            X_test[:,i] = (X_test[:,i]-minX[i])/(maxX[i]-minX[i])            \n",
    "            X_val[:,i] = (X_val[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train[:,None], Y_test[:,None], Y_val[:,None]\n",
    "    \n",
    "    if(which=='max'):\n",
    "        maxX    = np.max(np.abs(X_train),axis=(0))\n",
    "    \n",
    "        maxY    = np.max(np.abs(Y_train))\n",
    "    \n",
    "        Y_train = (Y_train)/(maxY)\n",
    "        Y_test = (Y_test)/(maxY)\n",
    "        Y_val   = (Y_val)/(maxY)\n",
    "        \n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/(maxX[i])\n",
    "            X_test[:,i] = (X_test[:,i])/(maxX[i])            \n",
    "            X_val[:,i] = (X_val[:,i])/(maxX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'yeo'):\n",
    "            pt = PowerTransformer(standardize=True)\n",
    "            X_train = pt.fit_transform(X_train)            \n",
    "            X_test  = pt.transform(X_test)\n",
    "            X_val   = pt.transform(X_val)\n",
    "            Y_train  = pt.fit_transform(Y_train.reshape(-1,1))            \n",
    "            Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "            Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "            print(pt.lambdas_)\n",
    "            return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'quant'):\n",
    "                pt = QuantileTransformer(output_distribution='normal')\n",
    "                X_train = pt.fit_transform(X_train)\n",
    "                X_test  = pt.transform(X_test)\n",
    "                X_val   = pt.transform(X_val)\n",
    "                Y_train = pt.fit_transform(Y_train.reshape(-1,1))\n",
    "                Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "                Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "                return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='log'):\n",
    "               X_train = do_log(X_train)    \n",
    "               X_test = do_log(X_test)    \n",
    "               X_val = do_log(X_val)\n",
    "               Y_train = do_log2(Y_train)\n",
    "               Y_test = do_log2(Y_test)\n",
    "               Y_val = do_log2(Y_val)\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='exp'):\n",
    "               X_train = X_train**0.3    \n",
    "               X_test = X_test**0.3    \n",
    "               X_val = X_val**0.3\n",
    "               Y_train = Y_train**0.3\n",
    "               Y_test = Y_test**0.3\n",
    "               Y_val = Y_val**0.3\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        X_train = RS.fit_transform(X_train)\n",
    "        X_test = RS.transform(X_test)\n",
    "        X_val = RS.transform(X_val)\n",
    "        Y_train = RS.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = RS.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = RS.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scaling\n",
    "def do_inverse_scaling(Y_sc, Y_un, which):\n",
    "    if(which=='std'):\n",
    "        meanY = np.mean(Y_un)\n",
    "        stdY = np.std(Y_un)\n",
    "        return Y_sc*stdY + meanY\n",
    "    if(which=='minmax'):\n",
    "        minY = np.min(Y_un)\n",
    "        maxY = np.max(Y_un)\n",
    "        return Y_sc*(maxY-minY)+minY\n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        RS.fit(Y_un.reshape(-1,1))\n",
    "        return RS.inverse_transform(Y_sc.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template XGB model, input takes the number of estimators\n",
    "# See XGB reference for details\n",
    "def get_model_XGB(nest):\n",
    "    model = xgb.XGBRegressor(versbosity=0,booster='gbtree',objective='reg:squarederror',max_depth=3, \\\n",
    "                               learning_rate=0.1,n_estimators=nest,n_jobs=8,importance_type='gain')\n",
    "    return model\n",
    "        \n",
    "               \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns mean squared error in the predictions of model\n",
    "def get_score(model, X, Y, Y_un, which):\n",
    "    pred = model.predict(X)\n",
    "    pred = do_inverse_scaling(pred,Y_un,which)\n",
    "    Y    = do_inverse_scaling(Y,Y_un,which)\n",
    "    npts=576\n",
    "    sc = np.zeros(int(Y.shape[0]/npts))\n",
    "    for i in range(0,sc.shape[0]):\n",
    "        sc[i]=np.sqrt(mean_squared_error(Y[i*npts:(i+1)*npts],pred[i*npts:(i+1)*npts])/np.mean(Y[i*npts:(i+1)*npts]**2))\n",
    "        #sc[i]=r2_score(Y[i*576:(i+1)*576],pred[i*576:(i+1)*576])\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will fit an XGB model for each component of Gij and save the trained model\n",
    "reg = 500\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(i,j)\n",
    "        X_train, X_test, X_val,Y_train,Y_test, Y_val, Y_un = get_train_test_val_S2_data(i,j,'std')\n",
    "\n",
    "        model = get_model_XGB(reg)\n",
    "        model.fit(X_train,Y_train,eval_set=[(X_val,Y_val)],early_stopping_rounds=40,verbose=False)\n",
    "    \n",
    "        model.save_model('models/Gij_{}_{}_S2_XGB.model'.format(i,j))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template of ANN, takes as input \n",
    "# 1) reg : L2 regularisation weight\n",
    "# 2) dimi: input dimensions\n",
    "def get_model(reg,dimi):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8,input_dim=dimi,use_bias=True,kernel_regularizer=regularizers.l2(reg)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.01))\n",
    "        model.add(Dense(6, use_bias=True,kernel_regularizer=regularizers.l2(reg)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.01))\n",
    "        model.add(Dense(4,use_bias=True,kernel_regularizer=regularizers.l2(reg)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.01))\n",
    "       \n",
    "        opt = optimizers.Adam(learning_rate=0.001)\n",
    "        model.add(Dense(1,activation='linear'))\n",
    "        model.compile(optimizer=opt,loss='mean_squared_error')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell will train ANN for various values of regularisation weight for each component,\n",
    "# the model which exhibits smallest error in the validation data will be saved and used later for predictions\n",
    "\n",
    "reg = [0,1e-5, 5e-5, 1e-4, 5e-4,1e-3,5e-3]\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20,restore_best_weights=True)\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        models=[]\n",
    "        X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un = get_train_test_val_S2_data(i,j,'std')\n",
    "        \n",
    "        scs = np.zeros((int(X_val.shape[0]/576),len(reg)))\n",
    "        sctr = np.zeros((int(X_train.shape[0]/576),len(reg)))\n",
    "        sct = np.zeros((int(X_test.shape[0]/576),len(reg)))\n",
    "        for ik, k  in enumerate(reg):\n",
    "            print(i,j)\n",
    "            \n",
    "            model = get_model(k,24)\n",
    "            models.append(model)\n",
    "            h=model.fit(X_train,Y_train,epochs=200,batch_size=512,validation_data=(X_val,Y_val),callbacks=[es],shuffle=True)\n",
    "    \n",
    "            scs[:,ik] = get_score(model, X_val, Y_val, Y_un, 'std')\n",
    "            sct[:,ik] = get_score(model, X_test, Y_test, Y_un, 'std')\n",
    "            sctr[:,ik] = get_score(model, X_train, Y_train, Y_un, 'std')\n",
    "        idx = np.argmin(np.mean(scs,axis=0))\n",
    "        print(idx)\n",
    "        models[idx].save('./models/Gij_{}_{}_S2_ANN.h5'.format(i,j))\n",
    "    #scv2[:,i] = get_score(model, X_val2, Y_val2, Y_un, 'std')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will return Gij for DNS and predictions from ANN and XGB, change the input data to get results for case S1 and S2\n",
    "def get_Gij_predictions(case='S1', scale='std'):\n",
    "    \n",
    "    nfs = 24\n",
    "    DNS = np.zeros((576*16,3,3))\n",
    "    PRED = np.zeros((576*16,3,3))\n",
    "    PRED_ANN = np.zeros((576*16,3,3))\n",
    "    \n",
    "    for i1 in range(0,3):\n",
    "        for j1 in range(0,3):\n",
    "            print(i1,j1)\n",
    "           \n",
    "            if(case=='S1'):\n",
    "                X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un = get_train_test_val_S1_data(i1,j1,scale)\n",
    "            else:\n",
    "                X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un = get_train_test_val_S2_data(i1,j1,scale)\n",
    "            \n",
    "\n",
    "            #print(Y_test.shape)\n",
    "            DNS[:,i1,j1] = Y_test[:,0]           \n",
    "            model = get_model_XGB(500)\n",
    "            model.load_model('models/Gij_{}_{}_{}_XGB.model'.format(i1,j1,case))\n",
    "            model_ANN  = tf.keras.models.load_model('models/Gij_{}_{}_{}_ANN.h5'.format(i1,j1,case))\n",
    "            PRED[:,i1,j1] = model.predict(X_test)\n",
    "            PRED[:,i1,j1] = do_inverse_scaling(PRED[:,i1,j1],Y_un,scale)\n",
    "            \n",
    "            PRED_ANN[:,i1,j1] = model_ANN.predict(X_test)[:,0]\n",
    "            PRED_ANN[:,i1,j1] = do_inverse_scaling(PRED_ANN[:,i1,j1],Y_un,scale)\n",
    "            \n",
    "            \n",
    "            DNS[:,i1,j1] = do_inverse_scaling(DNS[:,i1,j1],Y_un,scale)\n",
    "   \n",
    "    return PRED, PRED_ANN, DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_XGB, PRED, DNS = get_Gij_predictions('S2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Figure 3 and 4\n",
    "    \n",
    "    plt.figure(figsize=(14,10))\n",
    "    k=8\n",
    "    x = np.linspace(0,0.423e-2,576)\n",
    "    x=x-0.423e-2/2\n",
    "    x=x*100\n",
    "    for i in range(0,3):\n",
    "      for j in range(0,3):\n",
    "        plt.subplot(3,3,i*3+j+1) \n",
    "        \n",
    "        plt.plot(x,(DNS[k*576:(k+1)*576,i,j]-min(DNS[k*576:(k+1)*576,i,j]))/(max((DNS[k*576:(k+1)*576,i,j]))-min(DNS[k*576:(k+1)*576,i,j])),'--x',linewidth=2,markevery=12,markeredgewidth=1,markersize=8)\n",
    "        plt.plot(x,(PRED[k*576:(k+1)*576,i,j]-min(DNS[k*576:(k+1)*576,i,j]))/(max((DNS[k*576:(k+1)*576,i,j]))-min(DNS[k*576:(k+1)*576,i,j])),linewidth=2)\n",
    "        plt.plot(x,(PRED_XGB[k*576:(k+1)*576,i,j]-min(DNS[k*576:(k+1)*576,i,j]))/(max((DNS[k*576:(k+1)*576,i,j]))-min(DNS[k*576:(k+1)*576,i,j])),'.',linewidth=2)\n",
    "\n",
    "        \n",
    "        plt.locator_params(axis='y', nbins=3)\n",
    "        plt.locator_params(axis='x', nbins=3)\n",
    "        if(i==0 and j==0):\n",
    "            plt.legend(('DNS','ANN','XGB'))\n",
    "        #if(i==1 and j==1):\n",
    "            #plt.ylim((\\))\n",
    "            #plt.yticks([-0.5, 0, 0.5])\n",
    "        #plt.ylim((-0.1,1.1))\n",
    "        plt.subplots_adjust(wspace=0.05)\n",
    "        plt.subplots_adjust(hspace=0.05)\n",
    "        plt.xlabel('$Y (cm)$')\n",
    "\n",
    "        if(i<2):\n",
    "        #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            #plt.gca().axes.get_xaxis().set_visible(False)\n",
    "            plt.xticks([-0.2,0.0,0.2],\"\")\n",
    "            plt.xlabel(\"\")\n",
    "        if(j>0):\n",
    "            #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            plt.yticks([0,0.5,1],\"\")\n",
    "        plt.grid(alpha=0.5)\n",
    "        #x = np.linspace(min(Gij[i,j,:]*eps/K),max(Gij[i,j,:]*eps/K),10)        \n",
    "        ax=plt.gca()\n",
    "        plt.text(0.1,0.9,str(i+1)+','+str(j+1),transform=ax.transAxes,bbox=dict(facecolor='white',alpha=0.5),size=15)\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + \n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            item.set_fontsize(15)\n",
    "        #plt.plot(x,x,'k--')\n",
    "    #plt.savefig('Gij-ANN-XGB-S2.png',dpi=300,bbox_inches = \"tight\")     \n",
    "    #plt.close()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error values for figure 5 and 8, give predictions for a case, will return error\n",
    "def get_error(pred, DNS):\n",
    "    errs = np.zeros(int(pred.shape[0]/576))\n",
    "    for i in range(errs.shape[0]):\n",
    "        errs[i] = np.sqrt(np.sum((DNS[i*576:(i+1)*576,:,:]-pred[i*576:(i+1)*576,:,:])**2))/np.sqrt(np.sum((DNS[i*576:(i+1)*576,:,:])**2))\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EANNS1 = get_error(PRED, DNS)\n",
    "EXGBS1 = get_error(PRED_XGB, DNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Figure 5 and 8\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(EANNS1[0:10],'-x',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "#plt.plot(EXGBS1[0:10],'-x',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "#plt.plot(EANNS2[0:10],'-o',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "#plt.plot(EXGBS2[0:10],'-o',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "\n",
    "#plt.ylim(0,0.4)\n",
    "plt.ylabel('$\\epsilon_T$')\n",
    "plt.xlabel('Sample')\n",
    "plt.grid(alpha=0.2)\n",
    "ax=plt.gca()\n",
    "plt.yticks([0, 0.10,0.20])\n",
    "#plt.legend(('$\\epsilon_{3,1}$','$\\epsilon_{3,2}$','$\\epsilon_{3,3}$'),prop={'size': 18})\n",
    "plt.legend(('$\\epsilon$-ANN-$\\mathcal{S}$1','$\\epsilon$-XGB-$\\mathcal{S}$1','$\\epsilon$-ANN-$\\mathcal{S}$2','$\\epsilon$-XGB-$\\mathcal{S}$2'),prop={'size': 16})\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + \n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(20)\n",
    "#plt.savefig('eps-S1.png',dpi=300,bbox_inches = \"tight\")     \n",
    "    #plt.close()\n",
    "#plt.plot(MERRS[:,2,2]*100,'-x')\n",
    "#plt.plot(m*100,'-x')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data needed to obtain Reynolds stresses and Gij for various models below\n",
    "def get_data_RSS(direc,ist,nt,stp, delU):\n",
    "            _, Tij, meanVelGrad, b, Sij, _, Lij, eps, K, _, _, _, _ = get_training_data_time(direc,ist,False,False,delU)\n",
    "            for i in range(ist+stp,ist+nt,stp):\n",
    "                _, Tij1, meanVelGrad1, b1, Sij1, _, Lij1, eps1, K1, _, _, _, _ = get_training_data_time(direc,i,False,False,delU)\n",
    "                Tij = np.append(Tij, Tij1, axis=2)\n",
    "                b = np.append(b, b1, axis=2)                \n",
    "                meanVelGrad = np.append(meanVelGrad,meanVelGrad1,axis=2)\n",
    "                Sij = np.append(Sij,Sij1,axis=2)\n",
    "                Lij = np.append(Lij,Lij1,axis=2)\n",
    "                eps = np.append(eps,eps1,axis=0)\n",
    "                K = np.append(K,K1,axis=0)\n",
    "            \n",
    "                \n",
    "            return Tij, b, meanVelGrad, Sij, Lij, eps, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtains Reynolds stress closure implied by the Gij values\n",
    "# Reynolds stress closure means the values of unclosed terms in the Reynolds stress transport equation\n",
    "def get_RSM(Gij,Tij):\n",
    "    RSM = np.zeros((Gij.shape[0],3,3))\n",
    "   \n",
    "    for i in range(0,3):\n",
    "        for j in range(0,3):\n",
    "            for k in range(0,3):\n",
    "                RSM[:,i,j]=RSM[:,i,j]+Gij[:,i,k]*Tij[:,k,j]+Gij[:,j,k]*Tij[:,k,i]\n",
    "    return RSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gij from LIPM model\n",
    "def LIPM_model(C0,CIPM,alpha2,alpha3,beta1,beta2,beta3,gama5,gama6,b,Tij,meanVelGrad,eps,K,lambdaij,Sij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "    for i in range(0,K.shape[0]):        \n",
    "        #P = - 0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) + np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))\n",
    "        #To be used when normalised by eps/K \n",
    "        P1 = b[:,:,i]*Sij[:,:,i]\n",
    "        P = -2.0*P1.sum()*K[i]\n",
    "        B3 = np.matmul(np.matmul(b[:,:,i],b[:,:,i]),b[:,:,i])\n",
    "        \n",
    "        alpha1 = -(0.5+3.0/4*C0)+3.0*alpha2*np.trace(B3)+0.5*CIPM*P/eps[i] #P is non dim so no omega here\n",
    "        \n",
    "        pred[:,:,i] = (alpha1*np.eye(3,3)+alpha2*b[:,:,i] + alpha3*np.matmul(b[:,:,i],b[:,:,i]))*eps[i]/K[i] + beta1*np.eye(3,3)*np.trace(meanVelGrad[:,:,i]) + \\\n",
    "        beta2*meanVelGrad[:,:,i] + beta3*np.transpose(meanVelGrad[:,:,i]) + gama5*np.matmul(b[:,:,i],meanVelGrad[:,:,i]) + \\\n",
    "        gama6*np.matmul(b[:,:,i],np.transpose(meanVelGrad[:,:,i]))\n",
    "     \n",
    "        pred[:,:,i] = pred[:,:,i]+0.5*C0*eps[i]*lambdaij[:,:,i]\n",
    "       \n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSSG Model\n",
    "def LSSG_model(C0,C2SSG,C3SSG,C3SSGp,C3starSSG,C5SSG,b,Tij,meanVelGrad,eps,K,lambdaij,Sij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "    # To be used when normalised with delta and delU\n",
    "    for i in range(0,K.shape[0]):        \n",
    "        P = - 0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) + np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))\n",
    "        B3 = np.matmul(np.matmul(b[:,:,i],b[:,:,i]),b[:,:,i])\n",
    "        alpha2 = 4.0-1.7*P/eps[i]\n",
    "        alpha1 = -(0.5+3.0/4*C0)-1.0/4*C2SSG*np.trace(np.matmul(b[:,:,i],b[:,:,i])) + \\\n",
    "        (3.0*alpha2-3.0/4*C2SSG)*np.trace(B3) + 3.0/8*(C3SSG-C3starSSG*np.sqrt(np.trace(np.matmul(b[:,:,i],b[:,:,i]))))*P/eps[i] \n",
    "        alpha3 = 3.0/4*C2SSG-3.0*alpha2\n",
    "        beta1 = -0.2\n",
    "        beta2 = 3.0/8*(C3SSG-C3SSGp*np.sqrt(np.trace(np.matmul(b[:,:,i],b[:,:,i]))))+0.5\n",
    "        beta3 = 3.0/8*(C3SSG-C3SSGp*np.sqrt(np.trace(np.matmul(b[:,:,i],b[:,:,i]))))-0.5\n",
    "        gama5 = 3.0/2-3.0/4*C5SSG\n",
    "        gama6 = -3.0/2+3.0/4*C5SSG\n",
    "        \n",
    "        pred[:,:,i] = (alpha1*np.eye(3,3)+alpha2*b[:,:,i] + alpha3*np.matmul(b[:,:,i],b[:,:,i]))*eps[i]/K[i] + beta1*np.eye(3,3)*np.trace(meanVelGrad[:,:,i]) + \\\n",
    "        beta2*meanVelGrad[:,:,i] + beta3*np.transpose(meanVelGrad[:,:,i]) + gama5*np.matmul(b[:,:,i],meanVelGrad[:,:,i]) + \\\n",
    "        gama6*np.matmul(b[:,:,i],np.transpose(meanVelGrad[:,:,i]))\n",
    "        \n",
    "        \n",
    "        pred[:,:,i] = pred[:,:,i]+0.5*C0*eps[i]*lambdaij[:,:,i]\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLM model\n",
    "def get_SLM(C0,eps,K,Lij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "\n",
    "    for i in range(0,K.shape[0]):\n",
    "        pred[:,:,i] = -(0.5+3.0/4*C0)*np.eye(3,3)*eps[i]/K[i] + 0.5*C0*eps[i]*Lij[:,:,i]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Reynolds stress closure for various models\n",
    "\n",
    "Tij, b, meanVelGrad, Sij, Lij, eps, K = get_data_RSS('./data/50_new_scaled/',15,80,5,100)\n",
    "LIPM  = LIPM_model(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b,Tij,meanVelGrad,eps,K,Lij,Sij)\n",
    "LSSG = LSSG_model(2.1,4.2,0.8,1.0,1.0,0.4,b,Tij,meanVelGrad,eps,K,Lij,Sij)\n",
    "\n",
    "SLM = get_SLM(2.1,eps,K,Lij)\n",
    "\n",
    "LIPM = np.moveaxis(LIPM,2,0)\n",
    "LSSG = np.moveaxis(LSSG,2,0)\n",
    "SLM  = np.moveaxis(SLM,2,0)\n",
    "Tij  = np.moveaxis(Tij,2,0)\n",
    "\n",
    "RSS_LIPM = get_RSM(LIPM,Tij)\n",
    "RSS_LSSG = get_RSM(LSSG,Tij)\n",
    "RSS_DNS = get_RSM(DNS,Tij)\n",
    "RSS_XGB = get_RSM(PRED_XGB,Tij)\n",
    "RSS_ANN = get_RSM(PRED,Tij)\n",
    "\n",
    "RSS_SLM = get_RSM(SLM,Tij)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Figure 6 and 7\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    k=4\n",
    "    x = np.linspace(0,0.423e-2,576)\n",
    "    x=x-0.423e-2/2\n",
    "    x=x/0.0109e-3\n",
    "    #iindex = [(0,,1,2]\n",
    "    n=1\n",
    "    for i in range(0,3):\n",
    "      for j in range(0,3):\n",
    "        if(i>j):\n",
    "            continue\n",
    "            \n",
    "        plt.subplot(2,3,n) \n",
    "        n=n+1\n",
    "        plt.plot(x,RSS_DNS[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),'--x',linewidth=2,markevery=14,markeredgewidth=1.2,markersize=10)\n",
    "        plt.plot(x,RSS_ANN[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),'--',linewidth=2)\n",
    "        plt.plot(x,RSS_XGB[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),':',linewidth=2)\n",
    "        plt.plot(x,RSS_SLM[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=2,alpha=0.7)\n",
    "        plt.plot(x,RSS_LSSG[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=2,alpha=0.7)\n",
    "        plt.plot(x,RSS_LIPM[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=2,alpha=0.7)\n",
    "        \n",
    "        \n",
    "        plt.locator_params(axis='y', nbins=3)\n",
    "        if(i==0 and j==0):\n",
    "            plt.legend(('DNS','ANN','XGB','SLM','LSSG','LIPM'))\n",
    "        #if(i==1 and j==1):\n",
    "            #plt.ylim((\\))\n",
    "            #plt.yticks([-0.5, 0, 0.5])\n",
    "        #plt.ylim((-0.1,1.2))\n",
    "        plt.subplots_adjust(wspace=0.15)\n",
    "        plt.subplots_adjust(hspace=0.05)\n",
    "        plt.xlabel(r'$Y/\\delta_{\\theta}$')\n",
    "        if(n==5):\n",
    "            plt.ylim((-1,1.5))\n",
    "        if(n==6):\n",
    "            plt.ylim((-1.1,1.0))\n",
    "        plt.xticks([-200,-100,0.0,100,200])\n",
    "\n",
    "        if(n<5):\n",
    "        #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            #plt.gca().axes.get_xaxis().set_visible(False)\n",
    "            plt.xticks([-200,-100,0.0,100,200],\"\")\n",
    "            #plt.xlabel(\"\")\n",
    "        #if(j>0):\n",
    "            #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        #    plt.yticks([0,0.5,1],\"\")\n",
    "        \n",
    "        plt.grid(alpha=0.3)\n",
    "        #x = np.linspace(min(Gij[i,j,:]*eps/K),max(Gij[i,j,:]*eps/K),10)        \n",
    "        ax=plt.gca()\n",
    "        plt.text(0.1,0.9,str(i+1)+','+str(j+1),transform=ax.transAxes,bbox=dict(facecolor='white',alpha=0.5),size=15)\n",
    "        \n",
    "        plt.text(0.68,0.8,\"{:.2e}\".format(max(abs(RSS_DNS[k*576:(k+1)*576,i,j]))),transform=ax.transAxes,bbox=dict(facecolor='white',alpha=0.5),size=12)\n",
    "        \n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + \n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            item.set_fontsize(15)\n",
    "        #plt.plot(x,x,'k--')\n",
    "    #plt.savefig('RSS-ANN-XGB-S1.png',dpi=300,bbox_inches = \"tight\")     \n",
    "    #plt.close()\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
