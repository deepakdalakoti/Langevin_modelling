{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import time\n",
    "os.environ[\"PATH\"] += \"/home/dalakoti/geppy\"\n",
    "import operator\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Lasso, SGDRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer,QuantileTransformer, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression,mutual_info_regression, SelectFromModel\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, GaussianNoise, Conv2D, MaxPooling2D, Flatten, Conv1D,MaxPooling1D\n",
    "from keras.losses import logcosh\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from sklearn.svm import SVR\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "from keras import optimizers\n",
    "from multiprocessing import Pool, Process\n",
    "from keras import regularizers, Input, optimizers, layers\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import math\n",
    "import xgboost as xgb\n",
    "#from numpy import exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(loc,d,delU):\n",
    "    Gij = np.loadtxt(loc+'/Gij_'+d+'.dat')\n",
    "    Tij = np.loadtxt(loc+'/Tij_'+d+'.dat')\n",
    "    K   = np.loadtxt(loc+'/k-eps_'+d+'.dat')    \n",
    "    meanVelGrad = np.loadtxt(loc+'/mean_vel_grad_'+d+'.dat')\n",
    "    Lij = np.loadtxt(loc+'/lambda_'+d+'.dat')\n",
    "    Reyn = np.loadtxt(loc+'/Reyn_'+d+'.dat')\n",
    "    rho = np.loadtxt(loc+'/rho_'+d+'.dat')\n",
    "    mv = np.loadtxt(loc+'/mean_vel_'+d+'.dat')\n",
    "    \n",
    "    mvgg = np.loadtxt(loc+'/mvgg_'+d+'.dat')\n",
    "    \n",
    "    idel = [3, 6, 7, 12, 15, 16, 21, 24, 25]\n",
    "    \n",
    "    mvgg = np.delete(mvgg,idel,axis=1)\n",
    "    delta = np.ones(Reyn.shape[0])*np.sum(rho*(delU/2-mv[:,0])*(delU/2+mv[:,0]))*7.34e-6/(0.68*delU**2)\n",
    "    #delta = np.ones(Reyn.shape[0])*100/np.max(meanVelGrad[:,1])\n",
    "    x = np.linspace(0,0.0423,576)\n",
    "    x = x-0.0423/2.0\n",
    "    eps = np.copy(K[:,1])\n",
    "    K   = K[:,0]\n",
    "    index = np.where(K>0.05*np.max(K))\n",
    "    t_time = np.zeros(576)\n",
    "    t_time[:] = int(d)*3.38e-7\n",
    "    \n",
    "    loend = index[0][0]\n",
    "    hiend = index[0][-1]\n",
    "    #loend = 100\n",
    "    #hiend = 476\n",
    "    #Gij = Gij[loend:hiend,:]\n",
    "    #Tij = Tij[loend:hiend,:]\n",
    "    #meanVelGrad = meanVelGrad[loend:hiend,:]\n",
    "    #eps = eps[loend:hiend]\n",
    "    #K = K[loend:hiend] \n",
    "    #Lij = Lij[loend:hiend]\n",
    "    #Reyn = Reyn[loend:hiend]\n",
    "    #delta = delta[loend:hiend]\n",
    "    #x = x[loend:hiend]/delta\n",
    "    #t_time = t_time[loend:hiend]\n",
    "        \n",
    "    \n",
    "    return Gij, Tij, meanVelGrad, eps, K, Lij, Reyn, delta,x,t_time,mvgg\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time,mvgg):\n",
    "        # basis for CNN just, Tij and meanVelGrad\\n\",\n",
    "        basis_vect = np.zeros((b.shape[0],3,3,33))\n",
    "        basis_vect[:,:,:,0] = b\n",
    "        basis_vect[:,:,:,1] = meanVelGrad\n",
    "        basis_vect[:,:,:,2] = Lij[:,0,0,None,None]\n",
    "        basis_vect[:,:,:,3] = Lij[:,0,1,None,None]\n",
    "        basis_vect[:,:,:,4] = Lij[:,0,2,None,None]\n",
    "        basis_vect[:,:,:,5] = Lij[:,1,1,None,None]\n",
    "        basis_vect[:,:,:,6] = Lij[:,1,2,None,None]\n",
    "        basis_vect[:,:,:,7] = Lij[:,2,2,None,None]\n",
    "        basis_vect[:,:,:,8] = np.trace(meanVelGrad,axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,9] = np.matmul(np.matmul(meanVelGrad,b),b)\n",
    "        \n",
    "        basis_vect[:,:,:,10] = np.matmul(np.matmul(np.transpose(meanVelGrad,(0,2,1)),Lij),meanVelGrad)\n",
    "\n",
    "        #basis_vect[:,:,:,8] = np.trace(meanVelGrad,axis1=1,axis2=2)[:,None,None]\n",
    "        #basis_vect[:,:,:,9] = np.trace(np.matmul(Tij,meanVelGrad),axis1=1,axis2=2)[:,None,None]\n",
    "        #basis_vect[:,:,:,10] = Tij*np.trace(meanVelGrad,axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,11] = np.trace(Lij,axis1=1,axis2=2)[:,None,None]      \n",
    "\n",
    "        basis_vect[:,:,:,12] = np.transpose(meanVelGrad,(0,2,1))\n",
    "        basis_vect[:,:,:,13] = np.matmul(Lij,meanVelGrad)\n",
    "        basis_vect[:,:,:,14] = np.matmul(meanVelGrad,Lij)\n",
    "        basis_vect[:,:,:,15] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),Lij)\n",
    "        basis_vect[:,:,:,16] = np.matmul(Lij,np.transpose(meanVelGrad,(0,2,1)))\n",
    "        #basis_vect[:,:,:,6] = np.matmul(np.matmul(Lij,meanVelGrad),meanVelGrad)\n",
    "        #basis_vect[:,:,:,7] = np.matmul(np.matmul(meanVelGrad,meanVelGrad),Lij)\n",
    "        #basis_vect[:,:,:,8] = np.matmul(np.matmul(Lij,Lij),meanVelGrad)\n",
    "        #basis_vect[:,:,:,9] = np.matmul(np.matmul(meanVelGrad,Lij),Lij)\n",
    "        #basis_vect[:,:,:,10] = np.matmul(np.matmul(meanVelGrad,Lij),meanVelGrad)\n",
    "        #basis_vect[:,:,:,11] = np.matmul(np.matmul(Lij,meanVelGrad),Lij)\n",
    "        basis_vect[:,:,:,17] = np.matmul(b,meanVelGrad)    \n",
    "        basis_vect[:,:,:,18] = np.matmul(meanVelGrad,b)\n",
    "        basis_vect[:,:,:,19] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),b)\n",
    "        basis_vect[:,:,:,20] = np.matmul(b,np.transpose(meanVelGrad,(0,2,1)))\n",
    "        \n",
    "        \n",
    "        basis_vect[:,:,:,21] = Reyn[:,None,None]\n",
    "        basis_vect[:,:,:,22] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),Lij)\n",
    "        basis_vect[:,:,:,23] = K[:,None,None]\n",
    "        basis_vect[:,:,:,24] = eps[:,None,None]\n",
    "        basis_vect[:,:,:,25] = b\n",
    "        \n",
    "        \n",
    "        \n",
    "        #basis_vect[:,:,:,18] = np.trace(basis_vect[:,:,:,1],axis1=1,axis2=2)[:,None,None]\\n\",\n",
    "        #basis_vect[:,:,:,19] = np.trace(basis_vect[:,:,:,2],axis1=1,axis2=2)[:,None,None]\\n\",\n",
    "        #basis_vect[:,:,:,20] = np.trace(basis_vect[:,:,:,3],axis1=1,axis2=2)[:,None,None]\\n\",\n",
    "        #basis_vect[:,:,:,21] = np.trace(basis_vect[:,:,:,4],axis1=1,axis2=2)[:,None,None]\\n\",\n",
    "        #basis_vect[:,:,:,22] = np.trace(basis_vect[:,:,:,5],axis1=1,axis2=2)[:,None,None]\\n\",\n",
    "        #basis_vect[:,:,:,23] = np.trace(basis_vect[:,:,:,7],axis1=1,axis2=2)[:,None,None]\\n\",\n",
    "        #basis_vect[:,:,:,24] = np.matmul(Lij,np.transpose(meanVelGrad,(0,2,1)))\\n\",\n",
    "        ##basis_vect[:,:,:,25] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),Lij)\\n\",\n",
    "        #basis_vect[:,:,:,26] = np.matmul(Tij,np.transpose(meanVelGrad,(0,2,1)))    \\n\",\n",
    "        #basis_vect[:,:,:,27] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),Tij)\\n\",\n",
    "        #basis_vect[:,:,:,28] = Lij[0,1]\\n\",\n",
    "        #basis_vect[:,:,:,29] = Lij[0,2]\\n\",\n",
    "        #basis_vect[:,:,:,30] = K[:,None,None]/eps[:,None,None]\\n\",\n",
    "        return basis_vect       \n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time,mvgg):\n",
    "        # basis for CNN just, Tij and meanVelGrad\\n\",\n",
    "        basis_vect = np.zeros((b.shape[0],3,3,33))\n",
    "        basis_vect[:,:,:,0] = b\n",
    "        basis_vect[:,:,:,1] = meanVelGrad\n",
    "        basis_vect[:,:,:,2] = Lij[:,0,0,None,None]\n",
    "        basis_vect[:,:,:,3] = Lij[:,0,1,None,None]\n",
    "        basis_vect[:,:,:,4] = Lij[:,0,2,None,None]\n",
    "        basis_vect[:,:,:,5] = Lij[:,1,1,None,None]\n",
    "        basis_vect[:,:,:,6] = Lij[:,1,2,None,None]\n",
    "        basis_vect[:,:,:,7] = Lij[:,2,2,None,None]\n",
    "        basis_vect[:,:,:,8] = np.transpose(meanVelGrad,(0,2,1))\n",
    "        basis_vect[:,:,:,9] = np.matmul(Lij,meanVelGrad)\n",
    "        basis_vect[:,:,:,10] = np.matmul(meanVelGrad,Lij)\n",
    "        basis_vect[:,:,:,11] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),Lij)\n",
    "        basis_vect[:,:,:,12] = np.matmul(Lij,np.transpose(meanVelGrad,(0,2,1)))\n",
    "        basis_vect[:,:,:,13] = np.matmul(b,meanVelGrad)    \n",
    "        basis_vect[:,:,:,14] = np.matmul(meanVelGrad,b)\n",
    "        basis_vect[:,:,:,15] = np.matmul(np.transpose(meanVelGrad,(0,2,1)),b)\n",
    "        basis_vect[:,:,:,16] = np.matmul(b,np.transpose(meanVelGrad,(0,2,1)))        \n",
    "        basis_vect[:,:,:,17] = K[:,None,None]\n",
    "        basis_vect[:,:,:,18] = eps[:,None,None]\n",
    "        basis_vect[:,:,:,19] = Reyn[:,None,None]\n",
    "        basis_vect[:,:,:,20] = np.matmul(np.matmul(meanVelGrad,b),b)       \n",
    "        basis_vect[:,:,:,21] = np.trace(meanVelGrad,axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,22] = np.matmul(np.matmul(np.transpose(meanVelGrad,(0,2,1)),Lij),meanVelGrad)\n",
    "        return basis_vect       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(dir_loc,normalise=False,normalise_const=True,delU=100):\n",
    "    \n",
    "    files = glob.glob(dir_loc+'accu*.dat')\n",
    "    indexes = [F[-7:-4] for F in files]        \n",
    "    loindices = np.zeros(len(indexes)+1)\n",
    "    Gij, Tij , meanVelGrad , eps, K, Lij, Reyn, delta, x, t_time = read_data(dir_loc,indexes[0],delU)\n",
    "    loindices[1] = K.shape[0]\n",
    "    \n",
    "    for i, d in enumerate(indexes[1:-1]):\n",
    "        Gij1, Tij1 , meanVelGrad1 , eps1, K1, Lij1, Reyn1, delta1, x1, t_time1 = read_data(dir_loc,d,delU)\n",
    "        loindices[i+2] = loindices[i+1]+K1.shape[0]\n",
    "        Gij = np.append(Gij,Gij1,axis=0)\n",
    "        Tij = np.append(Tij,Tij1,axis=0)\n",
    "        meanVelGrad = np.append(meanVelGrad,meanVelGrad1,axis=0)    \n",
    "        eps = np.append(eps,eps1,axis=0)\n",
    "        K = np.append(K,K1,axis=0)\n",
    "        Lij = np.append(Lij,Lij1,axis=0)\n",
    "        Reyn = np.append(Reyn,Reyn1,axis=0)\n",
    "        delta = np.append(delta,delta1,axis=0)\n",
    "        x = np.append(x,x1,axis=0)\n",
    "        t_time = np.append(t_time,t_time1,axis=0)\n",
    "        \n",
    "        \n",
    "    loindices[len(indexes)] = loindices[len(indexes)]-1   \n",
    "    loindices = loindices.astype(int)    \n",
    "     \n",
    "    b = np.copy(Tij)\n",
    "    b[:,0] = b[:,0]-2.0*K/3.0\n",
    "    b[:,4] = b[:,4]-2.0*K/3.0\n",
    "    b[:,8] = b[:,8]-2.0*K/3.0\n",
    "    Gij = np.reshape(Gij,(Gij.shape[0],3,3))\n",
    "    Tij = np.reshape(Tij,(Tij.shape[0],3,3))\n",
    "    meanVelGrad = np.reshape(meanVelGrad,(meanVelGrad.shape[0],3,3))\n",
    "    b = np.reshape(b,(b.shape[0],3,3))\n",
    "    Lij = np.reshape(Lij,(Lij.shape[0],3,3))\n",
    "\n",
    "    Sij = np.zeros((b.shape[0],3,3))\n",
    "    omega = np.zeros((b.shape[0],3,3))\n",
    "    \n",
    "    for i in range(Sij.shape[0]):\n",
    "        Sij[i,:,:] = 0.5*(meanVelGrad[i,:,:]+np.transpose(meanVelGrad[i,:,:]))\n",
    "        omega[i,:,:] = 0.5*(meanVelGrad[i,:,:]-np.transpose(meanVelGrad[i,:,:]))\n",
    "        \n",
    "    b = b/(2.0*K[:,None,None])\n",
    "\n",
    "    if(normalise):    \n",
    "        Gij = Gij*K[:,None,None]/eps[:,None,None]\n",
    "        Tij = Tij/K[:,None,None]\n",
    "        meanVelGrad = meanVelGrad*K[:,None,None]/eps[:,None,None]\n",
    "        Sij = Sij*K[:,None,None]/eps[:,None,None]\n",
    "        omega = omega*K[:,None,None]/eps[:,None,None]\n",
    "        Lij = Lij*K[:,None,None]\n",
    "        #t_time = t_time*eps/K\n",
    "        \n",
    "    if(normalise_const):               \n",
    "        Gij = Gij*delta[:,None,None]/delU\n",
    "        #Gij = Gij*delta[:,None,None]/delU**3        \n",
    "        Tij = Tij/delU**2\n",
    "        meanVelGrad = meanVelGrad*delta[:,None,None]/delU\n",
    "        Sij = Sij*delta[:,None,None]/delU\n",
    "        omega = omega*delta[:,None,None]/delU\n",
    "        eps = eps*delta/delU**3\n",
    "        K = K/delU**2\n",
    "        Lij = Lij*delU**2\n",
    "        t_time = t_time*delU/delta\n",
    "        \n",
    "        \n",
    "    \n",
    "    basis_vect = get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time)\n",
    "    basis_vect = np.moveaxis(basis_vect,0,-2)\n",
    "    Gij = np.moveaxis(Gij,0,-1)\n",
    "    Tij = np.moveaxis(Tij,0,-1)\n",
    "    Lij = np.moveaxis(Lij,0,-1)\n",
    "    b = np.moveaxis(b,0,-1)\n",
    "    meanVelGrad = np.moveaxis(meanVelGrad,0,-1)\n",
    "    Sij = np.moveaxis(Sij,0,-1)\n",
    "    omega = np.moveaxis(omega,0,-1)\n",
    "    \n",
    "    \n",
    "        \n",
    "    return Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K, basis_vect, loindices.astype(int), delta,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_time(dir_loc,time,normalise=False,normalise_const=True,delU=100):\n",
    "\n",
    "    files = sorted(glob.glob(dir_loc+'accu*.dat'))\n",
    "    indexes = [F[-7:-4] for F in files]        \n",
    "    loindices = np.zeros(len(indexes)+1)\n",
    "    Gij, Tij , meanVelGrad , eps, K, Lij, Reyn, delta, x, t_time,mvgg = read_data(dir_loc,indexes[time],delU)\n",
    "    loindices[1] = K.shape[0]\n",
    "    \n",
    "    b = np.copy(Tij)\n",
    "    b[:,0] = b[:,0]-2.0*K/3.0\n",
    "    b[:,4] = b[:,4]-2.0*K/3.0\n",
    "    b[:,8] = b[:,8]-2.0*K/3.0\n",
    "    Gij = np.reshape(Gij,(Gij.shape[0],3,3))\n",
    "    Tij = np.reshape(Tij,(Tij.shape[0],3,3))\n",
    "    meanVelGrad = np.reshape(meanVelGrad,(meanVelGrad.shape[0],3,3))\n",
    "    b = np.reshape(b,(b.shape[0],3,3))\n",
    "    Lij = np.reshape(Lij,(Lij.shape[0],3,3))\n",
    "\n",
    "    Sij = np.zeros((b.shape[0],3,3))\n",
    "    omega = np.zeros((b.shape[0],3,3))\n",
    "    \n",
    "    for i in range(Sij.shape[0]):\n",
    "        Sij[i,:,:] = 0.5*(meanVelGrad[i,:,:]+np.transpose(meanVelGrad[i,:,:]))\n",
    "        omega[i,:,:] = 0.5*(meanVelGrad[i,:,:]-np.transpose(meanVelGrad[i,:,:]))\n",
    "        \n",
    "    b = b/(2.0*K[:,None,None])\n",
    "    if(normalise):    \n",
    "        Gij = Gij*K[:,None,None]/eps[:,None,None]\n",
    "        Tij = Tij/K[:,None,None]\n",
    "        meanVelGrad = meanVelGrad*K[:,None,None]/eps[:,None,None]\n",
    "        Sij = Sij*K[:,None,None]/eps[:,None,None]\n",
    "        omega = omega*K[:,None,None]/eps[:,None,None]\n",
    "        Lij = Lij*K[:,None,None]\n",
    "    \n",
    "    if(normalise_const):\n",
    "        \n",
    "        Gij = Gij*delta[:,None,None]/delU\n",
    "        #Gij = Gij*delta[:,None,None]/delU**3        \n",
    "        Tij = Tij/delU**2\n",
    "        meanVelGrad = meanVelGrad*delta[:,None,None]/delU\n",
    "        Sij = Sij*delta[:,None,None]/delU\n",
    "        omega = omega*delta[:,None,None]/delU\n",
    "        eps = eps*delta/delU**3\n",
    "        K = K/delU**2\n",
    "        Lij = Lij*delU**2\n",
    "        t_time = t_time*delU/delta\n",
    "\n",
    "    basis_vect = get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time,mvgg)\n",
    "    basis_vect = np.moveaxis(basis_vect,0,-2)\n",
    "    Gij = np.moveaxis(Gij,0,-1)\n",
    "    Tij = np.moveaxis(Tij,0,-1)\n",
    "    Lij = np.moveaxis(Lij,0,-1)\n",
    "    b = np.moveaxis(b,0,-1)\n",
    "    meanVelGrad = np.moveaxis(meanVelGrad,0,-1)\n",
    "    Sij = np.moveaxis(Sij,0,-1)\n",
    "    omega = np.moveaxis(omega,0,-1)\n",
    "        \n",
    "    return Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K, basis_vect, loindices.astype(int), delta, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_correlated(X):\n",
    "    c = np.corrcoef(X.T)\n",
    "    c = np.nan_to_num(c)\n",
    "    \n",
    "    index = list(np.where(np.triu(c,k=1)>0.99))    \n",
    "    to_drop = list(set(index[1]))\n",
    "    \n",
    "    consts = np.all(X == X[0,:], axis = 0)\n",
    "    constsi = list(np.where(consts)[0])\n",
    "    to_drop = list(set(to_drop+constsi))\n",
    "\n",
    "    \n",
    "    X_new = np.delete(X,to_drop,axis=1)\n",
    "    \n",
    "    \n",
    "    return X_new, to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_training(direc,ist,nt,stp, delU,nfs,i1,j1):\n",
    "            Gij, _, _, _, _, _, Lij, _, _, basis_vect, _, _, _ = get_training_data_time(direc,ist,False,False,delU)\n",
    "            idxs = np.zeros(math.ceil((nt)/stp)+1)\n",
    "            idxs[0]=0\n",
    "            X = np.copy(basis_vect[i1,j1,:,0:nfs])\n",
    "            Y = np.copy(Gij[i1,j1,:])\n",
    "            j=1\n",
    "            for i in range(ist+stp,ist+nt,stp):\n",
    "                idxs[j] = idxs[j-1]+Gij.shape[2]\n",
    "                Gij, _, _, _, _, _, Lij, _, _, basis_vect, _, _, _ = get_training_data_time(direc,i,False,False,delU)\n",
    "                X = np.append(X,basis_vect[i1,j1,:,0:nfs],axis=0)\n",
    "                Y = np.append(Y,Gij[i1,j1,:],axis=0)\n",
    "                j=j+1\n",
    "            idxs[j] = X.shape[0]    \n",
    "            #Only take lambda_kj terms\n",
    "            if(j1==0):\n",
    "                X = np.delete(X,(5,6,7),axis=1)\n",
    "            if(j1==1):\n",
    "                X = np.delete(X,(2,4,7),axis=1)\n",
    "            if(j1==2):\n",
    "                X = np.delete(X,(2,3,5),axis=1)\n",
    "            \n",
    "                \n",
    "            return X,Y,idxs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train,X_test, X_val, Y_train, Y_test, Y_val, which):\n",
    "    \n",
    "    if(which == 'std'):\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_val = sc.transform(X_val)\n",
    "        Y_train = sc.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = sc.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = sc.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'mean'):\n",
    "        meanX   = np.mean(X_train,axis=0)\n",
    "        stdX    = np.std(X_train,axis=0)\n",
    "    \n",
    "        meanY   = np.mean(Y_train)\n",
    "        stdY    = np.std(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train)/meanY\n",
    "        Y_test = (Y_test)/meanY\n",
    "        Y_val   = (Y_val)/meanY\n",
    "        \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/meanX[i]\n",
    "            X_test[:,i] = (X_test[:,i])/meanX[i]\n",
    "            X_val[:,i] = (X_val[:,i])/meanX[i]\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    \n",
    "    if(which=='minmax'):\n",
    "        minX   = np.min(X_train,axis=(0))\n",
    "        maxX    = np.max(X_train,axis=(0))\n",
    "    \n",
    "        minY   = np.min(Y_train)\n",
    "        maxY    = np.max(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train-minY)/(maxY-minY)\n",
    "        Y_test = (Y_test-minY)/(maxY-minY)\n",
    "        Y_val   = (Y_val-minY)/(maxY-minY)\n",
    "        #Y_train = (Y_train)/(maxY-minY)\n",
    "        #Y_test = (Y_test)/(maxY-minY)\n",
    "        #Y_val   = (Y_val)/(maxY-minY)\n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            X_test[:,i] = (X_test[:,i]-minX[i])/(maxX[i]-minX[i])            \n",
    "            X_val[:,i] = (X_val[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='max'):\n",
    "        maxX    = np.max(np.abs(X_train),axis=(0))\n",
    "    \n",
    "        maxY    = np.max(np.abs(Y_train))\n",
    "    \n",
    "        Y_train = (Y_train)/(maxY)\n",
    "        Y_test = (Y_test)/(maxY)\n",
    "        Y_val   = (Y_val)/(maxY)\n",
    "        \n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/(maxX[i])\n",
    "            X_test[:,i] = (X_test[:,i])/(maxX[i])            \n",
    "            X_val[:,i] = (X_val[:,i])/(maxX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'yeo'):\n",
    "            pt = PowerTransformer(standardize=True)\n",
    "            X_train = pt.fit_transform(X_train)            \n",
    "            X_test  = pt.transform(X_test)\n",
    "            X_val   = pt.transform(X_val)\n",
    "            Y_train  = pt.fit_transform(Y_train.reshape(-1,1))            \n",
    "            Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "            Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "            print(pt.lambdas_)\n",
    "            return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'quant'):\n",
    "                pt = QuantileTransformer(output_distribution='normal')\n",
    "                X_train = pt.fit_transform(X_train)\n",
    "                X_test  = pt.transform(X_test)\n",
    "                X_val   = pt.transform(X_val)\n",
    "                Y_train = pt.fit_transform(Y_train.reshape(-1,1))\n",
    "                Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "                Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "                return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='log'):\n",
    "               X_train = do_log(X_train)    \n",
    "               X_test = do_log(X_test)    \n",
    "               X_val = do_log(X_val)\n",
    "               Y_train = do_log2(Y_train)\n",
    "               Y_test = do_log2(Y_test)\n",
    "               Y_val = do_log2(Y_val)\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='exp'):\n",
    "               X_train = X_train**0.3    \n",
    "               X_test = X_test**0.3    \n",
    "               X_val = X_val**0.3\n",
    "               Y_train = Y_train**0.3\n",
    "               Y_test = Y_test**0.3\n",
    "               Y_val = Y_val**0.3\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        X_train = RS.fit_transform(X_train)\n",
    "        X_test = RS.transform(X_test)\n",
    "        X_val = RS.transform(X_val)\n",
    "        Y_train = RS.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = RS.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = RS.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inverse_scaling(Y_sc, Y_un, which):\n",
    "    if(which=='std'):\n",
    "        meanY = np.mean(Y_un)\n",
    "        stdY = np.std(Y_un)\n",
    "        return Y_sc*stdY + meanY\n",
    "    if(which=='minmax'):\n",
    "        minY = np.min(Y_un)\n",
    "        maxY = np.max(Y_un)\n",
    "        return Y_sc*(maxY-minY)+minY\n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        RS.fit(Y_un.reshape(-1,1))\n",
    "        return RS.inverse_transform(Y_sc.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts=576\n",
    "np.random.seed(10)\n",
    "nT = [i for i in range(0,40)]\n",
    "np.random.shuffle(nT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts=576\n",
    "np.random.seed(10)\n",
    "nT = [i for i in range(0,100)]\n",
    "np.random.shuffle(nT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('NT_100',nT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i1,j1):\n",
    "    nfs = 23\n",
    "    \n",
    "    X, Y, _ = get_CNN_training('./data/CaseF_scaled/',0,100,2,100,nfs,i1,j1)\n",
    "    X1, Y1, _ = get_CNN_training('./data/CaseC_scaled/',50,150,3,100,nfs,i1,j1)\n",
    "    X = np.append(X,X1,axis=0)\n",
    "    Y = np.append(Y,Y1,axis=0)\n",
    "\n",
    "    nfs=20\n",
    "    npts=576\n",
    "    X_train = np.zeros((npts*60,nfs))\n",
    "    Y_train = np.zeros((npts*60,1))\n",
    "\n",
    "    X_val = np.zeros((npts*20,nfs))\n",
    "    Y_val = np.zeros((npts*20,1))\n",
    "    \n",
    "    X_val2 = np.zeros((npts*20,nfs))\n",
    "    Y_val2 = np.zeros((npts*20,1))\n",
    "    \n",
    "\n",
    "    for i in range(0,60):\n",
    "        X_train[i*npts:(i+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_train[i*npts:(i+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "    j=0\n",
    "    for i in range(60,80):\n",
    "        X_val[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_val[j*npts:(j+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "        j=j+1\n",
    "    j=0\n",
    "    for i in range(80,100):\n",
    "        X_val2[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_val2[j*npts:(j+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "        j=j+1\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    nfs=23\n",
    "    minY = np.min(Y_train)\n",
    "    maxY = np.max(Y_train)\n",
    "    stdY = np.std(Y_train)\n",
    "    meanY = np.mean(Y_train)\n",
    "    Y_un = np.copy(Y_train)\n",
    "\n",
    "    X_test, Y_test, _ = get_CNN_training('./data/50_new_scaled/',15,80,5,150,nfs,i1,j1)\n",
    "    #X_test, Y_test, _ = get_CNN_training('./data/CaseF/',80,20,2,150,nfs,i1,j1)\n",
    "\n",
    "    #sc = StandardScaler()\n",
    "    #sc.fit(X_train)\n",
    "    #X_val2 = sc.transform(X_val2)\n",
    "    #sc.fit(Y_train)\n",
    "    #Y_val2 = sc.transform(Y_val2)\n",
    "    \n",
    "\n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i1,j1):\n",
    "    nfs = 23\n",
    "    \n",
    "    X, Y, _ = get_CNN_training('./data/CaseF/',0,80,2,100,nfs,i1,j1)\n",
    "\n",
    "    nfs=20\n",
    "    npts=576\n",
    "    X_train = np.zeros((npts*30,nfs))\n",
    "    Y_train = np.zeros((npts*30,1))\n",
    "\n",
    "    X_val = np.zeros((npts*10,nfs))\n",
    "    Y_val = np.zeros((npts*10,1))\n",
    "\n",
    "\n",
    "    for i in range(0,30):\n",
    "        X_train[i*npts:(i+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_train[i*npts:(i+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "    j=0\n",
    "    for i in range(30,40):\n",
    "        X_val[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_val[j*npts:(j+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "        j=j+1\n",
    "    nfs=23\n",
    "    minY = np.min(Y_train)\n",
    "    maxY = np.max(Y_train)\n",
    "    stdY = np.std(Y_train)\n",
    "    meanY = np.mean(Y_train)\n",
    "    Y_un = np.copy(Y_train)\n",
    "\n",
    "    X_test, Y_test, _ = get_CNN_training('./data/50_new/',15,80,5,150,nfs,i1,j1)\n",
    "    #X_test, Y_test, _ = get_CNN_training('./data/CaseF/',80,20,2,150,nfs,i1,j1)\n",
    "\n",
    "    \n",
    "\n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_XGB(nest):\n",
    "    model = xgb.XGBRegressor(versbosity=0,booster='gbtree',objective='reg:squarederror',max_depth=3, \\\n",
    "                               learning_rate=0.1,n_estimators=nest,n_jobs=8,importance_type='gain')\n",
    "    return model\n",
    "        \n",
    "               \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val,Y_train,Y_test, Y_val, Y_un = get_data(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "reg = [350]\n",
    "scs = np.zeros((int(X_val.shape[0]/576),len(reg)))\n",
    "sctr = np.zeros((int(X_train.shape[0]/576),len(reg)))\n",
    "sct = np.zeros((int(X_test.shape[0]/576),len(reg)))\n",
    "for i, j in enumerate(reg):\n",
    "    print(i)\n",
    "    model = get_model_XGB(j)\n",
    "    model.fit(X_train,Y_train,eval_set=[(X_val,Y_val)],early_stopping_rounds=40,verbose=False)\n",
    "    \n",
    "    scs[:,i] = get_score(model, X_val, Y_val, Y_un, 'std')\n",
    "    sct[:,i] = get_score(model, X_test, Y_test, Y_un, 'std')\n",
    "    sctr[:,i] = get_score(model, X_train, Y_train, Y_un, 'std')\n",
    "    #if(np.mean(sct,axis=0)[i]<0.13):\n",
    "    #    model.save('models/Gij_0_1_S2.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b9228aa7f60>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(sctr,'-o')\n",
    "plt.plot(scs,'-o')\n",
    "plt.plot(sct,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(reg,dimi):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8,input_dim=dimi,use_bias=True,kernel_regularizer=regularizers.l2(reg)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.01))\n",
    "        #model.add(layers.BatchNormalization())\n",
    "        #model.add(Dropout(0.1))\n",
    "        model.add(Dense(6, use_bias=True,kernel_regularizer=regularizers.l2(reg)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.01))\n",
    "        #model.add(Dropout(0.1))\n",
    "        \n",
    "        #model.add(layers.BatchNormalization())\n",
    "        #model.add(Dropout(0.2))\n",
    "        #model.add(layers.BatchNormalization())\n",
    "        \n",
    "        \n",
    "        model.add(Dense(4,use_bias=True,kernel_regularizer=regularizers.l2(reg)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.01))\n",
    "        #model.add(layers.BatchNormalization())\n",
    "        #model.add(Dropout(0.1))\n",
    "        \n",
    "       \n",
    "        opt = optimizers.Adam(learning_rate=0.001)\n",
    "        #optN = optimizers.nadam(learning_rate=0.0005)\\n\",\n",
    "        model.add(Dense(1,activation='linear'))\n",
    "        model.compile(optimizer=opt,loss='mean_squared_error')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/Gij_1_0_S2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 1s 35us/sample - loss: 0.9105 - val_loss: 0.6538\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7237 - val_loss: 0.5032\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5439 - val_loss: 0.3733\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3953 - val_loss: 0.2881\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2913 - val_loss: 0.2311\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2288 - val_loss: 0.1946\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1900 - val_loss: 0.1644\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1597 - val_loss: 0.1384\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1344 - val_loss: 0.1159\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1135 - val_loss: 0.0973\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0961 - val_loss: 0.0819\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0819 - val_loss: 0.0696\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0702 - val_loss: 0.0597\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0516\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0529 - val_loss: 0.0449\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0467 - val_loss: 0.0395\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0415 - val_loss: 0.0350\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0314\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0337 - val_loss: 0.0285\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0262\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0243\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0265 - val_loss: 0.0230\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0250 - val_loss: 0.0219\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0238 - val_loss: 0.0211\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0220 - val_loss: 0.0199\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0213 - val_loss: 0.0195\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0208 - val_loss: 0.0191\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0203 - val_loss: 0.0188\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0199 - val_loss: 0.0186\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0196 - val_loss: 0.0184\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0193 - val_loss: 0.0182\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0187 - val_loss: 0.0179\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0185 - val_loss: 0.0177\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0183 - val_loss: 0.0176\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0181 - val_loss: 0.0175\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0179 - val_loss: 0.0174\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0172\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0168 - val_loss: 0.0168\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0167\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0166\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0159\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 5us/sample - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0145 - val_loss: 0.0152\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0141 - val_loss: 0.0148\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0141 - val_loss: 0.0148\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0140 - val_loss: 0.0147\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0138 - val_loss: 0.0146\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0138 - val_loss: 0.0146\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0135 - val_loss: 0.0143\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0134 - val_loss: 0.0142\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0134 - val_loss: 0.0142\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0133 - val_loss: 0.0142\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0133 - val_loss: 0.0141\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0132 - val_loss: 0.0140\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0131 - val_loss: 0.0140\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0131 - val_loss: 0.0140\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0131 - val_loss: 0.0139\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0129 - val_loss: 0.0137\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0128 - val_loss: 0.0136\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0127 - val_loss: 0.0136\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0126 - val_loss: 0.0133\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0130\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0130\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0126\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0113\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0113\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0110\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - ETA: 0s - loss: 0.009 - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 376/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0101\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0098\n",
      "0 1\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 0.6562 - val_loss: 0.4673\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4783 - val_loss: 0.3766\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3966 - val_loss: 0.2831\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2609 - val_loss: 0.0934\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0876 - val_loss: 0.0447\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0506 - val_loss: 0.0271\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0328 - val_loss: 0.0175\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0227 - val_loss: 0.0126\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0102\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0082\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.9495e-04 - val_loss: 0.0010\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.8387e-04 - val_loss: 0.0010\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.7315e-04 - val_loss: 0.0010\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.6315e-04 - val_loss: 0.0010\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.5323e-04 - val_loss: 0.0010\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.4366e-04 - val_loss: 0.0010\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.3421e-04 - val_loss: 0.0010\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.2502e-04 - val_loss: 9.9460e-04\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.1586e-04 - val_loss: 9.8821e-04\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 9.0727e-04 - val_loss: 9.8245e-04\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.9844e-04 - val_loss: 9.7688e-04\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.9015e-04 - val_loss: 9.7138e-04\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.8183e-04 - val_loss: 9.6637e-04\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.7377e-04 - val_loss: 9.6079e-04\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.6665e-04 - val_loss: 9.5613e-04\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.5935e-04 - val_loss: 9.5169e-04\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.5249e-04 - val_loss: 9.4720e-04\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.4602e-04 - val_loss: 9.4271e-04\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.3978e-04 - val_loss: 9.3905e-04\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.3375e-04 - val_loss: 9.3487e-04\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.2729e-04 - val_loss: 9.3060e-04\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.2182e-04 - val_loss: 9.2723e-04\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.1601e-04 - val_loss: 9.2380e-04\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.1028e-04 - val_loss: 9.2039e-04\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 8.0502e-04 - val_loss: 9.1663e-04\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.9954e-04 - val_loss: 9.1398e-04\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.9379e-04 - val_loss: 9.1079e-04\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.8856e-04 - val_loss: 9.0775e-04\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.8360e-04 - val_loss: 9.0461e-04\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.7851e-04 - val_loss: 9.0206e-04\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.7360e-04 - val_loss: 8.9884e-04\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.6891e-04 - val_loss: 8.9628e-04\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.6408e-04 - val_loss: 8.9367e-04\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.5965e-04 - val_loss: 8.9061e-04\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.5541e-04 - val_loss: 8.8817e-04\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.5110e-04 - val_loss: 8.8555e-04\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.4691e-04 - val_loss: 8.8334e-04\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.4303e-04 - val_loss: 8.8119e-04\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.3915e-04 - val_loss: 8.7839e-04\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.3529e-04 - val_loss: 8.7603e-04\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.3149e-04 - val_loss: 8.7314e-04\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.2722e-04 - val_loss: 8.7108e-04\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.2333e-04 - val_loss: 8.6914e-04\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.1956e-04 - val_loss: 8.6673e-04\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.1592e-04 - val_loss: 8.6455e-04\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.1239e-04 - val_loss: 8.6234e-04\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.0900e-04 - val_loss: 8.6003e-04\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.0555e-04 - val_loss: 8.5754e-04\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 7.0149e-04 - val_loss: 8.5441e-04\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.9824e-04 - val_loss: 8.5160e-04\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.9491e-04 - val_loss: 8.4931e-04\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.9135e-04 - val_loss: 8.4634e-04\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.8794e-04 - val_loss: 8.4442e-04\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.8447e-04 - val_loss: 8.4207e-04\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.8144e-04 - val_loss: 8.3958e-04\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.7828e-04 - val_loss: 8.3674e-04\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.7505e-04 - val_loss: 8.3354e-04\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.7179e-04 - val_loss: 8.3085e-04\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.6860e-04 - val_loss: 8.2808e-04\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.6565e-04 - val_loss: 8.2604e-04\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.6260e-04 - val_loss: 8.2369e-04\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.5978e-04 - val_loss: 8.2116e-04\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.5670e-04 - val_loss: 8.1937e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.5361e-04 - val_loss: 8.1810e-04\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.5072e-04 - val_loss: 8.1505e-04\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.4765e-04 - val_loss: 8.1348e-04\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.4467e-04 - val_loss: 8.1136e-04\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.4173e-04 - val_loss: 8.1036e-04\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.3874e-04 - val_loss: 8.0918e-04\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.3599e-04 - val_loss: 8.0677e-04\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.3346e-04 - val_loss: 8.0516e-04\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.3045e-04 - val_loss: 8.0314e-04\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.2777e-04 - val_loss: 8.0147e-04\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.2513e-04 - val_loss: 7.9900e-04\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.2255e-04 - val_loss: 7.9703e-04\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.2006e-04 - val_loss: 7.9557e-04\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.1772e-04 - val_loss: 7.9441e-04\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.1544e-04 - val_loss: 7.9228e-04\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.1304e-04 - val_loss: 7.9094e-04\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.1069e-04 - val_loss: 7.8979e-04\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.0859e-04 - val_loss: 7.8855e-04\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.0640e-04 - val_loss: 7.8680e-04\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.0404e-04 - val_loss: 7.8513e-04\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 6.0196e-04 - val_loss: 7.8368e-04\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.9993e-04 - val_loss: 7.8261e-04\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.9788e-04 - val_loss: 7.8150e-04\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.9585e-04 - val_loss: 7.8118e-04\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.9400e-04 - val_loss: 7.8165e-04\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.9193e-04 - val_loss: 7.8040e-04\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.8993e-04 - val_loss: 7.7964e-04\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.8804e-04 - val_loss: 7.7875e-04\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.8638e-04 - val_loss: 7.7723e-04\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.8426e-04 - val_loss: 7.7684e-04\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.8237e-04 - val_loss: 7.7670e-04\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.8015e-04 - val_loss: 7.7469e-04\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.7822e-04 - val_loss: 7.7386e-04\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.7653e-04 - val_loss: 7.7259e-04\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.7444e-04 - val_loss: 7.7174e-04\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.7249e-04 - val_loss: 7.7138e-04\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.7101e-04 - val_loss: 7.7186e-04\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.6918e-04 - val_loss: 7.7134e-04\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.6720e-04 - val_loss: 7.7031e-04\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.6549e-04 - val_loss: 7.7070e-04\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.6319e-04 - val_loss: 7.6982e-04\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.6133e-04 - val_loss: 7.6967e-04\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.5948e-04 - val_loss: 7.6958e-04\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.5781e-04 - val_loss: 7.6887e-04\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.5615e-04 - val_loss: 7.6922e-04\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.5450e-04 - val_loss: 7.6903e-04\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.5289e-04 - val_loss: 7.6829e-04\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.5150e-04 - val_loss: 7.6949e-04\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.4971e-04 - val_loss: 7.6868e-04\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.4809e-04 - val_loss: 7.6785e-04\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.4649e-04 - val_loss: 7.6673e-04\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.4469e-04 - val_loss: 7.6541e-04\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.4292e-04 - val_loss: 7.6500e-04\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.4150e-04 - val_loss: 7.6465e-04\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3996e-04 - val_loss: 7.6496e-04\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3840e-04 - val_loss: 7.6465e-04\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3712e-04 - val_loss: 7.6483e-04\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3572e-04 - val_loss: 7.6532e-04\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3436e-04 - val_loss: 7.6551e-04\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3325e-04 - val_loss: 7.6506e-04\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3187e-04 - val_loss: 7.6426e-04\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.3046e-04 - val_loss: 7.6365e-04\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.2882e-04 - val_loss: 7.6319e-04\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.2743e-04 - val_loss: 7.6349e-04\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.2590e-04 - val_loss: 7.6300e-04\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.2422e-04 - val_loss: 7.6245e-04\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.2271e-04 - val_loss: 7.6241e-04\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.2130e-04 - val_loss: 7.6159e-04\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1983e-04 - val_loss: 7.6080e-04\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1830e-04 - val_loss: 7.5987e-04\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1697e-04 - val_loss: 7.5894e-04\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1565e-04 - val_loss: 7.5732e-04\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1387e-04 - val_loss: 7.5518e-04\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1260e-04 - val_loss: 7.5386e-04\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.1116e-04 - val_loss: 7.5304e-04\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0974e-04 - val_loss: 7.5133e-04\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0837e-04 - val_loss: 7.5086e-04\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0716e-04 - val_loss: 7.4980e-04\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0588e-04 - val_loss: 7.4978e-04\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0435e-04 - val_loss: 7.4929e-04\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0333e-04 - val_loss: 7.5024e-04\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0216e-04 - val_loss: 7.5119e-04\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0123e-04 - val_loss: 7.5085e-04\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 5.0017e-04 - val_loss: 7.5117e-04\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9930e-04 - val_loss: 7.4989e-04\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9767e-04 - val_loss: 7.4760e-04\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9661e-04 - val_loss: 7.4758e-04\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9569e-04 - val_loss: 7.4924e-04\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9475e-04 - val_loss: 7.4976e-04\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9372e-04 - val_loss: 7.4839e-04\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9268e-04 - val_loss: 7.4696e-04\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9158e-04 - val_loss: 7.4647e-04\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.9055e-04 - val_loss: 7.4668e-04\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8982e-04 - val_loss: 7.4694e-04\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8896e-04 - val_loss: 7.4800e-04\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8820e-04 - val_loss: 7.4845e-04\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8760e-04 - val_loss: 7.4856e-04\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8665e-04 - val_loss: 7.4773e-04\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8586e-04 - val_loss: 7.4733e-04\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8528e-04 - val_loss: 7.4770e-04\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8443e-04 - val_loss: 7.4718e-04\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8361e-04 - val_loss: 7.4707e-04\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8251e-04 - val_loss: 7.4594e-04\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8153e-04 - val_loss: 7.4566e-04\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.8071e-04 - val_loss: 7.4488e-04\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7925e-04 - val_loss: 7.4310e-04\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7792e-04 - val_loss: 7.4163e-04\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7659e-04 - val_loss: 7.3932e-04\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7506e-04 - val_loss: 7.3781e-04\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7373e-04 - val_loss: 7.3590e-04\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7239e-04 - val_loss: 7.3432e-04\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7136e-04 - val_loss: 7.3548e-04\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7084e-04 - val_loss: 7.3548e-04\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.7015e-04 - val_loss: 7.3598e-04\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6931e-04 - val_loss: 7.3598e-04\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6843e-04 - val_loss: 7.3604e-04\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6770e-04 - val_loss: 7.3611e-04\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6713e-04 - val_loss: 7.3597e-04\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6639e-04 - val_loss: 7.3572e-04\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6554e-04 - val_loss: 7.3684e-04\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6504e-04 - val_loss: 7.3737e-04\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6426e-04 - val_loss: 7.3579e-04\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6342e-04 - val_loss: 7.3652e-04\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6268e-04 - val_loss: 7.3344e-04\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6178e-04 - val_loss: 7.3441e-04\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6125e-04 - val_loss: 7.3244e-04\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.6043e-04 - val_loss: 7.3345e-04\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5982e-04 - val_loss: 7.3218e-04\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5913e-04 - val_loss: 7.3291e-04\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5851e-04 - val_loss: 7.3210e-04\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5781e-04 - val_loss: 7.3182e-04\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5724e-04 - val_loss: 7.3340e-04\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5678e-04 - val_loss: 7.3214e-04\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5606e-04 - val_loss: 7.3255e-04\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5559e-04 - val_loss: 7.3001e-04\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5483e-04 - val_loss: 7.3113e-04\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5426e-04 - val_loss: 7.2974e-04\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5354e-04 - val_loss: 7.2968e-04\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5288e-04 - val_loss: 7.2794e-04\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5209e-04 - val_loss: 7.2708e-04\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5158e-04 - val_loss: 7.2718e-04\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5097e-04 - val_loss: 7.2595e-04\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.5038e-04 - val_loss: 7.2627e-04\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4974e-04 - val_loss: 7.2450e-04\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4910e-04 - val_loss: 7.2520e-04\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4866e-04 - val_loss: 7.2496e-04\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4805e-04 - val_loss: 7.2414e-04\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4741e-04 - val_loss: 7.2391e-04\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4674e-04 - val_loss: 7.2350e-04\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4612e-04 - val_loss: 7.2281e-04\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4540e-04 - val_loss: 7.2242e-04\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4488e-04 - val_loss: 7.2230e-04\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4439e-04 - val_loss: 7.2177e-04\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4378e-04 - val_loss: 7.2192e-04\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4328e-04 - val_loss: 7.2081e-04\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4268e-04 - val_loss: 7.2056e-04\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4209e-04 - val_loss: 7.2061e-04\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4183e-04 - val_loss: 7.1948e-04\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4123e-04 - val_loss: 7.1809e-04\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.4031e-04 - val_loss: 7.1626e-04\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3951e-04 - val_loss: 7.1549e-04\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3882e-04 - val_loss: 7.1568e-04\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3813e-04 - val_loss: 7.1515e-04\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3756e-04 - val_loss: 7.1366e-04\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3675e-04 - val_loss: 7.1270e-04\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3603e-04 - val_loss: 7.1222e-04\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3546e-04 - val_loss: 7.1234e-04\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3487e-04 - val_loss: 7.1161e-04\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3429e-04 - val_loss: 7.1149e-04\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3398e-04 - val_loss: 7.1067e-04\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3334e-04 - val_loss: 7.1160e-04\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3301e-04 - val_loss: 7.1092e-04\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3247e-04 - val_loss: 7.1049e-04\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3180e-04 - val_loss: 7.1028e-04\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3136e-04 - val_loss: 7.0914e-04\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3078e-04 - val_loss: 7.0802e-04\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.3020e-04 - val_loss: 7.0753e-04\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2957e-04 - val_loss: 7.0628e-04\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2895e-04 - val_loss: 7.0454e-04\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2830e-04 - val_loss: 7.0460e-04\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2779e-04 - val_loss: 7.0426e-04\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2724e-04 - val_loss: 7.0323e-04\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2670e-04 - val_loss: 7.0340e-04\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2626e-04 - val_loss: 7.0280e-04\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2566e-04 - val_loss: 7.0252e-04\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2511e-04 - val_loss: 7.0113e-04\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2460e-04 - val_loss: 7.0111e-04\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2401e-04 - val_loss: 7.0030e-04\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2355e-04 - val_loss: 7.0047e-04\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2298e-04 - val_loss: 6.9836e-04\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2232e-04 - val_loss: 6.9813e-04\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2177e-04 - val_loss: 6.9621e-04\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2112e-04 - val_loss: 6.9511e-04\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2059e-04 - val_loss: 6.9422e-04\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.2004e-04 - val_loss: 6.9410e-04\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1947e-04 - val_loss: 6.9317e-04\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1879e-04 - val_loss: 6.9222e-04\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1837e-04 - val_loss: 6.9152e-04\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1763e-04 - val_loss: 6.9109e-04\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1724e-04 - val_loss: 6.9024e-04\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1651e-04 - val_loss: 6.8853e-04\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1591e-04 - val_loss: 6.8770e-04\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1533e-04 - val_loss: 6.8617e-04\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1471e-04 - val_loss: 6.8519e-04\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1401e-04 - val_loss: 6.8392e-04\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1351e-04 - val_loss: 6.8441e-04\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1300e-04 - val_loss: 6.8291e-04\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1242e-04 - val_loss: 6.8254e-04\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1193e-04 - val_loss: 6.8183e-04\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1130e-04 - val_loss: 6.7947e-04\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1077e-04 - val_loss: 6.7875e-04\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.1014e-04 - val_loss: 6.7827e-04\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0965e-04 - val_loss: 6.7680e-04\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0906e-04 - val_loss: 6.7536e-04\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0840e-04 - val_loss: 6.7460e-04\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0787e-04 - val_loss: 6.7361e-04\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0732e-04 - val_loss: 6.7139e-04\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0666e-04 - val_loss: 6.6955e-04\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0595e-04 - val_loss: 6.6844e-04\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0547e-04 - val_loss: 6.6667e-04\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0475e-04 - val_loss: 6.6539e-04\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0412e-04 - val_loss: 6.6356e-04\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0350e-04 - val_loss: 6.6196e-04\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0281e-04 - val_loss: 6.6076e-04\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0212e-04 - val_loss: 6.5832e-04\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0135e-04 - val_loss: 6.5711e-04\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0067e-04 - val_loss: 6.5584e-04\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 4.0006e-04 - val_loss: 6.5536e-04\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9954e-04 - val_loss: 6.5459e-04\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9903e-04 - val_loss: 6.5344e-04\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9854e-04 - val_loss: 6.5222e-04\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9796e-04 - val_loss: 6.5134e-04\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9744e-04 - val_loss: 6.4909e-04\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9674e-04 - val_loss: 6.4778e-04\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9621e-04 - val_loss: 6.4568e-04\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9556e-04 - val_loss: 6.4483e-04\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9503e-04 - val_loss: 6.4330e-04\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9442e-04 - val_loss: 6.4337e-04\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9390e-04 - val_loss: 6.4172e-04\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9324e-04 - val_loss: 6.3984e-04\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9267e-04 - val_loss: 6.3677e-04\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9185e-04 - val_loss: 6.3473e-04\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9115e-04 - val_loss: 6.3315e-04\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9062e-04 - val_loss: 6.3168e-04\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.9004e-04 - val_loss: 6.2990e-04\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8939e-04 - val_loss: 6.2868e-04\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8863e-04 - val_loss: 6.2530e-04\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8788e-04 - val_loss: 6.2363e-04\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8736e-04 - val_loss: 6.2303e-04\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8688e-04 - val_loss: 6.2155e-04\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8634e-04 - val_loss: 6.1959e-04\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8565e-04 - val_loss: 6.1793e-04\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8498e-04 - val_loss: 6.1623e-04\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8417e-04 - val_loss: 6.1514e-04\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8376e-04 - val_loss: 6.1270e-04\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8285e-04 - val_loss: 6.1263e-04\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8238e-04 - val_loss: 6.1074e-04\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8180e-04 - val_loss: 6.0984e-04\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8120e-04 - val_loss: 6.0800e-04\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8061e-04 - val_loss: 6.0685e-04\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.8006e-04 - val_loss: 6.0496e-04\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7939e-04 - val_loss: 6.0273e-04\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7885e-04 - val_loss: 6.0156e-04\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7825e-04 - val_loss: 5.9922e-04\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7760e-04 - val_loss: 5.9655e-04\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7692e-04 - val_loss: 5.9320e-04\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7626e-04 - val_loss: 5.9231e-04\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7553e-04 - val_loss: 5.9205e-04\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7528e-04 - val_loss: 5.9088e-04\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7469e-04 - val_loss: 5.8939e-04\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7420e-04 - val_loss: 5.8898e-04\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7380e-04 - val_loss: 5.8701e-04\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7319e-04 - val_loss: 5.8585e-04\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7279e-04 - val_loss: 5.8431e-04\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7225e-04 - val_loss: 5.8310e-04\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7180e-04 - val_loss: 5.8332e-04\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7149e-04 - val_loss: 5.8252e-04\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7106e-04 - val_loss: 5.8118e-04\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7058e-04 - val_loss: 5.7978e-04\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.7011e-04 - val_loss: 5.7908e-04\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6974e-04 - val_loss: 5.7960e-04\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6955e-04 - val_loss: 5.7869e-04\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6913e-04 - val_loss: 5.7707e-04\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6871e-04 - val_loss: 5.7717e-04\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6851e-04 - val_loss: 5.7669e-04\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6794e-04 - val_loss: 5.7531e-04\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6754e-04 - val_loss: 5.7274e-04\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6699e-04 - val_loss: 5.7183e-04\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6651e-04 - val_loss: 5.7071e-04\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6613e-04 - val_loss: 5.7050e-04\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6568e-04 - val_loss: 5.6924e-04\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6518e-04 - val_loss: 5.6755e-04\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6500e-04 - val_loss: 5.6828e-04\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6476e-04 - val_loss: 5.6671e-04\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6437e-04 - val_loss: 5.6530e-04\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6399e-04 - val_loss: 5.6514e-04\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6369e-04 - val_loss: 5.6543e-04\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6346e-04 - val_loss: 5.6509e-04\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6315e-04 - val_loss: 5.6469e-04\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6285e-04 - val_loss: 5.6400e-04\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6243e-04 - val_loss: 5.6338e-04\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6217e-04 - val_loss: 5.6251e-04\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6165e-04 - val_loss: 5.6081e-04\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6118e-04 - val_loss: 5.5994e-04\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6096e-04 - val_loss: 5.5975e-04\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6058e-04 - val_loss: 5.5922e-04\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6028e-04 - val_loss: 5.5956e-04\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.6016e-04 - val_loss: 5.5856e-04\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5980e-04 - val_loss: 5.5790e-04\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5953e-04 - val_loss: 5.5706e-04\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5929e-04 - val_loss: 5.5577e-04\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5887e-04 - val_loss: 5.5474e-04\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5856e-04 - val_loss: 5.5296e-04\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5807e-04 - val_loss: 5.5159e-04\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5777e-04 - val_loss: 5.5105e-04\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5757e-04 - val_loss: 5.5103e-04\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5731e-04 - val_loss: 5.4926e-04\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5701e-04 - val_loss: 5.4856e-04\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5666e-04 - val_loss: 5.4788e-04\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5648e-04 - val_loss: 5.4569e-04\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5610e-04 - val_loss: 5.4473e-04\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5576e-04 - val_loss: 5.4388e-04\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5549e-04 - val_loss: 5.4346e-04\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5535e-04 - val_loss: 5.4294e-04\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5511e-04 - val_loss: 5.4280e-04\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5498e-04 - val_loss: 5.4173e-04\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5474e-04 - val_loss: 5.4132e-04\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 3.5462e-04 - val_loss: 5.3991e-04\n",
      "0 2\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 1.1441 - val_loss: 1.1035\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.9561 - val_loss: 0.9828\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.8072 - val_loss: 0.7819\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6153 - val_loss: 0.5591\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4513 - val_loss: 0.3741\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3212 - val_loss: 0.2696\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2385 - val_loss: 0.2228\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1974 - val_loss: 0.1960\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1695 - val_loss: 0.1755\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1495 - val_loss: 0.1589\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1324 - val_loss: 0.1451\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1197 - val_loss: 0.1351\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1111 - val_loss: 0.1274\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1046 - val_loss: 0.1209\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0994 - val_loss: 0.1156\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0955 - val_loss: 0.1112\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0923 - val_loss: 0.1072\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0897 - val_loss: 0.1038\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0875 - val_loss: 0.1008\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0857 - val_loss: 0.0983\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0842 - val_loss: 0.0962\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0828 - val_loss: 0.0944\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0816 - val_loss: 0.0928\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0795 - val_loss: 0.0901\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0777 - val_loss: 0.0879\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0769 - val_loss: 0.0869\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0761 - val_loss: 0.0860\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0755 - val_loss: 0.0852\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0748 - val_loss: 0.0844\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0742 - val_loss: 0.0837\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0737 - val_loss: 0.0830\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0732 - val_loss: 0.0824\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0727 - val_loss: 0.0818\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0722 - val_loss: 0.0812\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0718 - val_loss: 0.0806\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0713 - val_loss: 0.0801\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0709 - val_loss: 0.0796\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0705 - val_loss: 0.0792\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0701 - val_loss: 0.0787\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0697 - val_loss: 0.0782\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0694 - val_loss: 0.0777\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0691 - val_loss: 0.0772\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0687 - val_loss: 0.0768\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0684 - val_loss: 0.0763\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0680 - val_loss: 0.0759\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0677 - val_loss: 0.0755\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0675 - val_loss: 0.0751\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0672 - val_loss: 0.0748\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0669 - val_loss: 0.0745\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0666 - val_loss: 0.0741\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0663 - val_loss: 0.0738\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0661 - val_loss: 0.0736\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0658 - val_loss: 0.0733\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0656 - val_loss: 0.0730\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0653 - val_loss: 0.0728\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0650 - val_loss: 0.0726\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0647 - val_loss: 0.0724\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0643 - val_loss: 0.0721\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0640 - val_loss: 0.0719\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0637 - val_loss: 0.0716\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0714\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0711\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0709\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0624 - val_loss: 0.0706\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0704\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0702\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0698\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0612 - val_loss: 0.0695\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0693\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0690\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0605 - val_loss: 0.0688\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0602 - val_loss: 0.0685\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0599 - val_loss: 0.0683\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0597 - val_loss: 0.0681\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0595 - val_loss: 0.0678\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0592 - val_loss: 0.0677\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0590 - val_loss: 0.0675\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0587 - val_loss: 0.0674\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0585 - val_loss: 0.0672\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0583 - val_loss: 0.0670\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0580 - val_loss: 0.0669\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0578 - val_loss: 0.0667\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0576 - val_loss: 0.0666\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0573 - val_loss: 0.0664\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0571 - val_loss: 0.0662\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0569 - val_loss: 0.0660\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0567 - val_loss: 0.0659\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0564 - val_loss: 0.0657\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0562 - val_loss: 0.0656\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0559 - val_loss: 0.0654\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0557 - val_loss: 0.0652\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0554 - val_loss: 0.0649\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0552 - val_loss: 0.0647\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0549 - val_loss: 0.0645\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0547 - val_loss: 0.0643\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0545 - val_loss: 0.0641\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0543 - val_loss: 0.0639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0540 - val_loss: 0.0636\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0538 - val_loss: 0.0633\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0535 - val_loss: 0.0631\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0533 - val_loss: 0.0628\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0530 - val_loss: 0.0627\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0527 - val_loss: 0.0625\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0524 - val_loss: 0.0623\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0522 - val_loss: 0.0621\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0519 - val_loss: 0.0619\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0516 - val_loss: 0.0618\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0514 - val_loss: 0.0617\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0512 - val_loss: 0.0616\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0509 - val_loss: 0.0614\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0507 - val_loss: 0.0613\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0505 - val_loss: 0.0612\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0503 - val_loss: 0.0611\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0501 - val_loss: 0.0609\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0499 - val_loss: 0.0608\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0498 - val_loss: 0.0606\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0496 - val_loss: 0.0605\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0494 - val_loss: 0.0604\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0493 - val_loss: 0.0602\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0491 - val_loss: 0.0601\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0490 - val_loss: 0.0600\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0488 - val_loss: 0.0598\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0487 - val_loss: 0.0597\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0486 - val_loss: 0.0596\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0484 - val_loss: 0.0595\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0482 - val_loss: 0.0594\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0481 - val_loss: 0.0593\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0479 - val_loss: 0.0592\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0478 - val_loss: 0.0591\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0476 - val_loss: 0.0590\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0475 - val_loss: 0.0590\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0473 - val_loss: 0.0589\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0472 - val_loss: 0.0588\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0470 - val_loss: 0.0587\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0468 - val_loss: 0.0586\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0466 - val_loss: 0.0585\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0465 - val_loss: 0.0584\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0463 - val_loss: 0.0583\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0462 - val_loss: 0.0582\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0460 - val_loss: 0.0581\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0458 - val_loss: 0.0579\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0456 - val_loss: 0.0578\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0455 - val_loss: 0.0577\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0453 - val_loss: 0.0576\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0452 - val_loss: 0.0574\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0451 - val_loss: 0.0573\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0449 - val_loss: 0.0572\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0448 - val_loss: 0.0571\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0447 - val_loss: 0.0569\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0445 - val_loss: 0.0568\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0444 - val_loss: 0.0566\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0443 - val_loss: 0.0565\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0442 - val_loss: 0.0563\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0440 - val_loss: 0.0561\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0439 - val_loss: 0.0560\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0438 - val_loss: 0.0558\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0437 - val_loss: 0.0556\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0436 - val_loss: 0.0555\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0435 - val_loss: 0.0553\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0434 - val_loss: 0.0552\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0433 - val_loss: 0.0551\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0431 - val_loss: 0.0549\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0431 - val_loss: 0.0548\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0430 - val_loss: 0.0547\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0429 - val_loss: 0.0545\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0428 - val_loss: 0.0544\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0427 - val_loss: 0.0542\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 4us/sample - loss: 0.0426 - val_loss: 0.0541\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 4us/sample - loss: 0.0425 - val_loss: 0.0540\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0424 - val_loss: 0.0539\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0423 - val_loss: 0.0537\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0422 - val_loss: 0.0536\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0422 - val_loss: 0.0535\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0421 - val_loss: 0.0534\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0420 - val_loss: 0.0533\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0419 - val_loss: 0.0533\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0419 - val_loss: 0.0532\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0418 - val_loss: 0.0531\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0417 - val_loss: 0.0530\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0417 - val_loss: 0.0529\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0416 - val_loss: 0.0528\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0415 - val_loss: 0.0528\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0415 - val_loss: 0.0527\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0414 - val_loss: 0.0526\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0413 - val_loss: 0.0526\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0413 - val_loss: 0.0526\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0412 - val_loss: 0.0525\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0412 - val_loss: 0.0524\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0411 - val_loss: 0.0523\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0411 - val_loss: 0.0523\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0410 - val_loss: 0.0522\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0410 - val_loss: 0.0522\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0409 - val_loss: 0.0521\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0408 - val_loss: 0.0521\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0408 - val_loss: 0.0520\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0407 - val_loss: 0.0520\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0407 - val_loss: 0.0519\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0406 - val_loss: 0.0519\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0406 - val_loss: 0.0519\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0405 - val_loss: 0.0518\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0405 - val_loss: 0.0518\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0404 - val_loss: 0.0518\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0404 - val_loss: 0.0517\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0403 - val_loss: 0.0517\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0403 - val_loss: 0.0516\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0402 - val_loss: 0.0516\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0402 - val_loss: 0.0515\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0401 - val_loss: 0.0515\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0401 - val_loss: 0.0515\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0401 - val_loss: 0.0514\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0400 - val_loss: 0.0514\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0399 - val_loss: 0.0513\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0399 - val_loss: 0.0513\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0399 - val_loss: 0.0513\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0398 - val_loss: 0.0512\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0398 - val_loss: 0.0512\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0397 - val_loss: 0.0512\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0397 - val_loss: 0.0511\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0396 - val_loss: 0.0511\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0396 - val_loss: 0.0511\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0395 - val_loss: 0.0511\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0395 - val_loss: 0.0510\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0394 - val_loss: 0.0510\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0394 - val_loss: 0.0510\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0394 - val_loss: 0.0509\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0393 - val_loss: 0.0509\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0393 - val_loss: 0.0508\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0392 - val_loss: 0.0508\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0392 - val_loss: 0.0508\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0391 - val_loss: 0.0507\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0391 - val_loss: 0.0507\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0390 - val_loss: 0.0507\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0390 - val_loss: 0.0506\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0389 - val_loss: 0.0506\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0389 - val_loss: 0.0506\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0389 - val_loss: 0.0506\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0388 - val_loss: 0.0506\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0388 - val_loss: 0.0505\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0387 - val_loss: 0.0505\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0387 - val_loss: 0.0505\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0386 - val_loss: 0.0505\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0386 - val_loss: 0.0505\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0386 - val_loss: 0.0505\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0385 - val_loss: 0.0505\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0385 - val_loss: 0.0504\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0384 - val_loss: 0.0504\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0384 - val_loss: 0.0504\n",
      "Epoch 250/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0384 - val_loss: 0.0504\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0383 - val_loss: 0.0503\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0383 - val_loss: 0.0503\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0382 - val_loss: 0.0503\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0382 - val_loss: 0.0503\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0382 - val_loss: 0.0502\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0381 - val_loss: 0.0502\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0381 - val_loss: 0.0502\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0381 - val_loss: 0.0502\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0380 - val_loss: 0.0502\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0380 - val_loss: 0.0502\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0380 - val_loss: 0.0502\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0379 - val_loss: 0.0502\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0379 - val_loss: 0.0502\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0378 - val_loss: 0.0502\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0378 - val_loss: 0.0501\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0377 - val_loss: 0.0501\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0377 - val_loss: 0.0501\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0377 - val_loss: 0.0501\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0376 - val_loss: 0.0500\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0376 - val_loss: 0.0500\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0376 - val_loss: 0.0500\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0376 - val_loss: 0.0500\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0375 - val_loss: 0.0500\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0375 - val_loss: 0.0500\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0375 - val_loss: 0.0499\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0374 - val_loss: 0.0499\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0374 - val_loss: 0.0499\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0374 - val_loss: 0.0499\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0373 - val_loss: 0.0498\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0373 - val_loss: 0.0498\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0373 - val_loss: 0.0498\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0498\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0497\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0497\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0497\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0497\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0371 - val_loss: 0.0497\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0371 - val_loss: 0.0497\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0371 - val_loss: 0.0497\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0370 - val_loss: 0.0496\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0370 - val_loss: 0.0497\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0370 - val_loss: 0.0496\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0370 - val_loss: 0.0496\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0369 - val_loss: 0.0496\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0369 - val_loss: 0.0496\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0369 - val_loss: 0.0496\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0369 - val_loss: 0.0496\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0368 - val_loss: 0.0496\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0368 - val_loss: 0.0495\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0368 - val_loss: 0.0495\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0367 - val_loss: 0.0495\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0367 - val_loss: 0.0495\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0367 - val_loss: 0.0494\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0366 - val_loss: 0.0494\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0366 - val_loss: 0.0493\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0366 - val_loss: 0.0493\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0365 - val_loss: 0.0492\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0365 - val_loss: 0.0492\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0365 - val_loss: 0.0491\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0364 - val_loss: 0.0491\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0364 - val_loss: 0.0490\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0364 - val_loss: 0.0490\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0489\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0489\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0489\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0488\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0362 - val_loss: 0.0488\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0362 - val_loss: 0.0487\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0362 - val_loss: 0.0487\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0361 - val_loss: 0.0487\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0361 - val_loss: 0.0486\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0361 - val_loss: 0.0486\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0361 - val_loss: 0.0485\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0360 - val_loss: 0.0485\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0360 - val_loss: 0.0485\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0360 - val_loss: 0.0484\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0359 - val_loss: 0.0484\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0359 - val_loss: 0.0484\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0359 - val_loss: 0.0483\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0483\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0482\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0482\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0482\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0481\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0357 - val_loss: 0.0481\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0357 - val_loss: 0.0481\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0357 - val_loss: 0.0480\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0480\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0480\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0480\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0479\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0479\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0479\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0479\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0478\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0478\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0354 - val_loss: 0.0478\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0354 - val_loss: 0.0478\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0354 - val_loss: 0.0477\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0477\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0477\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0477\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0476\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0476\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0475\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0476\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0475\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - ETA: 0s - loss: 0.035 - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0475\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0351 - val_loss: 0.0475\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0351 - val_loss: 0.0475\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0351 - val_loss: 0.0474\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0351 - val_loss: 0.0474\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0474\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0474\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0473\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0473\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0473\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0473\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0473\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0473\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0473\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0473\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0473\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0472\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0473\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0472\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0473\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0472\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0472\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0472\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0472\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0472\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0472\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0472\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0471\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0471\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0471\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0471\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0472\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0471\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0471\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0471\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0470\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0471\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0470\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0471\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0470\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0471\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0470\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0470\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0471\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0471\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0472\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0471\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0471\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0471\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0471\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0471\n",
      "Epoch 444/500\n",
      "25088/34560 [====================>.........] - ETA: 0s - loss: 0.0341Restoring model weights from the end of the best epoch\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0471\n",
      "Epoch 00444: early stopping\n",
      "1 0\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 1s 19us/sample - loss: 2.6933 - val_loss: 1.3294\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 1.1728 - val_loss: 0.8808\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.8917 - val_loss: 0.7504\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7851 - val_loss: 0.6855\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7314 - val_loss: 0.6488\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7008 - val_loss: 0.6229\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6744 - val_loss: 0.5943\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6441 - val_loss: 0.5638\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6128 - val_loss: 0.5345\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5821 - val_loss: 0.5069\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5527 - val_loss: 0.4812\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5245 - val_loss: 0.4563\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4955 - val_loss: 0.4315\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4664 - val_loss: 0.4073\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4400 - val_loss: 0.3847\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4166 - val_loss: 0.3637\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3955 - val_loss: 0.3444\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3761 - val_loss: 0.3265\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3582 - val_loss: 0.3097\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3415 - val_loss: 0.2940\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3258 - val_loss: 0.2792\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3110 - val_loss: 0.2652\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2972 - val_loss: 0.2521\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2841 - val_loss: 0.2397\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2718 - val_loss: 0.2282\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2603 - val_loss: 0.2172\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2494 - val_loss: 0.2070\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2390 - val_loss: 0.1973\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2289 - val_loss: 0.1882\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2190 - val_loss: 0.1795\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2096 - val_loss: 0.1714\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2003 - val_loss: 0.1636\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1914 - val_loss: 0.1562\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1831 - val_loss: 0.1492\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1754 - val_loss: 0.1427\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1682 - val_loss: 0.1364\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1615 - val_loss: 0.1308\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1553 - val_loss: 0.1253\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1494 - val_loss: 0.1202\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1439 - val_loss: 0.1156\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1388 - val_loss: 0.1111\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1339 - val_loss: 0.1069\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1293 - val_loss: 0.1030\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1250 - val_loss: 0.0993\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1209 - val_loss: 0.0957\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1169 - val_loss: 0.0923\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1131 - val_loss: 0.0890\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1095 - val_loss: 0.0857\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1060 - val_loss: 0.0826\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1027 - val_loss: 0.0796\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0996 - val_loss: 0.0767\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0965 - val_loss: 0.0740\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0936 - val_loss: 0.0713\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0907 - val_loss: 0.0687\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0880 - val_loss: 0.0662\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0853 - val_loss: 0.0639\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0828 - val_loss: 0.0616\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0802 - val_loss: 0.0594\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0778 - val_loss: 0.0573\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0754 - val_loss: 0.0552\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0729 - val_loss: 0.0533\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0706 - val_loss: 0.0513\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0684 - val_loss: 0.0496\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0661 - val_loss: 0.0481\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0638 - val_loss: 0.0462\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0445\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0592 - val_loss: 0.0425\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0570 - val_loss: 0.0406\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0549 - val_loss: 0.0388\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0528 - val_loss: 0.0371\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0510 - val_loss: 0.0356\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0491 - val_loss: 0.0340\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0474 - val_loss: 0.0326\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0456 - val_loss: 0.0312\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0440 - val_loss: 0.0299\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0424 - val_loss: 0.0287\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0408 - val_loss: 0.0274\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0393 - val_loss: 0.0263\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0378 - val_loss: 0.0252\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0241\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0231\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0333 - val_loss: 0.0222\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0214\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0206\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0200\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0193\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0187\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0257 - val_loss: 0.0181\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0246 - val_loss: 0.0175\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0236 - val_loss: 0.0170\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0226 - val_loss: 0.0165\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0217 - val_loss: 0.0161\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0209 - val_loss: 0.0158\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0202 - val_loss: 0.0155\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0195 - val_loss: 0.0152\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0189 - val_loss: 0.0149\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0183 - val_loss: 0.0147\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0178 - val_loss: 0.0145\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0143\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0141\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0140\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0138\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0137\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0154 - val_loss: 0.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0152 - val_loss: 0.0134\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0149 - val_loss: 0.0133\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0144 - val_loss: 0.0131\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0142 - val_loss: 0.0130\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0130 - val_loss: 0.0124\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0118 - val_loss: 0.0119\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 180/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0092 - val_loss: 0.0106\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 255/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0106\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0105\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 330/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0082 - val_loss: 0.0099\n",
      "1 1\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 0.9304 - val_loss: 0.8130\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6892 - val_loss: 0.5272\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4207 - val_loss: 0.3106\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2684 - val_loss: 0.2077\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1864 - val_loss: 0.1525\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1363 - val_loss: 0.1252\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1154 - val_loss: 0.1132\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1065 - val_loss: 0.1053\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1003 - val_loss: 0.0989\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0953 - val_loss: 0.0935\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0907 - val_loss: 0.0890\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0866 - val_loss: 0.0851\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0831 - val_loss: 0.0821\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0803 - val_loss: 0.0796\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0777 - val_loss: 0.0775\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0755 - val_loss: 0.0755\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0734 - val_loss: 0.0736\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0714 - val_loss: 0.0719\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0695 - val_loss: 0.0703\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0678 - val_loss: 0.0687\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0662 - val_loss: 0.0673\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0648 - val_loss: 0.0660\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0634 - val_loss: 0.0647\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0622 - val_loss: 0.0635\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0624\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0599 - val_loss: 0.0612\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0590 - val_loss: 0.0602\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0581 - val_loss: 0.0591\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0572 - val_loss: 0.0582\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0564 - val_loss: 0.0574\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0557 - val_loss: 0.0565\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0549 - val_loss: 0.0558\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0542 - val_loss: 0.0551\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0535 - val_loss: 0.0544\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0529 - val_loss: 0.0537\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0524 - val_loss: 0.0532\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0518 - val_loss: 0.0526\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0512 - val_loss: 0.0521\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0507 - val_loss: 0.0516\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0502 - val_loss: 0.0511\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0497 - val_loss: 0.0506\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0493 - val_loss: 0.0502\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0489 - val_loss: 0.0497\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0485 - val_loss: 0.0493\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0481 - val_loss: 0.0489\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0477 - val_loss: 0.0485\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0473 - val_loss: 0.0481\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0469 - val_loss: 0.0478\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0466 - val_loss: 0.0474\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0462 - val_loss: 0.0471\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0459 - val_loss: 0.0468\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0456 - val_loss: 0.0464\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0453 - val_loss: 0.0461\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0450 - val_loss: 0.0458\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0447 - val_loss: 0.0456\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0445 - val_loss: 0.0453\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0442 - val_loss: 0.0450\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0439 - val_loss: 0.0448\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0437 - val_loss: 0.0446\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0434 - val_loss: 0.0443\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0431 - val_loss: 0.0441\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0429 - val_loss: 0.0438\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0427 - val_loss: 0.0436\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0425 - val_loss: 0.0434\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0422 - val_loss: 0.0431\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0420 - val_loss: 0.0429\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0418 - val_loss: 0.0427\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0415 - val_loss: 0.0424\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0412 - val_loss: 0.0421\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0410 - val_loss: 0.0418\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0407 - val_loss: 0.0416\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0405 - val_loss: 0.0414\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0403 - val_loss: 0.0411\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0401 - val_loss: 0.0410\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0399 - val_loss: 0.0408\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0397 - val_loss: 0.0406\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0396 - val_loss: 0.0405\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0394 - val_loss: 0.0403\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0393 - val_loss: 0.0402\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0391 - val_loss: 0.0401\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0390 - val_loss: 0.0399\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0389 - val_loss: 0.0398\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0387 - val_loss: 0.0397\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0386 - val_loss: 0.0395\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0385 - val_loss: 0.0394\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0383 - val_loss: 0.0393\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0382 - val_loss: 0.0391\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0381 - val_loss: 0.0390\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0380 - val_loss: 0.0389\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0379 - val_loss: 0.0388\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0378 - val_loss: 0.0387\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0377 - val_loss: 0.0386\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0376 - val_loss: 0.0385\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0375 - val_loss: 0.0384\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0373 - val_loss: 0.0383\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0382\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0371 - val_loss: 0.0381\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0370 - val_loss: 0.0380\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0369 - val_loss: 0.0379\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0368 - val_loss: 0.0378\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0367 - val_loss: 0.0377\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0366 - val_loss: 0.0377\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0365 - val_loss: 0.0376\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0364 - val_loss: 0.0375\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0374\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0362 - val_loss: 0.0373\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0361 - val_loss: 0.0372\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0360 - val_loss: 0.0371\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0359 - val_loss: 0.0370\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0359 - val_loss: 0.0369\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0368\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0357 - val_loss: 0.0367\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0366\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0366\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0354 - val_loss: 0.0365\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0364\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0364\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0351 - val_loss: 0.0363\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0362\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0362\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0361\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0361\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0360\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0360\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0359\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0359\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0358\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0358\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0357\n",
      "Epoch 130/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0357\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0356\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0356\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0355\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0355\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0339 - val_loss: 0.0354\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0338 - val_loss: 0.0354\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0338 - val_loss: 0.0354\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0337 - val_loss: 0.0353\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0337 - val_loss: 0.0353\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0336 - val_loss: 0.0352\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0335 - val_loss: 0.0352\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0335 - val_loss: 0.0351\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0334 - val_loss: 0.0351\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0334 - val_loss: 0.0350\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0333 - val_loss: 0.0350\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0333 - val_loss: 0.0349\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0332 - val_loss: 0.0349\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0332 - val_loss: 0.0348\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0331 - val_loss: 0.0348\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0331 - val_loss: 0.0347\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0330 - val_loss: 0.0347\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0330 - val_loss: 0.0347\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0329 - val_loss: 0.0347\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0329 - val_loss: 0.0346\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0328 - val_loss: 0.0346\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0328 - val_loss: 0.0345\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0327 - val_loss: 0.0345\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0327 - val_loss: 0.0344\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0326 - val_loss: 0.0344\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0326 - val_loss: 0.0344\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0325 - val_loss: 0.0343\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0325 - val_loss: 0.0343\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0325 - val_loss: 0.0343\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0324 - val_loss: 0.0342\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0324 - val_loss: 0.0342\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0341\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0341\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0341\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0322 - val_loss: 0.0341\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0322 - val_loss: 0.0340\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0321 - val_loss: 0.0340\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0321 - val_loss: 0.0339\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0339\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0339\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0338\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0319 - val_loss: 0.0338\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0319 - val_loss: 0.0338\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0318 - val_loss: 0.0337\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0318 - val_loss: 0.0337\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0337\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0337\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0337\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0336\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0336\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0335\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0335\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0335\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0334\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0334\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0333\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0333\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0333\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0332\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0332\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0331\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0331\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0331\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0330\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0330\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0329\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0329\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0329\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0328\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0328\n",
      "Epoch 205/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0327\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0328\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0327\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0327\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0326\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0326\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0326\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0325\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0325\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0325\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0325\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0324\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0324\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0324\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0323\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0323\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0323\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0322\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0322\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0321\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0321\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0321\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0321\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0320\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0320\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0320\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0319\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0319\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0319\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0318\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0318\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0318\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0318\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0317\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0317\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0317\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0316\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0316\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0316\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0315\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0315\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0315\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0315\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0314\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0314\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0314\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0313\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0313\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0313\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0312\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0312\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0312\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0312\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0311\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0310\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0310\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0310\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0309\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0308\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0308\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0308\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0308\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0307\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0307\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0307\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0307\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0306\n",
      "Epoch 280/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0306\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0306\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0306\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0306\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0305\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0305\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0305\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0305\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0305\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0304\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0304\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0304\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0304\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0304\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0304\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0303\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0303\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0303\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0303\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0303\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0303\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0302\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0302\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0302\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0302\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0300\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0300\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0300\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0300\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0300\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0300\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 5us/sample - loss: 0.0281 - val_loss: 0.0298\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0298\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0296\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0296\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0296\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0296\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0294\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0294\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0294\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0293\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0292\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0275 - val_loss: 0.0292\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0291\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0291\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0273 - val_loss: 0.0291\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0291\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 430/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0271 - val_loss: 0.0290\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0290\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0289\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0289\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0289\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0288\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0288\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0269 - val_loss: 0.0288\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0287\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0287\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0288\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0287\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0266 - val_loss: 0.0286\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0266 - val_loss: 0.0286\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0266 - val_loss: 0.0286\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0266 - val_loss: 0.0286\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0266 - val_loss: 0.0286\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0266 - val_loss: 0.0286\n",
      "1 2\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 1.3775 - val_loss: 1.1966\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 1.0230 - val_loss: 1.0221\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.8746 - val_loss: 0.9004\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7461 - val_loss: 0.7411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5945 - val_loss: 0.5474\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4607 - val_loss: 0.4135\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3812 - val_loss: 0.3477\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3359 - val_loss: 0.3124\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3079 - val_loss: 0.2897\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2895 - val_loss: 0.2748\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2771 - val_loss: 0.2646\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2679 - val_loss: 0.2572\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2609 - val_loss: 0.2515\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2548 - val_loss: 0.2468\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2494 - val_loss: 0.2428\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2446 - val_loss: 0.2392\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2402 - val_loss: 0.2353\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2361 - val_loss: 0.2321\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2327 - val_loss: 0.2289\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2298 - val_loss: 0.2262\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2274 - val_loss: 0.2240\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2253 - val_loss: 0.2223\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2235 - val_loss: 0.2208\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2217 - val_loss: 0.2193\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2201 - val_loss: 0.2179\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2184 - val_loss: 0.2165\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2168 - val_loss: 0.2152\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2154 - val_loss: 0.2141\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2141 - val_loss: 0.2130\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2127 - val_loss: 0.2119\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2115 - val_loss: 0.2110\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2104 - val_loss: 0.2100\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2093 - val_loss: 0.2091\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2083 - val_loss: 0.2083\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2074 - val_loss: 0.2075\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2064 - val_loss: 0.2068\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2056 - val_loss: 0.2060\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2047 - val_loss: 0.2053\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2039 - val_loss: 0.2046\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2032 - val_loss: 0.2040\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2024 - val_loss: 0.2034\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2017 - val_loss: 0.2028\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2010 - val_loss: 0.2023\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2003 - val_loss: 0.2018\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1997 - val_loss: 0.2014\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1990 - val_loss: 0.2009\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1984 - val_loss: 0.2004\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1978 - val_loss: 0.2000\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1972 - val_loss: 0.1994\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1966 - val_loss: 0.1991\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1960 - val_loss: 0.1986\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1955 - val_loss: 0.1984\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1949 - val_loss: 0.1980\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1943 - val_loss: 0.1977\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1937 - val_loss: 0.1975\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1931 - val_loss: 0.1972\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1926 - val_loss: 0.1970\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1920 - val_loss: 0.1968\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1914 - val_loss: 0.1966\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1908 - val_loss: 0.1963\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1901 - val_loss: 0.1960\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1894 - val_loss: 0.1957\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1888 - val_loss: 0.1954\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1882 - val_loss: 0.1951\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1875 - val_loss: 0.1948\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1868 - val_loss: 0.1945\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1862 - val_loss: 0.1943\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1855 - val_loss: 0.1940\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1848 - val_loss: 0.1937\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1842 - val_loss: 0.1933\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1835 - val_loss: 0.1928\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1829 - val_loss: 0.1925\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1823 - val_loss: 0.1921\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1817 - val_loss: 0.1918\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1811 - val_loss: 0.1916\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1805 - val_loss: 0.1914\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1800 - val_loss: 0.1911\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1794 - val_loss: 0.1908\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1789 - val_loss: 0.1906\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1784 - val_loss: 0.1903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1779 - val_loss: 0.1901\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1774 - val_loss: 0.1899\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1769 - val_loss: 0.1897\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1764 - val_loss: 0.1894\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1760 - val_loss: 0.1891\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1755 - val_loss: 0.1889\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1751 - val_loss: 0.1885\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1746 - val_loss: 0.1882\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1741 - val_loss: 0.1878\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1736 - val_loss: 0.1874\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1731 - val_loss: 0.1871\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1725 - val_loss: 0.1869\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1720 - val_loss: 0.1867\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1715 - val_loss: 0.1863\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1709 - val_loss: 0.1861\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1703 - val_loss: 0.1859\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1697 - val_loss: 0.1857\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1691 - val_loss: 0.1854\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1685 - val_loss: 0.1851\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1680 - val_loss: 0.1848\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1674 - val_loss: 0.1847\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1668 - val_loss: 0.1844\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1663 - val_loss: 0.1842\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1658 - val_loss: 0.1842\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1652 - val_loss: 0.1840\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1647 - val_loss: 0.1839\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1641 - val_loss: 0.1838\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1636 - val_loss: 0.1836\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1632 - val_loss: 0.1835\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1627 - val_loss: 0.1834\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1623 - val_loss: 0.1833\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1618 - val_loss: 0.1831\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - ETA: 0s - loss: 0.163 - 0s 3us/sample - loss: 0.1614 - val_loss: 0.1829\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1610 - val_loss: 0.1827\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1605 - val_loss: 0.1825\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1601 - val_loss: 0.1823\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1596 - val_loss: 0.1821\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1592 - val_loss: 0.1818\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1588 - val_loss: 0.1816\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1584 - val_loss: 0.1814\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1580 - val_loss: 0.1812\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1577 - val_loss: 0.1810\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1572 - val_loss: 0.1807\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1569 - val_loss: 0.1806\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1565 - val_loss: 0.1804\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1561 - val_loss: 0.1803\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1558 - val_loss: 0.1801\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1554 - val_loss: 0.1799\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1551 - val_loss: 0.1798\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1548 - val_loss: 0.1795\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1544 - val_loss: 0.1793\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1541 - val_loss: 0.1791\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1538 - val_loss: 0.1790\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1535 - val_loss: 0.1789\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1531 - val_loss: 0.1787\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1529 - val_loss: 0.1786\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1526 - val_loss: 0.1785\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1523 - val_loss: 0.1783\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1520 - val_loss: 0.1782\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1518 - val_loss: 0.1781\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1515 - val_loss: 0.1780\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1512 - val_loss: 0.1779\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1510 - val_loss: 0.1778\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1507 - val_loss: 0.1777\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1504 - val_loss: 0.1775\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1501 - val_loss: 0.1774\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1498 - val_loss: 0.1772\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1493 - val_loss: 0.1768\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1488 - val_loss: 0.1765\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1484 - val_loss: 0.1762\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1479 - val_loss: 0.1758\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1474 - val_loss: 0.1753\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1470 - val_loss: 0.1748\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1465 - val_loss: 0.1743\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1460 - val_loss: 0.1738\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1455 - val_loss: 0.1733\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1450 - val_loss: 0.1729\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1444 - val_loss: 0.1724\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1439 - val_loss: 0.1720\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1433 - val_loss: 0.1715\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1428 - val_loss: 0.1711\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1423 - val_loss: 0.1708\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1419 - val_loss: 0.1704\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1414 - val_loss: 0.1702\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1410 - val_loss: 0.1700\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1405 - val_loss: 0.1698\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1401 - val_loss: 0.1697\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1398 - val_loss: 0.1697\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1394 - val_loss: 0.1697\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1391 - val_loss: 0.1698\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1387 - val_loss: 0.1697\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1384 - val_loss: 0.1698\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1381 - val_loss: 0.1698\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1378 - val_loss: 0.1697\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1376 - val_loss: 0.1697\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1373 - val_loss: 0.1696\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1371 - val_loss: 0.1696\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1368 - val_loss: 0.1696\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1367 - val_loss: 0.1696\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1364 - val_loss: 0.1695\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1362 - val_loss: 0.1694\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1360 - val_loss: 0.1693\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1359 - val_loss: 0.1693\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1356 - val_loss: 0.1693\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1355 - val_loss: 0.1693\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1354 - val_loss: 0.1694\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1351 - val_loss: 0.1693\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1350 - val_loss: 0.1693\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1348 - val_loss: 0.1692\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1346 - val_loss: 0.1693\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1345 - val_loss: 0.1693\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1343 - val_loss: 0.1693\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1341 - val_loss: 0.1693\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1340 - val_loss: 0.1692\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1337 - val_loss: 0.1691\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1336 - val_loss: 0.1690\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1335 - val_loss: 0.1689\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1333 - val_loss: 0.1688\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1331 - val_loss: 0.1688\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1330 - val_loss: 0.1687\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1329 - val_loss: 0.1687\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1327 - val_loss: 0.1686\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1325 - val_loss: 0.1686\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1324 - val_loss: 0.1686\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1322 - val_loss: 0.1685\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1321 - val_loss: 0.1685\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1320 - val_loss: 0.1684\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1318 - val_loss: 0.1684\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1317 - val_loss: 0.1683\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1315 - val_loss: 0.1683\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1314 - val_loss: 0.1682\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1313 - val_loss: 0.1682\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1312 - val_loss: 0.1681\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1310 - val_loss: 0.1681\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1309 - val_loss: 0.1680\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1307 - val_loss: 0.1679\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1306 - val_loss: 0.1678\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1305 - val_loss: 0.1678\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1304 - val_loss: 0.1677\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1303 - val_loss: 0.1677\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1302 - val_loss: 0.1677\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1301 - val_loss: 0.1676\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1299 - val_loss: 0.1676\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1298 - val_loss: 0.1675\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1297 - val_loss: 0.1675\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1296 - val_loss: 0.1674\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1295 - val_loss: 0.1673\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1294 - val_loss: 0.1672\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1293 - val_loss: 0.1671\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1292 - val_loss: 0.1671\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1291 - val_loss: 0.1670\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1290 - val_loss: 0.1670\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1289 - val_loss: 0.1668\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1288 - val_loss: 0.1666\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1287 - val_loss: 0.1666\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1286 - val_loss: 0.1665\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1285 - val_loss: 0.1664\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1284 - val_loss: 0.1664\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1283 - val_loss: 0.1663\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1282 - val_loss: 0.1662\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1282 - val_loss: 0.1662\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1281 - val_loss: 0.1661\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1280 - val_loss: 0.1660\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1279 - val_loss: 0.1659\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1278 - val_loss: 0.1658\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1277 - val_loss: 0.1658\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1276 - val_loss: 0.1657\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1275 - val_loss: 0.1655\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1274 - val_loss: 0.1655\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1273 - val_loss: 0.1654\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1272 - val_loss: 0.1653\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1271 - val_loss: 0.1652\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1271 - val_loss: 0.1650\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1269 - val_loss: 0.1648\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1269 - val_loss: 0.1648\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1268 - val_loss: 0.1646\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1267 - val_loss: 0.1646\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1266 - val_loss: 0.1644\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1265 - val_loss: 0.1642\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1264 - val_loss: 0.1642\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1263 - val_loss: 0.1641\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1262 - val_loss: 0.1639\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1261 - val_loss: 0.1638\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1260 - val_loss: 0.1636\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1259 - val_loss: 0.1634\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1258 - val_loss: 0.1633\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1257 - val_loss: 0.1632\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1256 - val_loss: 0.1630\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1255 - val_loss: 0.1629\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1254 - val_loss: 0.1627\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1252 - val_loss: 0.1624\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1251 - val_loss: 0.1622\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1250 - val_loss: 0.1620\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1249 - val_loss: 0.1619\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1248 - val_loss: 0.1617\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1247 - val_loss: 0.1616\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1246 - val_loss: 0.1615\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1245 - val_loss: 0.1614\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1244 - val_loss: 0.1614\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1243 - val_loss: 0.1613\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1242 - val_loss: 0.1611\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1242 - val_loss: 0.1610\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1241 - val_loss: 0.1609\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1240 - val_loss: 0.1607\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1239 - val_loss: 0.1606\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1238 - val_loss: 0.1605\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1237 - val_loss: 0.1604\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1236 - val_loss: 0.1603\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1235 - val_loss: 0.1601\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1234 - val_loss: 0.1601\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1234 - val_loss: 0.1601\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1233 - val_loss: 0.1600\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1232 - val_loss: 0.1599\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1231 - val_loss: 0.1598\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1231 - val_loss: 0.1596\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1230 - val_loss: 0.1596\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1229 - val_loss: 0.1596\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1228 - val_loss: 0.1595\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1228 - val_loss: 0.1594\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1227 - val_loss: 0.1593\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1226 - val_loss: 0.1592\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1225 - val_loss: 0.1592\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1225 - val_loss: 0.1591\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1224 - val_loss: 0.1591\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1223 - val_loss: 0.1589\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1222 - val_loss: 0.1588\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1221 - val_loss: 0.1587\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1221 - val_loss: 0.1587\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1220 - val_loss: 0.1586\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1219 - val_loss: 0.1585\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1218 - val_loss: 0.1584\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1218 - val_loss: 0.1584\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1217 - val_loss: 0.1583\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1216 - val_loss: 0.1583\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1215 - val_loss: 0.1582\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1214 - val_loss: 0.1581\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1213 - val_loss: 0.1580\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1212 - val_loss: 0.1579\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1212 - val_loss: 0.1578\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1211 - val_loss: 0.1578\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1210 - val_loss: 0.1577\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1210 - val_loss: 0.1577\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1208 - val_loss: 0.1577\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1207 - val_loss: 0.1575\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1207 - val_loss: 0.1576\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1206 - val_loss: 0.1575\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1206 - val_loss: 0.1574\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1205 - val_loss: 0.1573\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1204 - val_loss: 0.1572\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1203 - val_loss: 0.1571\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1203 - val_loss: 0.1570\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1202 - val_loss: 0.1569\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1201 - val_loss: 0.1568\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1201 - val_loss: 0.1568\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1200 - val_loss: 0.1566\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1199 - val_loss: 0.1565\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1198 - val_loss: 0.1564\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1198 - val_loss: 0.1563\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1197 - val_loss: 0.1562\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1196 - val_loss: 0.1562\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1195 - val_loss: 0.1561\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1194 - val_loss: 0.1559\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1194 - val_loss: 0.1559\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1193 - val_loss: 0.1558\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1192 - val_loss: 0.1557\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1191 - val_loss: 0.1556\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1191 - val_loss: 0.1555\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1190 - val_loss: 0.1554\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1189 - val_loss: 0.1553\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1188 - val_loss: 0.1552\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1188 - val_loss: 0.1551\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1187 - val_loss: 0.1550\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1186 - val_loss: 0.1550\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1185 - val_loss: 0.1549\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1185 - val_loss: 0.1548\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1184 - val_loss: 0.1548\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1183 - val_loss: 0.1546\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1182 - val_loss: 0.1546\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1182 - val_loss: 0.1544\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1181 - val_loss: 0.1544\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1180 - val_loss: 0.1543\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1180 - val_loss: 0.1542\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1179 - val_loss: 0.1542\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1178 - val_loss: 0.1541\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1177 - val_loss: 0.1540\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1177 - val_loss: 0.1539\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1176 - val_loss: 0.1539\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1175 - val_loss: 0.1538\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1175 - val_loss: 0.1537\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1174 - val_loss: 0.1537\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1174 - val_loss: 0.1536\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1173 - val_loss: 0.1535\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1172 - val_loss: 0.1535\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1171 - val_loss: 0.1534\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1171 - val_loss: 0.1534\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1170 - val_loss: 0.1532\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1170 - val_loss: 0.1531\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1169 - val_loss: 0.1531\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1168 - val_loss: 0.1530\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1168 - val_loss: 0.1530\n",
      "Epoch 381/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1167 - val_loss: 0.1529\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1167 - val_loss: 0.1529\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1166 - val_loss: 0.1527\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1166 - val_loss: 0.1527\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1165 - val_loss: 0.1526\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1165 - val_loss: 0.1525\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1164 - val_loss: 0.1525\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1164 - val_loss: 0.1523\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1164 - val_loss: 0.1523\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1163 - val_loss: 0.1522\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1163 - val_loss: 0.1522\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1162 - val_loss: 0.1521\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1162 - val_loss: 0.1521\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1161 - val_loss: 0.1521\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1161 - val_loss: 0.1520\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1160 - val_loss: 0.1520\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1160 - val_loss: 0.1520\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1160 - val_loss: 0.1519\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1159 - val_loss: 0.1519\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1159 - val_loss: 0.1519\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1159 - val_loss: 0.1519\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1158 - val_loss: 0.1519\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1158 - val_loss: 0.1518\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1157 - val_loss: 0.1517\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1157 - val_loss: 0.1517\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1157 - val_loss: 0.1517\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1156 - val_loss: 0.1517\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1156 - val_loss: 0.1516\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1156 - val_loss: 0.1516\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1156 - val_loss: 0.1515\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1155 - val_loss: 0.1515\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1155 - val_loss: 0.1515\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1155 - val_loss: 0.1514\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1154 - val_loss: 0.1514\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1154 - val_loss: 0.1514\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1154 - val_loss: 0.1514\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1154 - val_loss: 0.1514\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1153 - val_loss: 0.1514\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1153 - val_loss: 0.1514\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1153 - val_loss: 0.1514\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1152 - val_loss: 0.1514\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1152 - val_loss: 0.1513\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1152 - val_loss: 0.1513\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1151 - val_loss: 0.1513\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1151 - val_loss: 0.1513\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1151 - val_loss: 0.1513\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1151 - val_loss: 0.1512\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1150 - val_loss: 0.1512\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1150 - val_loss: 0.1512\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1150 - val_loss: 0.1512\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1149 - val_loss: 0.1512\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1149 - val_loss: 0.1511\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1149 - val_loss: 0.1511\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1148 - val_loss: 0.1511\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1148 - val_loss: 0.1510\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1148 - val_loss: 0.1511\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1148 - val_loss: 0.1510\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1147 - val_loss: 0.1510\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1147 - val_loss: 0.1510\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1147 - val_loss: 0.1510\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1146 - val_loss: 0.1510\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1146 - val_loss: 0.1509\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1145 - val_loss: 0.1509\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1145 - val_loss: 0.1508\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1145 - val_loss: 0.1509\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1145 - val_loss: 0.1509\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1144 - val_loss: 0.1508\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1144 - val_loss: 0.1508\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1144 - val_loss: 0.1508\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1144 - val_loss: 0.1508\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1143 - val_loss: 0.1507\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1143 - val_loss: 0.1507\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1142 - val_loss: 0.1507\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1142 - val_loss: 0.1506\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1142 - val_loss: 0.1506\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1141 - val_loss: 0.1506\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1141 - val_loss: 0.1506\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1141 - val_loss: 0.1506\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1140 - val_loss: 0.1506\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1140 - val_loss: 0.1505\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1140 - val_loss: 0.1505\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1139 - val_loss: 0.1505\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1139 - val_loss: 0.1505\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1139 - val_loss: 0.1504\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1138 - val_loss: 0.1505\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1138 - val_loss: 0.1504\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1138 - val_loss: 0.1504\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1138 - val_loss: 0.1504\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1137 - val_loss: 0.1504\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1137 - val_loss: 0.1503\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1137 - val_loss: 0.1503\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1137 - val_loss: 0.1503\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1137 - val_loss: 0.1503\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1136 - val_loss: 0.1502\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1136 - val_loss: 0.1503\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1135 - val_loss: 0.1501\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1136 - val_loss: 0.1501\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1135 - val_loss: 0.1501\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1135 - val_loss: 0.1501\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1134 - val_loss: 0.1500\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1134 - val_loss: 0.1500\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1133 - val_loss: 0.1499\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1134 - val_loss: 0.1500\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1133 - val_loss: 0.1499\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1133 - val_loss: 0.1499\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1132 - val_loss: 0.1499\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1133 - val_loss: 0.1499\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1132 - val_loss: 0.1498\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1132 - val_loss: 0.1499\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1131 - val_loss: 0.1498\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1132 - val_loss: 0.1499\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1130 - val_loss: 0.1498\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1131 - val_loss: 0.1498\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1130 - val_loss: 0.1498\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1131 - val_loss: 0.1498\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1129 - val_loss: 0.1497\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1131 - val_loss: 0.1497\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1129 - val_loss: 0.1496\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1130 - val_loss: 0.1497\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1129 - val_loss: 0.1496\n",
      "2 0\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 0.9123 - val_loss: 0.5977\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7543 - val_loss: 0.4785\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6119 - val_loss: 0.3878\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5038 - val_loss: 0.3328\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4375 - val_loss: 0.3017\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3970 - val_loss: 0.2803\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3686 - val_loss: 0.2627\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3424 - val_loss: 0.2427\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3034 - val_loss: 0.2121\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2446 - val_loss: 0.1797\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1784 - val_loss: 0.1547\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1372 - val_loss: 0.1365\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1185 - val_loss: 0.1229\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1054 - val_loss: 0.1126\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0958 - val_loss: 0.1046\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0889 - val_loss: 0.0983\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0835 - val_loss: 0.0931\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0792 - val_loss: 0.0889\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0757 - val_loss: 0.0855\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0730 - val_loss: 0.0827\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0707 - val_loss: 0.0804\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0689 - val_loss: 0.0784\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0674 - val_loss: 0.0766\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0660 - val_loss: 0.0751\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0648 - val_loss: 0.0737\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0637 - val_loss: 0.0726\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0716\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0707\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0699\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0599 - val_loss: 0.0691\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0591 - val_loss: 0.0683\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0583 - val_loss: 0.0676\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0574 - val_loss: 0.0668\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0565 - val_loss: 0.0661\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0557 - val_loss: 0.0655\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0548 - val_loss: 0.0649\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0540 - val_loss: 0.0644\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0532 - val_loss: 0.0639\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0525 - val_loss: 0.0635\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0519 - val_loss: 0.0631\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0512 - val_loss: 0.0626\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0507 - val_loss: 0.0623\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0501 - val_loss: 0.0619\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0496 - val_loss: 0.0616\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0491 - val_loss: 0.0613\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0486 - val_loss: 0.0609\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0481 - val_loss: 0.0606\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0477 - val_loss: 0.0603\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0473 - val_loss: 0.0599\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0469 - val_loss: 0.0596\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0465 - val_loss: 0.0593\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0462 - val_loss: 0.0590\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0458 - val_loss: 0.0587\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0455 - val_loss: 0.0584\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0452 - val_loss: 0.0581\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0449 - val_loss: 0.0578\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0446 - val_loss: 0.0575\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0443 - val_loss: 0.0573\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0440 - val_loss: 0.0570\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0438 - val_loss: 0.0568\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0435 - val_loss: 0.0565\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0433 - val_loss: 0.0562\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0430 - val_loss: 0.0560\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0428 - val_loss: 0.0557\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0425 - val_loss: 0.0554\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0423 - val_loss: 0.0551\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0421 - val_loss: 0.0548\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0418 - val_loss: 0.0546\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0416 - val_loss: 0.0543\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0414 - val_loss: 0.0541\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0412 - val_loss: 0.0539\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0410 - val_loss: 0.0537\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0408 - val_loss: 0.0534\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0406 - val_loss: 0.0532\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0404 - val_loss: 0.0529\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0403 - val_loss: 0.0526\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0401 - val_loss: 0.0524\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0399 - val_loss: 0.0522\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0397 - val_loss: 0.0519\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0395 - val_loss: 0.0516\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0394 - val_loss: 0.0514\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0392 - val_loss: 0.0511\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0390 - val_loss: 0.0509\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0389 - val_loss: 0.0507\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0387 - val_loss: 0.0505\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0385 - val_loss: 0.0503\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0384 - val_loss: 0.0500\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0382 - val_loss: 0.0498\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0381 - val_loss: 0.0496\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0379 - val_loss: 0.0494\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0378 - val_loss: 0.0492\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0377 - val_loss: 0.0491\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0375 - val_loss: 0.0489\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0374 - val_loss: 0.0488\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0372 - val_loss: 0.0486\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0371 - val_loss: 0.0485\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0370 - val_loss: 0.0483\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0369 - val_loss: 0.0481\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0368 - val_loss: 0.0480\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0366 - val_loss: 0.0478\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0365 - val_loss: 0.0477\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0364 - val_loss: 0.0476\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0363 - val_loss: 0.0475\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0362 - val_loss: 0.0473\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0361 - val_loss: 0.0472\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0360 - val_loss: 0.0471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0359 - val_loss: 0.0470\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0358 - val_loss: 0.0469\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0357 - val_loss: 0.0467\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0357 - val_loss: 0.0466\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0465\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0355 - val_loss: 0.0464\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0354 - val_loss: 0.0463\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0462\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0353 - val_loss: 0.0461\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0459\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0351 - val_loss: 0.0458\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0350 - val_loss: 0.0457\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0456\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0349 - val_loss: 0.0455\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0454\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0453\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0347 - val_loss: 0.0452\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0346 - val_loss: 0.0451\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0450\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0448\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0344 - val_loss: 0.0447\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0446\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0343 - val_loss: 0.0445\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0444\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0342 - val_loss: 0.0443\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0442\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0441\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0340 - val_loss: 0.0440\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0339 - val_loss: 0.0439\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0339 - val_loss: 0.0438\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0338 - val_loss: 0.0437\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0338 - val_loss: 0.0436\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0337 - val_loss: 0.0435\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0337 - val_loss: 0.0435\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0336 - val_loss: 0.0434\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0336 - val_loss: 0.0433\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0335 - val_loss: 0.0433\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0335 - val_loss: 0.0432\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0335 - val_loss: 0.0432\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0334 - val_loss: 0.0431\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0334 - val_loss: 0.0431\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0333 - val_loss: 0.0430\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0333 - val_loss: 0.0430\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0332 - val_loss: 0.0429\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0332 - val_loss: 0.0429\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0331 - val_loss: 0.0429\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0331 - val_loss: 0.0429\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0331 - val_loss: 0.0428\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0330 - val_loss: 0.0427\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0330 - val_loss: 0.0427\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0330 - val_loss: 0.0427\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0329 - val_loss: 0.0426\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0329 - val_loss: 0.0426\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0329 - val_loss: 0.0425\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0328 - val_loss: 0.0425\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0328 - val_loss: 0.0424\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0328 - val_loss: 0.0424\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0327 - val_loss: 0.0423\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0327 - val_loss: 0.0423\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0327 - val_loss: 0.0422\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0326 - val_loss: 0.0422\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0326 - val_loss: 0.0422\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0326 - val_loss: 0.0421\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0325 - val_loss: 0.0421\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0325 - val_loss: 0.0420\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0325 - val_loss: 0.0420\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0324 - val_loss: 0.0420\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0324 - val_loss: 0.0419\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0324 - val_loss: 0.0419\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0418\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0418\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0418\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0322 - val_loss: 0.0417\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0322 - val_loss: 0.0417\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0322 - val_loss: 0.0417\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0321 - val_loss: 0.0416\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0321 - val_loss: 0.0416\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0321 - val_loss: 0.0415\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0414\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0414\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0413\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0319 - val_loss: 0.0413\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0319 - val_loss: 0.0412\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0319 - val_loss: 0.0412\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0319 - val_loss: 0.0412\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0318 - val_loss: 0.0411\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0318 - val_loss: 0.0411\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0318 - val_loss: 0.0411\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0411\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0410\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0410\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0410\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0409\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0409\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0409\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0408\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0316 - val_loss: 0.0408\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0408\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0407\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0407\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0407\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0315 - val_loss: 0.0407\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0407\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0406\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0406\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0406\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0406\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0406\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0405\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0405\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0405\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0405\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0313 - val_loss: 0.0405\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0404\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0404\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0404\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0404\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0312 - val_loss: 0.0404\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0404\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0403\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0403\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0403\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0403\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0403\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0310 - val_loss: 0.0402\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0402\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0402\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0401\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0401\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0401\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0401\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0401\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0401\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0401\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0401\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0308 - val_loss: 0.0401\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0307 - val_loss: 0.0400\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0400\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0399\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0399\n",
      "Epoch 257/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0399\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0399\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0399\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0399\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0305 - val_loss: 0.0398\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0397\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0397\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0397\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0397\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0396\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0396\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0396\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0304 - val_loss: 0.0396\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0396\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0395\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0395\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0395\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0395\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0394\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0394\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0394\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0394\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0393\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0393\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0393\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0393\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0392\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0392\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0302 - val_loss: 0.0392\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0391\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0391\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0391\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0391\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0391\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0390\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0390\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0390\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0390\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0390\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0390\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0389\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0389\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0389\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0389\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0388\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0388\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0300 - val_loss: 0.0388\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0388\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0388\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0386\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0386\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0299 - val_loss: 0.0386\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0386\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0386\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0386\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0386\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0385\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0384\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0384\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0384\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0384\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0383\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0382\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0382\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0382\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0297 - val_loss: 0.0382\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0382\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0382\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0381\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0381\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0381\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0381\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0381\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0380\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0380\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0380\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0380\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0380\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0295 - val_loss: 0.0379\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0377\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0377\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0377\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0377\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0377\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0376\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0376\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0376\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0376\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0376\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0376\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0375\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0374\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0374\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0374\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0374\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0292 - val_loss: 0.0374\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0374\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0373\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0372\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0372\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0372\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0372\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0371\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0370\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0370\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0370\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0290 - val_loss: 0.0370\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0370\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0370\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0369\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0368\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 4us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 4us/sample - loss: 0.0288 - val_loss: 0.0368\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 4us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0288 - val_loss: 0.0367\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0367\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0367\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0366\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0287 - val_loss: 0.0365\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0365\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0365\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0365\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0365\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0365\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0365\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0364\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0363\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0363\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0363\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0363\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0363\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0363\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0285 - val_loss: 0.0363\n",
      "2 1\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 0.9540 - val_loss: 0.7362\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7135 - val_loss: 0.6076\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5866 - val_loss: 0.5343\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5125 - val_loss: 0.4895\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4669 - val_loss: 0.4589\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4342 - val_loss: 0.4331\n",
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4070 - val_loss: 0.4088\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3579 - val_loss: 0.3617\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3344 - val_loss: 0.3382\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3110 - val_loss: 0.3141\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2873 - val_loss: 0.2890\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2628 - val_loss: 0.2629\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2375 - val_loss: 0.2353\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2108 - val_loss: 0.2054\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1827 - val_loss: 0.1738\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1534 - val_loss: 0.1428\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1263 - val_loss: 0.1165\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1043 - val_loss: 0.0961\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0878 - val_loss: 0.0805\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0758 - val_loss: 0.0700\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0671 - val_loss: 0.0626\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0567\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0562 - val_loss: 0.0527\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0527 - val_loss: 0.0492\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0499 - val_loss: 0.0468\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0476 - val_loss: 0.0449\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0459 - val_loss: 0.0436\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0444 - val_loss: 0.0424\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0432 - val_loss: 0.0414\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0421 - val_loss: 0.0407\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0412 - val_loss: 0.0400\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0404 - val_loss: 0.0393\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0397 - val_loss: 0.0387\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0390 - val_loss: 0.0382\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0384 - val_loss: 0.0377\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0378 - val_loss: 0.0373\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0373 - val_loss: 0.0368\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0352 - val_loss: 0.0351\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0348 - val_loss: 0.0348\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0345 - val_loss: 0.0346\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0341 - val_loss: 0.0343\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0338 - val_loss: 0.0341\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0335 - val_loss: 0.0338\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0332 - val_loss: 0.0335\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0329 - val_loss: 0.0333\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0326 - val_loss: 0.0330\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0323 - val_loss: 0.0328\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0320 - val_loss: 0.0325\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0317 - val_loss: 0.0323\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0314 - val_loss: 0.0320\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0311 - val_loss: 0.0318\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0309 - val_loss: 0.0316\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0306 - val_loss: 0.0314\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0303 - val_loss: 0.0313\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0301 - val_loss: 0.0311\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0298 - val_loss: 0.0309\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0296 - val_loss: 0.0307\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0293 - val_loss: 0.0305\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0291 - val_loss: 0.0303\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0289 - val_loss: 0.0301\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0286 - val_loss: 0.0299\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0282 - val_loss: 0.0296\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0280 - val_loss: 0.0294\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0278 - val_loss: 0.0293\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0276 - val_loss: 0.0291\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0274 - val_loss: 0.0290\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0272 - val_loss: 0.0288\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0270 - val_loss: 0.0287\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0268 - val_loss: 0.0285\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0267 - val_loss: 0.0284\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0265 - val_loss: 0.0283\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0264 - val_loss: 0.0281\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0262 - val_loss: 0.0280\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0260 - val_loss: 0.0278\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0259 - val_loss: 0.0277\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0257 - val_loss: 0.0276\n",
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0256 - val_loss: 0.0275\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0254 - val_loss: 0.0273\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0253 - val_loss: 0.0272\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0252 - val_loss: 0.0271\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0250 - val_loss: 0.0270\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0249 - val_loss: 0.0269\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0247 - val_loss: 0.0268\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0246 - val_loss: 0.0267\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0245 - val_loss: 0.0265\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0243 - val_loss: 0.0265\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0242 - val_loss: 0.0264\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0241 - val_loss: 0.0263\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0239 - val_loss: 0.0261\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0238 - val_loss: 0.0261\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0237 - val_loss: 0.0260\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0236 - val_loss: 0.0259\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0235 - val_loss: 0.0258\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0234 - val_loss: 0.0257\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0233 - val_loss: 0.0256\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0232 - val_loss: 0.0255\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0231 - val_loss: 0.0254\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0230 - val_loss: 0.0254\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0229 - val_loss: 0.0253\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0228 - val_loss: 0.0252\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0227 - val_loss: 0.0251\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0227 - val_loss: 0.0250\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0226 - val_loss: 0.0249\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0225 - val_loss: 0.0248\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0224 - val_loss: 0.0247\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0223 - val_loss: 0.0247\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0222 - val_loss: 0.0245\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0221 - val_loss: 0.0245\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0221 - val_loss: 0.0244\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0220 - val_loss: 0.0243\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0219 - val_loss: 0.0243\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0219 - val_loss: 0.0242\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0217 - val_loss: 0.0240\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0217 - val_loss: 0.0239\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0216 - val_loss: 0.0239\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0215 - val_loss: 0.0239\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0215 - val_loss: 0.0238\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0214 - val_loss: 0.0237\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0214 - val_loss: 0.0238\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 132/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0211 - val_loss: 0.0235\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0211 - val_loss: 0.0235\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0209 - val_loss: 0.0234\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0208 - val_loss: 0.0233\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0208 - val_loss: 0.0232\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0206 - val_loss: 0.0232\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0206 - val_loss: 0.0231\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0205 - val_loss: 0.0231\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0204 - val_loss: 0.0230\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0204 - val_loss: 0.0229\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0203 - val_loss: 0.0229\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0203 - val_loss: 0.0228\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0202 - val_loss: 0.0228\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0201 - val_loss: 0.0227\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0201 - val_loss: 0.0227\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 158/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0199 - val_loss: 0.0225\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0199 - val_loss: 0.0225\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0199 - val_loss: 0.0224\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0198 - val_loss: 0.0224\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0198 - val_loss: 0.0223\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0197 - val_loss: 0.0223\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0197 - val_loss: 0.0223\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0197 - val_loss: 0.0222\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0196 - val_loss: 0.0221\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0194 - val_loss: 0.0220\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0194 - val_loss: 0.0220\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0194 - val_loss: 0.0219\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0194 - val_loss: 0.0219\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0193 - val_loss: 0.0219\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0192 - val_loss: 0.0218\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0192 - val_loss: 0.0218\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0192 - val_loss: 0.0217\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0191 - val_loss: 0.0218\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0191 - val_loss: 0.0217\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0191 - val_loss: 0.0217\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0190 - val_loss: 0.0217\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0190 - val_loss: 0.0216\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0190 - val_loss: 0.0216\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0190 - val_loss: 0.0215\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0188 - val_loss: 0.0215\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0187 - val_loss: 0.0213\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0187 - val_loss: 0.0213\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0187 - val_loss: 0.0213\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0187 - val_loss: 0.0213\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0186 - val_loss: 0.0213\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0186 - val_loss: 0.0212\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0186 - val_loss: 0.0212\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0186 - val_loss: 0.0212\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0185 - val_loss: 0.0212\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0185 - val_loss: 0.0212\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0185 - val_loss: 0.0212\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0185 - val_loss: 0.0211\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0185 - val_loss: 0.0211\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0184 - val_loss: 0.0211\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0183 - val_loss: 0.0209\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0183 - val_loss: 0.0209\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0182 - val_loss: 0.0209\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0182 - val_loss: 0.0209\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0182 - val_loss: 0.0209\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0181 - val_loss: 0.0208\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0181 - val_loss: 0.0208\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0181 - val_loss: 0.0207\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0180 - val_loss: 0.0207\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0180 - val_loss: 0.0207\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0180 - val_loss: 0.0207\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0179 - val_loss: 0.0206\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0179 - val_loss: 0.0206\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 233/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0204\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0176 - val_loss: 0.0201\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0201\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0175 - val_loss: 0.0200\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0197\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0196\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0196\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 308/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0168 - val_loss: 0.0193\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0168 - val_loss: 0.0192\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0168 - val_loss: 0.0192\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0168 - val_loss: 0.0192\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0192\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0191\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0191\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0191\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0191\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0166 - val_loss: 0.0188\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0188\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0186\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0186\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0186\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0185\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 383/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0181\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0180\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 432/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0158 - val_loss: 0.0178\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0178\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0178\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0176\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0176\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0157 - val_loss: 0.0176\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 458/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0154 - val_loss: 0.0174\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0154 - val_loss: 0.0174\n",
      "2 2\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/500\n",
      "34560/34560 [==============================] - 0s 11us/sample - loss: 1.1071 - val_loss: 0.9756\n",
      "Epoch 2/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.9525 - val_loss: 0.9108\n",
      "Epoch 3/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.8936 - val_loss: 0.8601\n",
      "Epoch 4/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.8371 - val_loss: 0.8024\n",
      "Epoch 5/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7794 - val_loss: 0.7379\n",
      "Epoch 6/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.7169 - val_loss: 0.6635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.6456 - val_loss: 0.5836\n",
      "Epoch 8/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5737 - val_loss: 0.5115\n",
      "Epoch 9/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.5015 - val_loss: 0.4472\n",
      "Epoch 10/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.4349 - val_loss: 0.3948\n",
      "Epoch 11/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3772 - val_loss: 0.3538\n",
      "Epoch 12/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.3314 - val_loss: 0.3210\n",
      "Epoch 13/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2937 - val_loss: 0.2941\n",
      "Epoch 14/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2636 - val_loss: 0.2730\n",
      "Epoch 15/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2438 - val_loss: 0.2597\n",
      "Epoch 16/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2309 - val_loss: 0.2494\n",
      "Epoch 17/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2212 - val_loss: 0.2405\n",
      "Epoch 18/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2129 - val_loss: 0.2324\n",
      "Epoch 19/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.2056 - val_loss: 0.2248\n",
      "Epoch 20/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1988 - val_loss: 0.2178\n",
      "Epoch 21/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1927 - val_loss: 0.2110\n",
      "Epoch 22/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1867 - val_loss: 0.2042\n",
      "Epoch 23/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1805 - val_loss: 0.1971\n",
      "Epoch 24/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1742 - val_loss: 0.1897\n",
      "Epoch 25/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1676 - val_loss: 0.1824\n",
      "Epoch 26/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1609 - val_loss: 0.1749\n",
      "Epoch 27/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1540 - val_loss: 0.1678\n",
      "Epoch 28/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1483 - val_loss: 0.1617\n",
      "Epoch 29/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1431 - val_loss: 0.1557\n",
      "Epoch 30/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1381 - val_loss: 0.1500\n",
      "Epoch 31/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1333 - val_loss: 0.1447\n",
      "Epoch 32/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1289 - val_loss: 0.1401\n",
      "Epoch 33/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1249 - val_loss: 0.1358\n",
      "Epoch 34/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1213 - val_loss: 0.1320\n",
      "Epoch 35/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1182 - val_loss: 0.1290\n",
      "Epoch 36/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1156 - val_loss: 0.1265\n",
      "Epoch 37/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1132 - val_loss: 0.1243\n",
      "Epoch 38/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1110 - val_loss: 0.1224\n",
      "Epoch 39/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1090 - val_loss: 0.1207\n",
      "Epoch 40/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1073 - val_loss: 0.1190\n",
      "Epoch 41/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1057 - val_loss: 0.1174\n",
      "Epoch 42/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1042 - val_loss: 0.1159\n",
      "Epoch 43/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1028 - val_loss: 0.1146\n",
      "Epoch 44/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1016 - val_loss: 0.1131\n",
      "Epoch 45/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.1002 - val_loss: 0.1117\n",
      "Epoch 46/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0990 - val_loss: 0.1104\n",
      "Epoch 47/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0978 - val_loss: 0.1090\n",
      "Epoch 48/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0967 - val_loss: 0.1077\n",
      "Epoch 49/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0957 - val_loss: 0.1065\n",
      "Epoch 50/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0947 - val_loss: 0.1054\n",
      "Epoch 51/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0938 - val_loss: 0.1045\n",
      "Epoch 52/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0930 - val_loss: 0.1037\n",
      "Epoch 53/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0921 - val_loss: 0.1028\n",
      "Epoch 54/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0914 - val_loss: 0.1020\n",
      "Epoch 55/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0905 - val_loss: 0.1013\n",
      "Epoch 56/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0898 - val_loss: 0.1008\n",
      "Epoch 57/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0891 - val_loss: 0.1003\n",
      "Epoch 58/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0885 - val_loss: 0.0996\n",
      "Epoch 59/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0879 - val_loss: 0.0991\n",
      "Epoch 60/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0873 - val_loss: 0.0986\n",
      "Epoch 61/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0868 - val_loss: 0.0980\n",
      "Epoch 62/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0863 - val_loss: 0.0973\n",
      "Epoch 63/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0859 - val_loss: 0.0972\n",
      "Epoch 64/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0855 - val_loss: 0.0968\n",
      "Epoch 65/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0851 - val_loss: 0.0965\n",
      "Epoch 66/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0846 - val_loss: 0.0963\n",
      "Epoch 67/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0842 - val_loss: 0.0961\n",
      "Epoch 68/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0838 - val_loss: 0.0958\n",
      "Epoch 69/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0835 - val_loss: 0.0957\n",
      "Epoch 70/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0831 - val_loss: 0.0955\n",
      "Epoch 71/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0828 - val_loss: 0.0956\n",
      "Epoch 72/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0825 - val_loss: 0.0953\n",
      "Epoch 73/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0822 - val_loss: 0.0957\n",
      "Epoch 74/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0819 - val_loss: 0.0953\n",
      "Epoch 75/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0815 - val_loss: 0.0948\n",
      "Epoch 76/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0812 - val_loss: 0.0947\n",
      "Epoch 77/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0809 - val_loss: 0.0946\n",
      "Epoch 78/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0805 - val_loss: 0.0943\n",
      "Epoch 79/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0801 - val_loss: 0.0940\n",
      "Epoch 80/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0797 - val_loss: 0.0937\n",
      "Epoch 81/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0793 - val_loss: 0.0935\n",
      "Epoch 82/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0790 - val_loss: 0.0934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0787 - val_loss: 0.0932\n",
      "Epoch 84/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0784 - val_loss: 0.0932\n",
      "Epoch 85/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0782 - val_loss: 0.0930\n",
      "Epoch 86/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0780 - val_loss: 0.0926\n",
      "Epoch 87/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0777 - val_loss: 0.0924\n",
      "Epoch 88/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 89/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0773 - val_loss: 0.0919\n",
      "Epoch 90/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0771 - val_loss: 0.0917\n",
      "Epoch 91/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0770 - val_loss: 0.0914\n",
      "Epoch 92/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0769 - val_loss: 0.0913\n",
      "Epoch 93/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0768 - val_loss: 0.0912\n",
      "Epoch 94/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0767 - val_loss: 0.0910\n",
      "Epoch 95/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0766 - val_loss: 0.0910\n",
      "Epoch 96/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0765 - val_loss: 0.0907\n",
      "Epoch 97/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0765 - val_loss: 0.0905\n",
      "Epoch 98/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0765 - val_loss: 0.0906\n",
      "Epoch 99/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0763 - val_loss: 0.0905\n",
      "Epoch 100/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0763 - val_loss: 0.0902\n",
      "Epoch 101/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0762 - val_loss: 0.0900\n",
      "Epoch 102/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0761 - val_loss: 0.0898\n",
      "Epoch 103/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0760 - val_loss: 0.0897\n",
      "Epoch 104/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0759 - val_loss: 0.0895\n",
      "Epoch 105/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0758 - val_loss: 0.0892\n",
      "Epoch 106/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0757 - val_loss: 0.0893\n",
      "Epoch 107/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0756 - val_loss: 0.0892\n",
      "Epoch 108/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0755 - val_loss: 0.0889\n",
      "Epoch 109/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0754 - val_loss: 0.0888\n",
      "Epoch 110/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0753 - val_loss: 0.0887\n",
      "Epoch 111/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0752 - val_loss: 0.0882\n",
      "Epoch 112/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0750 - val_loss: 0.0880\n",
      "Epoch 113/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0749 - val_loss: 0.0879\n",
      "Epoch 114/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0748 - val_loss: 0.0877\n",
      "Epoch 115/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0747 - val_loss: 0.0875\n",
      "Epoch 116/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0746 - val_loss: 0.0876\n",
      "Epoch 117/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0745 - val_loss: 0.0873\n",
      "Epoch 118/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0744 - val_loss: 0.0873\n",
      "Epoch 119/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0743 - val_loss: 0.0872\n",
      "Epoch 120/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0742 - val_loss: 0.0871\n",
      "Epoch 121/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0741 - val_loss: 0.0869\n",
      "Epoch 122/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0740 - val_loss: 0.0869\n",
      "Epoch 123/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0739 - val_loss: 0.0868\n",
      "Epoch 124/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0738 - val_loss: 0.0867\n",
      "Epoch 125/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0737 - val_loss: 0.0865\n",
      "Epoch 126/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0736 - val_loss: 0.0864\n",
      "Epoch 127/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0736 - val_loss: 0.0863\n",
      "Epoch 128/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0734 - val_loss: 0.0863\n",
      "Epoch 129/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0734 - val_loss: 0.0861\n",
      "Epoch 130/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0732 - val_loss: 0.0860\n",
      "Epoch 131/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0732 - val_loss: 0.0859\n",
      "Epoch 132/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0731 - val_loss: 0.0858\n",
      "Epoch 133/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0730 - val_loss: 0.0857\n",
      "Epoch 134/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0729 - val_loss: 0.0856\n",
      "Epoch 135/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0729 - val_loss: 0.0855\n",
      "Epoch 136/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0728 - val_loss: 0.0854\n",
      "Epoch 137/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0727 - val_loss: 0.0853\n",
      "Epoch 138/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0727 - val_loss: 0.0852\n",
      "Epoch 139/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0726 - val_loss: 0.0851\n",
      "Epoch 140/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0724 - val_loss: 0.0851\n",
      "Epoch 141/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0724 - val_loss: 0.0849\n",
      "Epoch 142/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0722 - val_loss: 0.0849\n",
      "Epoch 143/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0722 - val_loss: 0.0848\n",
      "Epoch 144/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0721 - val_loss: 0.0848\n",
      "Epoch 145/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0720 - val_loss: 0.0847\n",
      "Epoch 146/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0719 - val_loss: 0.0846\n",
      "Epoch 147/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0717 - val_loss: 0.0844\n",
      "Epoch 148/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0717 - val_loss: 0.0843\n",
      "Epoch 149/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0716 - val_loss: 0.0841\n",
      "Epoch 150/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0716 - val_loss: 0.0841\n",
      "Epoch 151/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0714 - val_loss: 0.0839\n",
      "Epoch 152/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0713 - val_loss: 0.0838\n",
      "Epoch 153/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0712 - val_loss: 0.0837\n",
      "Epoch 154/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0711 - val_loss: 0.0835\n",
      "Epoch 155/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0710 - val_loss: 0.0835\n",
      "Epoch 156/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0708 - val_loss: 0.0834\n",
      "Epoch 157/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0707 - val_loss: 0.0831\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0705 - val_loss: 0.0831\n",
      "Epoch 159/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0704 - val_loss: 0.0829\n",
      "Epoch 160/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0703 - val_loss: 0.0829\n",
      "Epoch 161/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0702 - val_loss: 0.0827\n",
      "Epoch 162/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0702 - val_loss: 0.0827\n",
      "Epoch 163/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0701 - val_loss: 0.0826\n",
      "Epoch 164/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0700 - val_loss: 0.0825\n",
      "Epoch 165/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0700 - val_loss: 0.0825\n",
      "Epoch 166/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0699 - val_loss: 0.0823\n",
      "Epoch 167/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0698 - val_loss: 0.0822\n",
      "Epoch 168/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0698 - val_loss: 0.0821\n",
      "Epoch 169/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0697 - val_loss: 0.0821\n",
      "Epoch 170/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0696 - val_loss: 0.0820\n",
      "Epoch 171/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0695 - val_loss: 0.0820\n",
      "Epoch 172/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0695 - val_loss: 0.0819\n",
      "Epoch 173/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0695 - val_loss: 0.0819\n",
      "Epoch 174/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0694 - val_loss: 0.0818\n",
      "Epoch 175/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0694 - val_loss: 0.0818\n",
      "Epoch 176/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0693 - val_loss: 0.0817\n",
      "Epoch 177/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0693 - val_loss: 0.0817\n",
      "Epoch 178/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0692 - val_loss: 0.0816\n",
      "Epoch 179/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0692 - val_loss: 0.0817\n",
      "Epoch 180/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0691 - val_loss: 0.0816\n",
      "Epoch 181/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0690 - val_loss: 0.0816\n",
      "Epoch 182/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0690 - val_loss: 0.0816\n",
      "Epoch 183/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0689 - val_loss: 0.0815\n",
      "Epoch 184/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0689 - val_loss: 0.0816\n",
      "Epoch 185/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0689 - val_loss: 0.0816\n",
      "Epoch 186/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0688 - val_loss: 0.0815\n",
      "Epoch 187/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0687 - val_loss: 0.0813\n",
      "Epoch 188/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0687 - val_loss: 0.0813\n",
      "Epoch 189/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0685 - val_loss: 0.0813\n",
      "Epoch 190/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0684 - val_loss: 0.0811\n",
      "Epoch 191/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0685 - val_loss: 0.0811\n",
      "Epoch 192/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0684 - val_loss: 0.0811\n",
      "Epoch 193/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0684 - val_loss: 0.0811\n",
      "Epoch 194/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0684 - val_loss: 0.0812\n",
      "Epoch 195/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0683 - val_loss: 0.0811\n",
      "Epoch 196/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0683 - val_loss: 0.0810\n",
      "Epoch 197/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0681 - val_loss: 0.0809\n",
      "Epoch 198/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0681 - val_loss: 0.0809\n",
      "Epoch 199/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0681 - val_loss: 0.0808\n",
      "Epoch 200/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0681 - val_loss: 0.0808\n",
      "Epoch 201/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0680 - val_loss: 0.0807\n",
      "Epoch 202/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0679 - val_loss: 0.0807\n",
      "Epoch 203/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0679 - val_loss: 0.0807\n",
      "Epoch 204/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0678 - val_loss: 0.0806\n",
      "Epoch 205/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0677 - val_loss: 0.0806\n",
      "Epoch 206/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0677 - val_loss: 0.0806\n",
      "Epoch 207/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0676 - val_loss: 0.0804\n",
      "Epoch 208/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0676 - val_loss: 0.0805\n",
      "Epoch 209/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0675 - val_loss: 0.0806\n",
      "Epoch 210/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0675 - val_loss: 0.0804\n",
      "Epoch 211/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0674 - val_loss: 0.0804\n",
      "Epoch 212/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0674 - val_loss: 0.0803\n",
      "Epoch 213/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0673 - val_loss: 0.0804\n",
      "Epoch 214/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0672 - val_loss: 0.0802\n",
      "Epoch 215/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0672 - val_loss: 0.0802\n",
      "Epoch 216/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0672 - val_loss: 0.0802\n",
      "Epoch 217/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0671 - val_loss: 0.0802\n",
      "Epoch 218/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0671 - val_loss: 0.0802\n",
      "Epoch 219/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0670 - val_loss: 0.0801\n",
      "Epoch 220/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0670 - val_loss: 0.0801\n",
      "Epoch 221/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0669 - val_loss: 0.0800\n",
      "Epoch 222/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0669 - val_loss: 0.0799\n",
      "Epoch 223/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0669 - val_loss: 0.0799\n",
      "Epoch 224/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0669 - val_loss: 0.0799\n",
      "Epoch 225/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0668 - val_loss: 0.0798\n",
      "Epoch 226/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0667 - val_loss: 0.0798\n",
      "Epoch 227/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0667 - val_loss: 0.0797\n",
      "Epoch 228/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0666 - val_loss: 0.0797\n",
      "Epoch 229/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0666 - val_loss: 0.0798\n",
      "Epoch 230/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0665 - val_loss: 0.0797\n",
      "Epoch 231/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0664 - val_loss: 0.0796\n",
      "Epoch 232/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0663 - val_loss: 0.0798\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0662 - val_loss: 0.0798\n",
      "Epoch 234/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0662 - val_loss: 0.0798\n",
      "Epoch 235/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0661 - val_loss: 0.0796\n",
      "Epoch 236/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0661 - val_loss: 0.0796\n",
      "Epoch 237/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0661 - val_loss: 0.0797\n",
      "Epoch 238/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0661 - val_loss: 0.0797\n",
      "Epoch 239/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0660 - val_loss: 0.0797\n",
      "Epoch 240/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0659 - val_loss: 0.0796\n",
      "Epoch 241/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0658 - val_loss: 0.0795\n",
      "Epoch 242/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0658 - val_loss: 0.0794\n",
      "Epoch 243/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0658 - val_loss: 0.0793\n",
      "Epoch 244/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0658 - val_loss: 0.0791\n",
      "Epoch 245/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0657 - val_loss: 0.0791\n",
      "Epoch 246/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0656 - val_loss: 0.0791\n",
      "Epoch 247/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0655 - val_loss: 0.0791\n",
      "Epoch 248/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0655 - val_loss: 0.0790\n",
      "Epoch 249/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0654 - val_loss: 0.0790\n",
      "Epoch 250/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0653 - val_loss: 0.0788\n",
      "Epoch 251/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0654 - val_loss: 0.0788\n",
      "Epoch 252/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0653 - val_loss: 0.0787\n",
      "Epoch 253/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0652 - val_loss: 0.0787\n",
      "Epoch 254/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0651 - val_loss: 0.0786\n",
      "Epoch 255/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0651 - val_loss: 0.0786\n",
      "Epoch 256/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0650 - val_loss: 0.0786\n",
      "Epoch 257/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0650 - val_loss: 0.0786\n",
      "Epoch 258/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0649 - val_loss: 0.0785\n",
      "Epoch 259/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0649 - val_loss: 0.0785\n",
      "Epoch 260/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0648 - val_loss: 0.0785\n",
      "Epoch 261/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0649 - val_loss: 0.0785\n",
      "Epoch 262/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0648 - val_loss: 0.0785\n",
      "Epoch 263/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0648 - val_loss: 0.0784\n",
      "Epoch 264/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0647 - val_loss: 0.0784\n",
      "Epoch 265/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0646 - val_loss: 0.0784\n",
      "Epoch 266/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0646 - val_loss: 0.0784\n",
      "Epoch 267/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0646 - val_loss: 0.0784\n",
      "Epoch 268/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0645 - val_loss: 0.0784\n",
      "Epoch 269/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0645 - val_loss: 0.0783\n",
      "Epoch 270/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0645 - val_loss: 0.0783\n",
      "Epoch 271/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0645 - val_loss: 0.0783\n",
      "Epoch 272/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0644 - val_loss: 0.0782\n",
      "Epoch 273/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0644 - val_loss: 0.0782\n",
      "Epoch 274/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0643 - val_loss: 0.0781\n",
      "Epoch 275/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0643 - val_loss: 0.0781\n",
      "Epoch 276/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0643 - val_loss: 0.0782\n",
      "Epoch 277/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0642 - val_loss: 0.0782\n",
      "Epoch 278/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0642 - val_loss: 0.0782\n",
      "Epoch 279/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0640 - val_loss: 0.0781\n",
      "Epoch 280/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0641 - val_loss: 0.0781\n",
      "Epoch 281/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0640 - val_loss: 0.0780\n",
      "Epoch 282/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0640 - val_loss: 0.0780\n",
      "Epoch 283/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0639 - val_loss: 0.0781\n",
      "Epoch 284/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0640 - val_loss: 0.0781\n",
      "Epoch 285/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0639 - val_loss: 0.0780\n",
      "Epoch 286/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0638 - val_loss: 0.0779\n",
      "Epoch 287/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0639 - val_loss: 0.0781\n",
      "Epoch 288/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0637 - val_loss: 0.0779\n",
      "Epoch 289/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0637 - val_loss: 0.0779\n",
      "Epoch 290/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0637 - val_loss: 0.0779\n",
      "Epoch 291/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0637 - val_loss: 0.0780\n",
      "Epoch 292/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0636 - val_loss: 0.0779\n",
      "Epoch 293/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0636 - val_loss: 0.0779\n",
      "Epoch 294/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0636 - val_loss: 0.0778\n",
      "Epoch 295/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0636 - val_loss: 0.0779\n",
      "Epoch 296/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0635 - val_loss: 0.0778\n",
      "Epoch 297/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0636 - val_loss: 0.0778\n",
      "Epoch 298/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0634 - val_loss: 0.0778\n",
      "Epoch 299/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0635 - val_loss: 0.0778\n",
      "Epoch 300/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0634 - val_loss: 0.0777\n",
      "Epoch 301/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0635 - val_loss: 0.0777\n",
      "Epoch 302/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0777\n",
      "Epoch 303/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0634 - val_loss: 0.0777\n",
      "Epoch 304/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0777\n",
      "Epoch 305/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0776\n",
      "Epoch 306/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0776\n",
      "Epoch 307/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0775\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0776\n",
      "Epoch 309/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0775\n",
      "Epoch 310/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0633 - val_loss: 0.0775\n",
      "Epoch 311/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0632 - val_loss: 0.0775\n",
      "Epoch 312/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0632 - val_loss: 0.0775\n",
      "Epoch 313/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0632 - val_loss: 0.0775\n",
      "Epoch 314/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0632 - val_loss: 0.0775\n",
      "Epoch 315/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0632 - val_loss: 0.0775\n",
      "Epoch 316/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0632 - val_loss: 0.0774\n",
      "Epoch 317/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0631 - val_loss: 0.0775\n",
      "Epoch 318/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0631 - val_loss: 0.0776\n",
      "Epoch 319/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0631 - val_loss: 0.0775\n",
      "Epoch 320/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0776\n",
      "Epoch 321/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0775\n",
      "Epoch 322/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0774\n",
      "Epoch 323/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0775\n",
      "Epoch 324/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0775\n",
      "Epoch 325/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0775\n",
      "Epoch 326/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0775\n",
      "Epoch 327/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0629 - val_loss: 0.0774\n",
      "Epoch 328/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0630 - val_loss: 0.0774\n",
      "Epoch 329/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0629 - val_loss: 0.0774\n",
      "Epoch 330/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0629 - val_loss: 0.0773\n",
      "Epoch 331/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0629 - val_loss: 0.0774\n",
      "Epoch 332/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0629 - val_loss: 0.0775\n",
      "Epoch 333/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0628 - val_loss: 0.0774\n",
      "Epoch 334/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0628 - val_loss: 0.0775\n",
      "Epoch 335/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0629 - val_loss: 0.0774\n",
      "Epoch 336/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0628 - val_loss: 0.0775\n",
      "Epoch 337/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0628 - val_loss: 0.0775\n",
      "Epoch 338/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0628 - val_loss: 0.0774\n",
      "Epoch 339/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0774\n",
      "Epoch 340/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0773\n",
      "Epoch 341/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0775\n",
      "Epoch 342/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0775\n",
      "Epoch 343/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0773\n",
      "Epoch 344/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0774\n",
      "Epoch 345/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0627 - val_loss: 0.0774\n",
      "Epoch 346/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0773\n",
      "Epoch 347/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0773\n",
      "Epoch 348/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0774\n",
      "Epoch 349/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0773\n",
      "Epoch 350/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0773\n",
      "Epoch 351/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0625 - val_loss: 0.0773\n",
      "Epoch 352/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0626 - val_loss: 0.0773\n",
      "Epoch 353/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0625 - val_loss: 0.0773\n",
      "Epoch 354/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0625 - val_loss: 0.0773\n",
      "Epoch 355/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0625 - val_loss: 0.0773\n",
      "Epoch 356/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0625 - val_loss: 0.0773\n",
      "Epoch 357/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0625 - val_loss: 0.0773\n",
      "Epoch 358/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0624 - val_loss: 0.0773\n",
      "Epoch 359/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0624 - val_loss: 0.0772\n",
      "Epoch 360/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0624 - val_loss: 0.0772\n",
      "Epoch 361/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0624 - val_loss: 0.0772\n",
      "Epoch 362/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0772\n",
      "Epoch 363/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0772\n",
      "Epoch 364/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0772\n",
      "Epoch 365/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0772\n",
      "Epoch 366/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0771\n",
      "Epoch 367/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0772\n",
      "Epoch 368/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0623 - val_loss: 0.0771\n",
      "Epoch 369/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0622 - val_loss: 0.0771\n",
      "Epoch 370/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0622 - val_loss: 0.0771\n",
      "Epoch 371/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0622 - val_loss: 0.0771\n",
      "Epoch 372/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0622 - val_loss: 0.0770\n",
      "Epoch 373/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0770\n",
      "Epoch 374/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0770\n",
      "Epoch 375/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0770\n",
      "Epoch 376/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0770\n",
      "Epoch 377/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0769\n",
      "Epoch 378/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0770\n",
      "Epoch 379/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0769\n",
      "Epoch 380/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0621 - val_loss: 0.0768\n",
      "Epoch 381/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0620 - val_loss: 0.0768\n",
      "Epoch 382/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0620 - val_loss: 0.0767\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0620 - val_loss: 0.0767\n",
      "Epoch 384/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0620 - val_loss: 0.0766\n",
      "Epoch 385/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0620 - val_loss: 0.0767\n",
      "Epoch 386/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0768\n",
      "Epoch 387/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0768\n",
      "Epoch 388/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 389/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0766\n",
      "Epoch 390/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 391/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 392/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 393/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 394/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 395/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0767\n",
      "Epoch 396/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 397/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0619 - val_loss: 0.0766\n",
      "Epoch 398/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 399/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 400/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 401/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 402/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 403/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0765\n",
      "Epoch 404/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0765\n",
      "Epoch 405/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0618 - val_loss: 0.0765\n",
      "Epoch 406/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0765\n",
      "Epoch 407/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0765\n",
      "Epoch 408/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0764\n",
      "Epoch 409/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0764\n",
      "Epoch 410/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0765\n",
      "Epoch 411/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 412/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0764\n",
      "Epoch 413/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 414/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0617 - val_loss: 0.0764\n",
      "Epoch 415/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0764\n",
      "Epoch 416/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 417/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0762\n",
      "Epoch 418/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 419/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 420/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0764\n",
      "Epoch 421/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0763\n",
      "Epoch 422/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 423/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0763\n",
      "Epoch 424/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0762\n",
      "Epoch 425/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0763\n",
      "Epoch 426/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0762\n",
      "Epoch 427/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0762\n",
      "Epoch 428/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0762\n",
      "Epoch 429/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0761\n",
      "Epoch 430/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0761\n",
      "Epoch 431/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0761\n",
      "Epoch 432/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0761\n",
      "Epoch 433/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0615 - val_loss: 0.0761\n",
      "Epoch 434/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0614 - val_loss: 0.0762\n",
      "Epoch 435/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0614 - val_loss: 0.0760\n",
      "Epoch 436/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0614 - val_loss: 0.0761\n",
      "Epoch 437/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0614 - val_loss: 0.0761\n",
      "Epoch 438/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0760\n",
      "Epoch 439/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0614 - val_loss: 0.0761\n",
      "Epoch 440/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0760\n",
      "Epoch 441/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 442/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 443/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 444/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 445/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 446/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 447/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0758\n",
      "Epoch 448/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 449/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0759\n",
      "Epoch 450/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0758\n",
      "Epoch 451/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0758\n",
      "Epoch 452/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0612 - val_loss: 0.0758\n",
      "Epoch 453/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0613 - val_loss: 0.0758\n",
      "Epoch 454/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0612 - val_loss: 0.0758\n",
      "Epoch 455/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0612 - val_loss: 0.0758\n",
      "Epoch 456/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0612 - val_loss: 0.0757\n",
      "Epoch 457/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0758\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0758\n",
      "Epoch 459/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0757\n",
      "Epoch 460/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0757\n",
      "Epoch 461/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0757\n",
      "Epoch 462/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0757\n",
      "Epoch 463/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0611 - val_loss: 0.0757\n",
      "Epoch 464/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0757\n",
      "Epoch 465/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0757\n",
      "Epoch 466/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0756\n",
      "Epoch 467/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0756\n",
      "Epoch 468/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0756\n",
      "Epoch 469/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0755\n",
      "Epoch 470/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0756\n",
      "Epoch 471/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0756\n",
      "Epoch 472/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0610 - val_loss: 0.0755\n",
      "Epoch 473/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 474/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 475/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 476/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 477/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 478/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 479/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 480/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0609 - val_loss: 0.0755\n",
      "Epoch 481/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 482/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 483/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 484/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 485/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 486/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 487/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 488/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 489/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 490/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0754\n",
      "Epoch 491/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0753\n",
      "Epoch 492/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0753\n",
      "Epoch 493/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0608 - val_loss: 0.0753\n",
      "Epoch 494/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0753\n",
      "Epoch 495/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0752\n",
      "Epoch 496/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0752\n",
      "Epoch 497/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0752\n",
      "Epoch 498/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0752\n",
      "Epoch 499/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0752\n",
      "Epoch 500/500\n",
      "34560/34560 [==============================] - 0s 3us/sample - loss: 0.0607 - val_loss: 0.0752\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40,restore_best_weights=True)\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        print(i,j)\n",
    "        X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un = get_data(i,j)\n",
    "        model = get_model(0,20)\n",
    "        #model.fit(X_train,Y_train,eval_set=[(X_val,Y_val)],early_stopping_rounds=40,verbose=False)\n",
    "\n",
    "        h=model.fit(X_train,Y_train,epochs=500,batch_size=512,validation_data=(X_val,Y_val),callbacks=[es],shuffle=False)\n",
    "        #model.save('models/Gij_'+str(i)+'_'+str(j)+'_S2_test.h5')\n",
    "        #pickle.dump(model, open(\"models/Gij_\"+str(i)+\"_\"+str(j)+\"_S1_XGB_test.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 34560 samples, validate on 11520 samples\n",
      "Epoch 1/100\n",
      "34560/34560 [==============================] - 0s 13us/step - loss: 0.1757 - val_loss: 0.0185\n",
      "Epoch 2/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 3/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 4/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 5/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 6/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 7/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 8/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 9/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 10/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 11/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0062 - val_loss: 0.0093\n",
      "Epoch 12/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 13/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 14/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 15/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 16/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 17/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 18/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 19/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 20/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 22/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 23/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 25/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 26/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 27/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 28/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 29/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 30/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 31/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 32/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 34/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 35/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 36/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 37/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 38/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 39/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 40/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 41/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 42/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 43/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 44/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 45/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 47/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 48/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 49/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 50/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 51/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 52/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 53/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 54/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 55/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 56/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 57/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 59/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 60/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 61/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 62/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 63/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 64/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 65/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 66/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 67/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 68/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 70/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 72/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 73/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 75/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 77/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0017 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 79/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 80/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 81/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 82/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 83/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 84/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 85/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 86/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 87/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 88/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 89/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 90/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 8.6934e-04 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 93/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0023 - val_loss: 0.0129\n",
      "Epoch 94/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 329.7945 - val_loss: 2.9671\n",
      "Epoch 95/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 1.2528 - val_loss: 0.2722\n",
      "Epoch 96/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.1984 - val_loss: 0.0804\n",
      "Epoch 97/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0843 - val_loss: 0.0856\n",
      "Epoch 98/100\n",
      "34560/34560 [==============================] - 0s 8us/step - loss: 0.0765 - val_loss: 0.0600\n",
      "Epoch 99/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0591 - val_loss: 0.0408\n",
      "Epoch 100/100\n",
      "34560/34560 [==============================] - 0s 7us/step - loss: 0.0518 - val_loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "reg = [0,5e-4,1e-3,5e-3]\n",
    "reg=[0]\n",
    "scs = np.zeros((int(X_val.shape[0]/576),len(reg)))\n",
    "sctr = np.zeros((int(X_train.shape[0]/576),len(reg)))\n",
    "sct = np.zeros((int(X_test.shape[0]/576),len(reg)))\n",
    "scv2 = np.zeros((int(X_val2.shape[0]/576),len(reg)))\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40,restore_best_weights=True)\n",
    "\n",
    "models=[]\n",
    "for i, j in enumerate(reg):\n",
    "    print(i)\n",
    "    model = get_model(j,20)\n",
    "    models.append(model)\n",
    "    h=model.fit(X_train,Y_train,epochs=100,batch_size=512,validation_data=(X_val,Y_val),callbacks=[es],shuffle=True)\n",
    "    \n",
    "    scs[:,i] = get_score(model, X_val, Y_val, Y_un, 'std')\n",
    "    sct[:,i] = get_score(model, X_test, Y_test, Y_un, 'std')\n",
    "    sctr[:,i] = get_score(model, X_train, Y_train, Y_un, 'std')\n",
    "    scv2[:,i] = get_score(model, X_val2, Y_val2, Y_un, 'std')\n",
    "    \n",
    "    #if(np.mean(sct,axis=0)[i]<0.13):\n",
    "    #    model.save('models/Gij_0_1_S2.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAyAAAAJYCAYAAACadoJwAAAgAElEQVR4XuzdCbRNdRvH8a8hUcqQSJlFyDzPUoaSqEjKHCIZigwhpcxDRSRFZEhCZchM5ikzhYyZiciY+V377KtzSS/u2Xfv/9n3t9dqvXc4+7+f5/N/1uv/3D3FunLlyhW0SUACEpCABCQgAQlIQAIScEEglhoQF5R1CAlIQAISkIAEJCABCUggIKAGRIUgAQlIQAISkIAEJCABCbgmoAbENWodSAISkIAEJCABCUhAAhJQA6IakIAEJCABCUhAAhKQgARcE1AD4hq1DiQBCUhAAhKQgAQkIAEJqAFRDUhAAhKQgAQkIAEJSEACrgmoAXGNWgeSgAQkIAEJSEACEpCABNSAqAYkIAEJSEACEpCABCQgAdcE1IC4Rq0DSUACEpCABCQgAQlIQAJqQFQDEpCABCQgAQlIQAISkIBrAmpAXKPWgSQgAQlIQAISkIAEJCABNSCqAQlIQAISkIAEJCABCUjANQE1IK5R60ASkIAEJCABCUhAAhKQgBoQ1YAEJCABCUhAAhKQgAQk4JqAGhDXqHUgCUhAAhKQgAQkIAEJSEANiGpAAhKQgAQkIAEJSEACEnBNQA2Ia9Q6kAQkIAEJSEACEpCABCSgBkQ1IAEJSEACEpCABCQgAQm4JqAGxDVqHUgCEpCABCQgAQlIQAISUAOiGpCABCQgAQlIQAISkIAEXBNQA+IatQ4kAQlIQAISkIAEJCABCagBUQ1IQAISkIAEJCABCUhAAq4JqAFxjVoHkoAEJCABCUhAAhKQgATUgKgGJCABCUhAAhKQgAQkIAHXBNSAuEatA0lAAhKQgAQkIAEJSEACakBUAxKQgAQkIAEJSEACEpCAawJqQFyj1oEkIAEJSEACEpCABCQgATUgqgEJSEACEpCABCQgAQlIwDUBNSCuUetAEpCABCQgAQlIQAISkIAaENWABCQgAQlIQAISkIAEJOCagBoQ16h1IAlIQAISkIAEJCABCUhADYhqQAISkIAEJCABCUhAAhJwTUANiGvUOpAEJCABCUhAAhKQgAQkoAZENSABCUhAAhKQgAQkIAEJuCagBsQ1ah1IAhKQgAQkIAEJSEACElADohqQgAQkIAEJSEACEpCABFwTUAPiGrUOJAEJSEACEpCABCQgAQmoAVENSEACEpCABCQgAQlIQAKuCagBcY1aB5KABCQgAQlIQAISkIAE1ICoBiQgAQlIQAISkIAEJCAB1wTUgLhGrQNJQAISkIAEJCABCUhAAmpAVAMSkIAEJCABCUhAAhKQgGsCakBco9aBJCABCUhAAhKQgAQkIAE1IKoBCUhAAhKQgAQkIAEJSMA1ATUgrlHrQBKQgAQkIAEJSEACEpCAGhDVgAQkIAEJSEACEpCABCTgmoAaENeodSAJSEACEpCABCQgAQlIQA2IakACEpCABCQgAQlIQAIScE1ADYhr1DqQBCQgAQlIQAISkIAEJKAGRDUgAQlIQAISkIAEJCABCbgmoAbENWodSAISkIAEJCABCUhAAhJQA6IakIAEJCABCUhAAhKQgARcE1AD4hq1DiQBCUhAAhKQgAQkIAEJqAFRDUhAAhKQgAQkIAEJSEACrgmoAXGNWgeSgAQkIAEJSEACEpCABNSAqAYkIAEJSEACEpCABCQgAdcE1IC4Rq0DSUACEpCABCQgAQlIQAJqQFQDEpCABCQgAQlIQAISkIBrAmpAXKPWgSQgAQlIQAISkIAEJCABNSCqAQlIQAISkIAEJCABCUjANQE1IK5R60ASkIAEJCABCUhAAhKQgBoQ1YAEJCABCUhAAhKQgAQk4JqAGhDXqHUgCUhAAhKQgAQkIAEJSEANiGpAAhKQgAQkIAEJSEACEnBNQA2Ia9Q6kAQkIAEJSEACEpCABCSgBkQ1IAEJSEACEpCABCQgAQm4JqAGxDVqHUgCEpCABCQgAQlIQAISUAOiGpCABCQgAQlIQAISkIAEXBNQA+IatQ4kAQlIQAISkIAEJCABCagBUQ1IQAISkIAEJCABCUhAAq4JqAFxjfrmBzpy5AgzZswgXbp0JEiQ4OY76BMSkIAEJCABCUhAAq4KnD17ll27dlG+fHmSJUvm6rH9cjA1IAbN5OjRo6lZs6ZBESkUCUhAAhKQgAQkIIEbCYwaNYoaNWoIJwoCvmpALl26RO/evRkyZAh79uwhderUNGjQgNatWxMnTpz/y9OrVy8mT57Mli1b+Ouvv0iRIgWFChWiQ4cO5M6d+1/7bty4kTZt2rBo0aLA74oXL441Rvbs2aMwDfYuixcvDoxjFXTWrFmjPI52lIAEJCABCUhAAhKIHoFNmzYF/mBsrQGLFSsWPQfx+ai+akCaNGnCoEGDqFevHkWLFmXJkiUMGzYM6+cDBw78v1P5wgsvkChRosDCP0mSJOzduzew7/79+5k3bx5FihT5Z/+tW7dSoEABkiZNSrNmzQI/79+/P8ePH2fFihVkypQpSmWzevVq8uXLx6pVq8ibN2+UxtBOEpCABCQgAQlIQALRJ6D1Wui2vmlANmzYQK5cuQINQb9+/f6RadGiBZ988gnr1q0jR44ctyV28ODBwFmUqlWrMmbMmH/2tb6fPn06Vgds/d7arDMuVvPy1FNPMW7cuNs6ztUPq6CjxKadJCABCUhAAhKQgGsCWq+FTu2bBsS6VKpbt27s2LGD9OnT/yOzc+dOMmTIQPv27enatettiV2+fJnEiRMHTq9NmzYtsO+pU6e47777qF69Ol999dU149WpU4exY8di3UyeMGHC2zqW9WEV9G2TaQcJSEACEpCABCTgqoDWa6Fz+6YBsZ5EYJ3lsM5aXL9Z93PkyZMncNbiZpvVPFiNh3Xp1UcffcSIESP4+OOPsc6kWNvSpUsDl3dZl3o1btz4muGsn1mXe1mfKVy48M0O9a/fq6Bvm0w7SEACEpCABCQgAVcFtF4Lnds3DYh1eVW8ePEC909cv1n3U1y4cAHrMq2bbbFixfrnI9Y9IdYlXZ07dyZ27NiBn0+YMCFwSdakSZN45plnrhnO+lnlypUZP348VapU+b+HOnDgANZ/kberNzXpHpCbzZJ+LwEJSEACEpCABLwRUAMSurtvGpCMGTMGnlxl3Xh+/WadsTh8+DDbtm27qdjs2bO5ePFi4LPW2Q/rTIb1dKv48eMH9h05ciS1a9cOvK+jXLly14w3c+bMwDOhrc/c7HG67733XqCxudGmBuSm06QPSEACEpCABCQgAU8E1ICEzu6bBsSpMyCRSa3H8ebMmZMSJUoEHo1rbToDEnrRaQQJSEACEpCABCQQrgJqQEKfOd80IE7dA3I96Wuvvcbnn3/O6dOnA2dBdA9I6EWnESQgAQlIQAISkEC4CqgBCX3mfNOAWE+56t69u6NPwbJ469atG3ja1aFDh0iePPlNn4L1zTffcPToUT0FK/Ta1AgSkIAEJCABCUjAOAE1IKFPiW8aEOsJWNaTrv7rPSBr164NXE5l3Yy+ffv2wEsHU6ZMGRC0zm5Y2913332NqPVuD+st6Pfeey/W43yvbtYN5tY9IJs3byZVqlSBH199D4h1Jsa6TCsqmwo6KmraRwISkIAEJCABCbgnoPVa6Na+aUAsCuuxuIMHDw68Cd16d8fixYsDbzNv1KgRn332WUBr165dgfeEWO/sGD58eOBnVnPy+OOPY70N/ZFHHgmcvdiyZUtg35MnT/L9999TsWLFf7St3xUsWDDwPpDmzZsHfm69Cd0682G9Cd0aIyqbCjoqatpHAhKQgAQkIAEJuCeg9Vro1r5qQKynV1lPrBoyZAh79+4NnJ1o0KABbdq0IW7cuP/ZgFjv/ujUqRMLFiwInMk4c+ZM4IlaxYsXp3Xr1uTLl+9f0uvXrw+MazU51mZ9tmfPnoGzLFHdVNBRldN+EpCABCQgAQlIwB0BrddCd/ZVAxI6h7cjqKC99dfRJSABCUhAAhKQwM0EtF67mdDNf68G5OZGrn1CBe0atQ4kAQlIQAISkIAEoiSg9VqU2K7ZSQ1I6IaOjaCCdoxSA0lAAhKQgAQkIIFoEdB6LXRWNSChGzo2ggraMUoNJAEJSEACEpCABKJFQOu10FnVgIRu6NgIKmjHKDWQBCQgAQlIQAISiBYBrddCZ1UDErqhYyO4WtDnT8PupXD+DNyfBe7P7FgeGkgCEpCABCQgAQn4VcDV9ZpPEdWAGDSxrhb00e3wSV47+zLvQfE3DZJQKBKQgAQkIAEJSMBMAVfXa2YShByVGpCQCZ0bwNWCPnEAPsxiB1+yDTzewblENJIEJCABCUhAAhLwqYCr6zWfGqoBMWhiXS3ov/+CHmns7Is0hfJdDZJQKBKQgAQkIAEJSMBMAVfXa2YShByVGpCQCZ0bwNWCvnQRPrjPDj5fXXimn3OJaCQJSEACEpCABCTgUwFX12s+NVQDYtDEul7QHySHS+cgRzWo8oVBEgpFAhKQgAQkIAEJmCng+nrNTIaQolIDEhKfszu7XtA908HZY5ClIlQf7WwyGk0CEpCABCQgAQn4UMD19ZoPDdWAGDSprhf0R9nhrz2Q4TGoPdEgCYUiAQlIQAISkIAEzBRwfb1mJkNIUakBCYnP2Z1dL+gBBeHIFkhVEBrMcjYZjSYBCUhAAhKQgAR8KOD6es2HhmpADJpU1wv688dg/xpIkR1eW2yQhEKRgAQkIAEJSEACZgq4vl4zkyGkqNSAhMTn7M6uF/TwirBrISRJBy3WOZuMRpOABCQgAQlIQAI+FHB9veZDQzUgBk2q6wU9uhpsnQF3J4fWWw2SUCgSkIAEJCABCUjATAHX12tmMoQUlRqQkPic3dn1gh5XF375HuIlhPb7nE1Go0lAAhKQgAQkIAEfCri+XvOhoRoQgybV9YKe+DqsGQXEgnePQaxYBmkoFAlIQAISkIAEJGCegOvrNfMIQo5IDUjIhM4N4HpBT20DKwbbCbQ/APHuci4ZjSQBCUhAAhKQgAR8KOD6es2HhmpADJpU1wt69nuw6CNboPV2uDuZQRoKRQISkIAEJCABCZgn4Pp6zTyCkCNSAxIyoXMDuF7Q83vDT13sBFqshyRpnUtGI0lAAhKQgAQkIAEfCri+XvOhoRoQgybV9YJe+inMeNsWeG0ppMhmkIZCkYAEJCABCUhAAuYJuL5eM48g5IjUgIRM6NwArhf0quEwuYWdQIM5kCq/c8loJAlIQAISkIAEJOBDAdfXaz40VANi0KS6XtDrx8F3DWyB2pMgQymDNBSKBCQgAQlIQAISME/A9fWaeQQhR6QGJGRC5wZwvaA3T4VvXrITqD4GslRwLhmNJAEJSEACEpCABHwo4Pp6zYeGakAMmlTXC3rHPBhR2RaoMhRyVDVIQ6FIQAISkIAEJCAB8wRcX6+ZRxByRGpAQiZ0bgDXC3rPzzC0jJ3AM/0hXx3nktFIEpCABCQgAQlIwIcCrq/XfGioBsSgSXW9oA/9CoOK2ALlu0ORJgZpKBQJSEACEpCABCRgnoDr6zXzCEKOSA1IyITODeB6QR/bBf1y2Qk83hFKtnYuGY0kAQlIQAISkIAEfCjg+nrNh4ZqQAyaVNcL+tQf0OdhW6B4SyjzrkEaCkUCEpCABCQgAQmYJ+D6es08gpAjUgMSMqFzA7he0OfPQLeUdgIFG0GFXs4lo5EkIAEJSEACEpCADwVcX6/50FANiEGT6npBX7kCnZMAVyBPTag80CANhSIBCUhAAhKQgATME3B9vWYeQcgRqQEJmdC5ATwp6K4PwoXT8Ojz8MIw55LRSBKQgAQkIAEJSMCHAp6s13zmqAbEoAn1pKB7Z4LThyFTeajxrUEaCkUCEpCABCQgAQmYJ+DJes08hpAiUgMSEp+zO3tS0NZTsKynYaUrAXWnOJuQRpOABCQgAQlIQAI+E/BkveYzQzUgBk2oJwX9aVE4/As8mBde/ckgDYUiAQlIQAISkIAEzBPwZL1mHkNIEakBCYnP2Z09KeghZWHvCkj2CDRd4WxCGk0CEpCABCQgAQn4TMCT9ZrPDNWAGDShnhT0iMqwYx4kSg1vbjRIQ6FIQAISkIAEJCAB8wQ8Wa+ZxxBSRGpAQuJzdmdPCnrMy7DlR0iQFNrudDYhjSYBCUhAAhKQgAR8JuDJes1nhmpADJpQTwp6QkPY8C3EuRPeOWyQhkKRgAQkIAEJSEAC5gl4sl4zjyGkiNSAhMTn7M6eFPTkFrBquJ1Ipz8hdhxnk9JoEpCABCQgAQlIwEcCnqzXfORnpaIGxKAJ9aSgp7eHZRFvQG+3B+Lfa5CIQpGABCQgAQlIQAJmCXiyXjOLIORo1ICETOjcAJ4U9NyusKCXnUTLzXBvSucS0kgSkIAEJCABCUjAZwKerNd8ZqgGxKAJ9aSgF30Es9+zFZqthvsyGiSiUCQgAQlIQAISkIBZAp6s18wiCDkaNSAhEzo3gCcFvfxzmNbaTqLRQkiZ07mENJIEJCABCUhAAhLwmYAn6zWfGaoBMWhCPSnoNaNhYhNbod50SFvEIBGFIgEJSEACEpCABMwS8GS9ZhZByNGoAQmZ0LkBPCnoX76HcXXtJGpOgIfLOJeQRpKABCQgAQlIQAI+E/BkveYzQzUgBk2oJwX920z4+gVbodpIyFbJIBGFIgEJSEACEpCABMwS8GS9ZhZByNGoAQmZ0LkBPCnoXYtheAU7iWc/g9wvOZeQRpKABCQgAQlIQAI+E/BkveYzQzUgBk2oJwW9fw18/pit8HRfKNDAIBGFIgEJSEACEpCABMwS8GS9ZhZByNGoAQmZ0LkBPCnoP36DgQXsJMp+AMWaO5eQRpKABCQgAQlIQAI+E/BkveYzQzUgBk2oJwX91z74KJutUKodlH7bIBGFIgEJSEACEpCABMwS8GS9ZhZByNGoAQmZ0LkBPCnos8egZzo7iaLNoFwX5xLSSBKQgAQkIAEJSMBnAp6s13xmqAbEoAn1pKAvnocu99sK+etDxQ8NElEoEpCABCQgAQlIwCwBT9ZrZhGEHI0akJAJnRvAs4J+PxlcvgA5q8Pzg51LSCNJQAISkIAEJCABnwl4tl7zkaMaEIMm07OC7pEG/v4Lsj4DL44ySEShSEACEpCABCQgAbMEPFuvmcUQUjRqQELic3Znzwq6b1Y4uR8yPgG1vnM2KY0mAQlIQAISkIAEfCTg2XrNR4ZqQAyaTM8K+pP8cHQrpC4M9WcYJKJQJCABCUhAAhKQgFkCnq3XzGIIKRo1ICHxObuzZwU9uCQcWAcP5IDGi5xNSqNJQAISkIAEJCABHwl4tl7zkaEaEIMm07OC/vIp2L0EkmaE5qsNElEoEpCABCQgAQlIwCwBz9ZrZjGEFI0akJD4nN3Zs4IeVRW2zYKED8BbW5xNSqNJQAISkIAEJCABHwl4tl7zkaEaEIMm07OC/rY2/DoR7rwX3t5jkIhCkYAEJCABCUhAAmYJeLZeM4shpGjUgITE5+zOnhX096/Buq8hVhzodBRixXI2MY0mAQlIQAISkIAEfCLg2XrNJ35WGmpADJpMzwr6x7fg5y9siQ6H4I74BqkoFAlIQAISkIAEJGCOgGfrNXMIQo5EDUjIhM4N4FlBz+oEi/vZibTZCXcldS4pjSQBCUhAAhKQgAR8JODZes1Hhr5qQC5dukTv3r0ZMmQIe/bsIXXq1DRo0IDWrVsTJ06c/5y2M2fOMGLECCZNmsSGDRs4evQo6dKlo2LFirRv357EiRNfs2/dunX56quvbjieddxUqVJFqUQ8K+h5PWFeNzvmNzZC4tRRil87SUACEpCABCQgAb8LeLZe8xGsrxqQJk2aMGjQIOrVq0fRokVZsmQJw4YNw/r5wIED/3PaNm7cSM6cOSlRogTly5cnefLkrFq1KtDIWI2I9fW99977z/5XGxCrCYkdO/Y14z7//PPcddddUSoRzwp6yQCY2cGO+fUVcP8jUYpfO0lAAhKQgAQkIAG/C3i2XvMRrG8aEOvMRa5cuWjWrBn9+kVcTgS0aNGCTz75hHXr1pEjR44bTt2RI0fYv39/oAmJvH355ZfUr1+fvn370rJly381IBcuXCBu3LiOlYNnBb3yS5jypp1Hw7nwUD7HctJAEpCABCQgAQlIwE8Cnq3XfITomwakQ4cOdOvWjR07dpA+ffp/pmjnzp1kyJAhcClV165db2vqTpw4QaJEiXjllVcYOnTovxqQ8+fPc/bsWRImTPivMyG3daCID3tW0OvGwvev2lHUmQLpS0QlfO0jAQlIQAISkIAEfC/g2XrNR7K+aUCsS6essxwHDx781/SkSJGCPHnyMH369Nuaui1btpAlSxbatWtH9+7d/9WA3HPPPZw8eZIECRLw1FNP0atXLzJmzHhbx4j8Yc8KetMUGFvDDuXlbyFz+SjnoB0lIAEJSEACEpCAnwU8W6/5CNU3DYh1eVW8ePEC92tcv+XNmxfrcinrMq3b2WrXrs2oUaNYs2ZN4PKuq5vVkFjj5cuXjzvvvJNly5YFLvOyGpKVK1eSNm3amx7mwIEDWP9F3jZt2kTNmjUDOVgxu7Ztnwsjn7MPV/VLyF7FtUPrQBKQgAQkIAEJSCCcBNSAhD5bvmlArDMP1pkO68bz6zfrhvTDhw+zbdu2Wxb7/PPPadSoUeDeD+sekJtts2bNoly5ctSpU4fhw4ff7OO89957dO7c+Yafc70B2b0cvixnx1JpAOStddP49QEJSEACEpCABCQQEwXUgIQ+675pQJw8A/LDDz9QtWpVKlSowHfffXfLN5pbZ0SssxrWDe0324w6A3JwI3xWzA75qV5QqNHNwtfvJSABCUhAAhKQQIwUUAMS+rT7pgFx6h6QmTNnUqlSpcBjfKdOnUr8+Lf+VnDrEbxTpkzBujk9KptnBf3nDuifxw75iU5QolVUwtc+EpCABCQgAQlIwPcCnq3XfCTrmwbEesqVdaN4KE/Bmj9/fuBmcutsypw5cwJPt7qdzXqM77FjxwIvQYzK5llBnzwEfTPbIZd4C554Jyrhax8JSEACEpCABCTgewHP1ms+kvVNA2I9Act60tV/vQdk7dq1gfd8WDePb9++PfB43ZQpU/4zlcuXL6dMmTKBR/hajUiSJEluOM2nT58OXJJl3XweeRs7dizVq1cP3Dfy2WefRalEPCvoc6eg+0N2zIWbwJPBJ35FKRHtJAEJSEACEpCABHwq4Nl6zUeevmlArDlp3LgxgwcPDrwJvVixYixevDjwJvTITcGuXbsCTUbkm8V///33QPNiPVK3R48egZvZI2/W92XLlg38yGpknn76aZ599lkyZcoUePLW0qVL+frrr0mdOjVWI3P9/rdaL54V9OXL8H5Ew5W3NlT65FZD1uckIAEJSEACEpBAjBLwbL3mI2VfNSAXL14MvItjyJAh7N27l1SpUtGgQQPatGnzz43kN2pA5s2bR+nSpf9zWkuVKoX1GWuz3jPSqlUrfv7558DN5tYZFavxeOaZZ7BehpgsWbIol4enBd3lAbh4FrJXharBly5GORntKAEJSEACEpCABHwo4Ol6zSeevmpAwn1OPC3oXhnhzBF4pAK8NCbcKRW/BCQgAQlIQAISiBYBT9dr0ZKR+4OqAXHf/D+P6GlBf5wDju+G9CWhzmSDVBSKBCQgAQlIQAISMEfA0/WaOQwhRaIGJCQ+Z3f2tKAHFoY/NsFD+aHhHGcT02gSkIAEJCABCUjAJwKertd8YqgGxKCJdLOgr1y5wpnzlzh74RLx74hDwhHlYN8qSJ4Nmiw1SEWhSEACEpCABCQgAXME3FyvmZO1s5GoAXHWM6TR3Czo7X+c4om+8wPxtq+QhVd3vgE7F0DiNPDGhpDy0M4SkIAEJCABCUjArwJurtf8aqgGxKCZdbOg9x8/S9EecwPZv1kmMy0OvwO/TYO7kkGb7QapKBQJSEACEpCABCRgjoCb6zVzsnY2EjUgznqGNJqbBX3s9HnyfDArEG+jUhl4+3Rv2DgB7rgLOhwIKQ/tLAEJSEACEpCABPwq4OZ6za+GakAMmlk3C/rvC5fI8s70QPZ1iqSlc6zBsHqErdHpGMSObZCMQpGABCQgAQlIQAJmCLi5XjMjY+ejUAPivGmUR3SzoK2b0DO0n8qVK1Atfyp63T0Glg+yY397H9yZMMp5aEcJSEACEpCABCTgVwE312t+NVQDYtDMul3Q2TpNDzwJq2LOlAxIMQUW9rU13toKCZMbJKNQJCABCUhAAhKQgBkCbq/XzMja2SjUgDjrGdJobhd0/i6zOHLqPGWyJmdIhgUw5307/uZrIGmGkHLRzhKQgAQkIAEJSMCPAm6v1/xoqAbEoFl1u6CL95zL3mNnKZrxPr7OsRamt7U1Gi+GB7IbJKNQJCABCUhAAhKQgBkCbq/XzMja2SjUgDjrGdJobhd02Q/ns/XwKfKkScz3hbfDpGZ2/PVnQeqCIeWinSUgAQlIQAISkIAfBdxer/nRUA2IQbPqdkFXHrCIdXv/IssD9zC9zB8w/hVbo9b3kPFxg2QUigQkIAEJSEACEjBDwO31mhlZOxuFGhBnPUMaze2CfnHwUpbv/JO0993F/ErnYMyLdvwvjoasFUPKRTtLQAISkIAEJCABPwq4vV7zo6EaEINm1e2CrjtsBfO2/EHye+5kxcvx4KtnbI3nv4Cc1QySUSgSkIAEJCABCUjADAG312tmZO1sFGpAnPUMaTS3C7rJ6FVM3XCQe+LHZUPDZPBFxGVXFT+C/BGXY4WUkXaWgAQkIAEJSEAC/hJwe73mLz07GzUgBs2q2wXd8tu1fLd6H3Fjx2LbGxng00K2RrmuULSpQTIKRQISkIAEJCABCZgh4PZ6zYysnY1CDYizniGN5nZBd/h+A6OX7w7EvLX1o9zxSS47/tIdoFSbkHLRzhKQgAQkIAEJSMCPAm6v1/xoqAbEoFl1u6C7/vgrXyzcGRDY0DY/91JvbJsAACAASURBVPTLbGsUawFlI15KaJCPQpGABCQgAQlIQAJeC7i9XvM63+g4vhqQ6FCN4phuF/SHM7fQf+62QLTL2xQjRf+0duQFGsLTfaKYhXaTgAQkIAEJSEAC/hVwe73mR0k1IAbNqtsFPWjednpO3xwQmNeqFOk+TQ1XLkPuGvDspwbJKBQJSEACEpCABCRghoDb6zUzsnY2CjUgznqGNJrbBT188U7em/xrIOZpLUqQdfijcO4EZKsM1UaElIt2loAEJCABCUhAAn4UcHu95kdDNSAGzarbBT325920nbAhIDDhtaLkG1cYTh2Eh8tCzfEGySgUCUhAAhKQgAQkYIaA2+s1M7J2Ngo1IM56hjSa2wU9ad1+mo9ZE4h5dINCFJtaFv7cAWmLQb2pIeWinSUgAQlIQAISkIAfBdxer/nRUA2IQbPqdkHP+vUQDUesDAgMqZ2fMguqwMENkDIXNFpgkIxCkYAEJCABCUhAAmYIuL1eMyNrZ6NQA+KsZ0ijuV3Qi7YeoebQ5YGY+7+Uh0or68GeZXBfJmhmNybaJCABCUhAAhKQgASCAm6v1/xorwbEoFl1u6BX/X6MKoOWBAR6VclJtc3NYftcuPchaGnfnK5NAhKQgAQkIAEJSEANiJM1oAbESc0Qx3K7Afl1/wkq9F8YiLpzpUeps6cjbJoM8RNBO/sN6dokIAEJSEACEpCABNSAOFkDakCc1AxxLLcbkJ1HTlO6z7xA1G2fzMJrf/aC9d9A7Dug05EQs9HuEpCABCQgAQlIwH8Cbq/X/CcIakAMmlW3C/rQib8p1G1OQKD5E5loeW4QrPzSFun4B8SNZ5COQpGABCQgAQlIQALeC7i9XvM+Y+cjUAPivGmUR3S7oP86e4FcnWcG4n21ZAbaxx0NSz6x42+7CxIkiXIu2lECEpCABCQgAQn4UcDt9ZofDdWAGDSrbhf0+YuXydxxWkCgZuE0dEk0Beb3sEXe/BUSPWSQjkKRgAQkIAEJSEAC3gu4vV7zPmPnI1AD4rxplEf0oqAfbj+Vi5evUCVvKvo+NA9mdbLjb7oSkmWKci7aUQISkIAEJCABCfhRwIv1mt8c1YAYNKNeFHSOd2dw8txFKuR4gE8zr4EfW9kir86DB/MYpKNQJCABCUhAAhKQgPcCXqzXvM/a2QjUgDjrGdJoXhR0ga6z+ePkOUo/cj/D8myHHxrbOdSdCumKhZSPdpaABCQgAQlIQAJ+E/BiveY3QzUgBs2oFwVdqvdP/H70DIUzJOWb4ofh29q2SI3xkKmsQToKRQISkIAEJCABCXgv4MV6zfusnY1ADYizniGN5kVBP/nxAjYfPEmuVImY+OTfMKqKncMLX8Gjz4aUj3aWgAQkIAEJSEACfhPwYr3mN0M1IAbNqBcF/ezAxazdc5zMKRIy8/l4MOxJW6Typ5CnhkE6CkUCEpCABCQgAQl4L+DFes37rJ2NQA2Is54hjeZFQb/8xTKWbD9K6qQJWFjrPhhc0s6hQh8o2DCkfLSzBCQgAQlIQAIS8JuAF+s1vxmqATFoRr0o6PrDf2bO5sMkSxiPla9lgE/y2iJlOkPxNwzSUSi+Fvj7L4ifyNcpKjkJSEACEvCHgBfrNX/IBbNQA2LQjHpR0K9/vZof1x/g7nhx+OWtXPBhFlukZBt4vINBOgrFtwIrvoCpre0zbhV6+zZNJSYBCUhAAv4Q8GK95g85NSBGzqMXBd163DrGrdpL7FiwvVMxYvVMa9sUaQrluxrppKB8JvBVJdg5HxI+AG9t8VlySkcCEpCABPwm4MV6zW+GOgNi0Ix6UdCdJm5kxNLfAwqbO5chfvfktki+evDMxwbpKBTfCgwpA3t/hviJoZ1di9okIAEJSEACpgp4sV4z1SKqcakBiapcNOznRUF3n7qJwQt2BLJZ26ksifumgkvnIEc1qPJFNGSpISVwncCgYnBoI8RNAB0PikcCEpCABCRgtIAX6zWjQaIQnBqQKKBF1y5eFPTHs3/j49lbAyktfftxUn6WFc4egywVofro6EpV40ogKNAvNxzbaX//7nGIFUs6EpCABCQgAWMFvFivGYsRxcDUgEQRLjp286KgB8/fTvdpmwPpzGlVioyjCsNfeyBDaaj9Q3SkqTElcK1An0fgVMSZj46HIe6dEpKABCQgAQkYK+DFes1YjCgGpgYkinDRsZsXBT1i6S46TfwlkM6UZsXJ/n1ZOLIFUhWEBrOiI02NKYFrBbqnhnMn7J+1263H8ao+JCABCUjAaAEv1mtGg0QhODUgUUCLrl28KOhxK/fQevz6QErjGxch/8znYf8aSJEdXlscXalqXAkEBd6/Dy5ftL9v9Rvck0I6EpCABCQgAWMFvFivGYsRxcDUgEQRLjp286Kgp6zfT9Ov1wTSGfFKQUouqQe7FkKS9NBibXSkqTElEBS4eB663B/8vsV6SBLxKGg5SUACEpCABAwU8GK9ZiBDSCGpAQmJz9mdvSjouZsP8crwlYFEBtfKR/m1zWHrDLg7ObS2b07XJoFoEzh7HK6+e8Y6yOs/w/2Zo+1wGlgCEpCABCQQqoAX67VQYzZtfzUgBs2IFwW9ZPsRXv5ieUChX/XcVN7aAX75HuIlhPb7DNJRKL4UOLEfPswaTK3RQkiZ05epKikJSEACEvCHgBfrNX/IBbNQA2LQjHpR0Gt2H+O5T5cEFLo/n4OXDvSENaOAWPDuMT0S1aD68GUoR7fDJ3mDqdWfBakL+jJVJSUBCUhAAv4Q8GK95g85NSBGzqMXBb3l4EnKf7wg4NGpYjZeOTEIVgy2fdofgHh3GWmloHwicGA9DC4RTKbOZEhf0ifJKQ0JSEACEvCjgBfrNb856gyIQTPqRUHvPnqGkr1/Cii0Lv8Ir18aBYs+slVab4e7kxkkpFB8J7B7GXxZPphWjfGQqazv0lRCEpCABCTgHwEv1mv+0bMzUQNi0Ix6UdCHT/5Nwa5zAgpNSz/MWwkmwdwutoqeSGRQdfg0lO1zYeRzweSqjYRslXyarNKSgAQkIAE/CHixXvODW+Qc1IAYNKNeFPSpcxfJ/u6MgEL94ul55755MONtW+W1pZAim0FCCsV3ApumwNgawbSeHwI5X/BdmkpIAhKQgAT8I+DFes0/enYmakAMmlEvCvripcs83GFaQOGlgmnonnYVTG5hqzSYA6nyGySkUHwnsH4cfNcgmFalAZC3lu/SVEISkIAEJOAfAS/Wa/7RUwNi3Fx6VdCZO0zj/KXLPJfnIT7Ktg0m1Ldtak+CDKWMc1JAPhJYNTzY8FppVegDBRv6KEGl4juBkwftR5U/UkEvzfTd5CohCdyagFfrtVuLLjw+pTMgBs2TVwWdq/NM/jp7gScffYDPChyCb16yVaqPgSwVDBJSKL4TWDYIprcLplWuCxRt5rs0lZCPBMbXh43jIcNjUHuijxJTKhKQwK0KeLVeu9X4wuFzakAMmiWvCrpwtzkcPPE3JTPfz4jHzsCIyrZKlaGQo6pBQgrFdwIL+sDcD4JpPd4RSrb2XZpKyEcCg0vBgbWQKDW8udFHiSkVCUjgVgW8Wq/danzh8Dk1IAbNklcFXbrPPHYeOU3BdEn5tuIdMOQJW+WZ/pCvjkFCCsV3AnM+gIV9gmlZzYfVhGiTgKkCAwrAkd8gQVJou9PUKBWXBCQQjQJerdeiMSXXh1YD4jr5fx/Qq4Ku0G8hvx44QY6HEjG5WlIYVMQOsnx3KNLEICGF4juB6W/Dsk+DaRVpCuW7+i5NJeQjgQ8fhRN7IW586HjIR4kpFQlI4FYFvFqv3Wp84fA5NSAGzZJXBV1l0BJW/X6MjPffzZxX0kG/XLaKLocxqDp8Gor1xDXrRvSrW4GG8HSkMyI+TVtphbFAz3Rw9pidQKc/IXacME5GoUtAAlER8Gq9FpVYTd1HDYhBM+NVQdccspxF247wUOIELG6aA/o8bKsUbwll3jVISKH4TmBCQ9jwbTCtPLWg8gDfpamEfCTwwf1w6bydULs9EP9eHyWnVCQggVsR8Gq9diuxhctn1IAYNFNeFXTDESuZ9eshkt4dj9Vti0G3lLZKwUZQoZdBQgrFdwLf1IDNU4Jp5agGVb7wXZpKyCcCly7CB/cFk2m1Be55wCfJKQ0JSOBWBbxar91qfOHwOV81IJcuXaJ3794MGTKEPXv2kDp1aho0aEDr1q2JE+e/T5OfOXOGESNGMGnSJDZs2MDRo0dJly4dFStWpH379iROnPhfc7lx40batGnDokWLAr8rXrw4vXr1Inv27FGed68KuvmYNUxat5/4d8Rm8/tPQuckwBXIUxMqD4xyPtpRAjcVGPkcbJ8b/FjWZ+DFUTfdTR+QgCcCf/8FPdIED91sNdyX0ZNQdFAJSMA7Aa/Wa95l7PyRfdWANGnShEGDBlGvXj2KFi3KkiVLGDZsGNbPBw7874W01UzkzJmTEiVKUL58eZInT86qVasCjYzViFhf33tv8DT71q1bKVCgAEmTJqVZM/udBf379+f48eOsWLGCTJkyRWmmvCrotuPXM3blnkDMO7pVIHb3h+DCaXj0eXhhWJRy0U4SuCWBoeVhz7LgRzOVgxrjbmlXfUgCrgucOAAfZgkettFCSJnT9TB0QAlIwFsBr9Zr3mbt7NF904BYZy5y5coVaAj69ev3j1KLFi345JNPWLduHTly5Lih3pEjR9i/f3+gCYm8ffnll9SvX5++ffvSsmXLf35VtWpVpk+fzqZNmwJnWazNOuOSNWtWnnrqKcaNi9oCyquCfm/SLwxfsiuQx6b3nyRBvyxw+jBkKg81Il2f72ztaTQJwGcl4OD6oET6klBnsmQkYKbAkW0wIF8wtldmQJrCZsaqqCQggWgT8Gq9Fm0JeTCwbxqQDh060K1bN3bs2EH69On/ody5cycZMmQIXErVtevtPd7zxIkTJEqUiFdeeYWhQ4cGxjx16hT33Xcf1atX56uvvrpmyurUqcPYsWOxGpqECRPe9nR6VdA9p29m0LztgXhXdSzDfUMLwrFdkK4E1I10ff5tZ6QdJHATgU/ywdFtwQ+lKggNZolNAmYKHFgHg0sGY6s5AR4uY2asikoCEog2Aa/Wa9GWkAcD+6YBsS6dss5yHDx48F+MKVKkIE+ePIGzFrezbdmyhSxZstCuXTu6d+8e2HXp0qWBy7usS70aN258zXDWz6zLvazPFC58+38V86qg+8/ZyoezfgvksqhtaVKNKQOHf4EH88KrP90OmT4rgdsT+DAbnNgX3OeBnNB44e2NoU9LwC2B35fCsCeDR6s2ErJVcuvoOo4EJGCIgFfrNUPSdyQM3zQg1uVV8eLFC9yvcf2WN29eLly4ELjB/Ha22rVrM2rUKNasWRO4vMvaJkyYgHUJlnXD+jPPPHPNcNbPKleuzPjx46lSpcr/PdSBAwew/ou8WZd01axZM5CDFbNb25CFO+jy46bA4Wa3LMnDk56HvSsg2SPQdIVbYeg4MVGgR1r4+3gwc9VcTKyC8Ml522wYFen/258bDLmqh0/8ilQCEnBEQA1I6Iy+aUAyZsyIdabDuvH8+s06Y3H48GG2bYt0qcdN7D7//HMaNWoUuPfDugfk6jZy5EisxmTGjBmUK1fumlFmzpwZuInd+ozVSPy/7b333qNz5843/IjbDcioZb/T8YeNgVgmNS1Gzrl1YMc8SJQa3rR/rk0C0SLwQXK4dC44dOK08Eake0Ki5aAaVAJRFPh1InxbO7jz032hQIMoDqbdJCCBcBVQAxL6zPmmAXHyDMgPP/wQOMtRoUIFvvvuO+LGjfuPtB/PgExYtZdW49YFchz7amEKLW8GW36EBEmh7c7Qq0wjSOBGApcvwftJr/1NwhTwln05oDYJGCewdgz8EOnS27IfQLHmxoWpgCQggegVUAMSuq9vGhCn7gGxzmJUqlQpcJ/H1KlTiR8//jXKfrwHZNqGA7w2enUgz+H1CvDYxg7226nj3AnvHA69yjSCBG4kcO4kdE917W/iJ4J2u+UlATMFfh4CP7YKxvbY2/BYOzNjVVQSkEC0CagBCZ3WNw2I9ZQr60bxUJ6CNX/+/MBjdK2zKXPmzLnhk6xu9hSsb775JvAiw3B6CtZPWw5Tb9jPgWoaVCMvT+3qAauG29XV6U+I/d8vcQy9BDVCjBU4eQj6Zr42/bjxoeOhGEuixA0XWNwfZr0TDLJocyj3geFBKzwJSMBpATUgoYv6pgGxnoBlPenqv94Dsnbt2sB7Pqyb0bdv3x54vG7KlCn/EVy+fDllypQJPMLXakSSJLHeBn7jzbrB3LoHZPPmzaRKZf8F9+p7QKwzMdZlWlHZvCro5TuO8uLn9svgPqyWi+cPfwrLIl7c2G4PxA++hDEqeWkfCdxQ4M+d0D/3v3/17nGIFUtoEjBP4KfuML9HMK789aHih+bFqYgkIIFoFfBqvRatSbk8uG8aEMvNeizu4MGDA29CL1asGIsXLw68Cd26mfyzzz4L0O7atSvQZFjv7Bg+3P4r/++//x5oXk6ePEmPHj0CN7NH3qzvy5Yt+8+PrMfzFixYMPA+kObN7et/rTehW2c+rDehP/LII1GaRq8Kev3e41QasDgQc9fnslPj9ChY0MvOoeVmuDfYqEUpMe0kgRsJHPoFBhX99286HII7rr30UYASMEJgZkdY8kkwlFwvwXP2vy3aJCCBmCPg1XrNT8K+akAuXrxIr169GDJkCHv37g2cnWjQoAFt2rT550byGzUg8+bNo3Tp0v85r6VKlcL6TORt/fr1gXGtJsfaihcvTs+ePf/1NvXbKRavCnrroZOU/WhBINSOT2elQayJMPs9O/Rmq+G+jLeThj4rgVsT2LsShjxhf9a69+Pvv+yv2/4OCRLf2hj6lATcFJjSElbaL6UNbFkrwYsj3YxAx5KABAwQ8Gq9ZkDqjoXgqwbEMRWPBvKqoPceO0PxnvYLB1uVzUyzhD/BtNa2QqOFkDKnRyI6rK8FdsyHEREvcUuSDo7tstNt9Rvcc+1ZSF87KLnwEfi+MawbE4w34xNQ67vwiV+RSkACjgh4tV5zJHhDBlEDYshEWGF4VdBHT50jX5fZAYkmj2WkTYpVMLGJLVNvOqQtYpCSQvGNwJZpMCbiJW4P5oX99pPYaLEOrIZEmwRMExhbEzZNDkaVpgi8Mt20KBWPBCQQzQJerdeiOS1Xh1cD4ir3/z+YVwV95vxFsnWaEQiubtF0vJfxNxhX1w625gR4uIxBSgrFNwIbJ8D4V+x0rBqz3jJtba+vgPujdh+Vb2yUiJkCI5+H7XOCsT2QExovNDNWRSUBS+Dodlj/LeSspsupHawIr9ZrDqbg+VBqQDyfgmAAXhX05ctXyNB+aiCQ6gVS0yPHQfj6BTuwaiMhW8RlMgZZKRQfCKweCZOa2onkqGa/e8baGi2AlLl8kKBS8J3Al0/C7qXBtJJmhOYRZ+58l6wS8oXAqKqwbRY8XBZqjvdFSiYk4dV6zYTcnYpBDYhTkg6M42VBZ3lnGn9fuEylXA/Sv8gZGF7BzujZzyD3Sw5kpyEkcJ3A8s+D9xoVagzLI54m9MpMSFNIXBIwT+CzEnBwfTCue1JCq83mxamIJHBVYEBBOLIFkmWGpvb7vrSFLuDlei306M0YQQ2IGfMQiMLLgs7z/kyOnblA2Wwp+KJMHPj8MVvm6b5QoIFBSgrFNwKLPgo+be2x9jCvm51a7UmQoZRv0lQiPhLonxf+3B5M6M5E8PZuHyWoVHwn8FEO+Gs33PMgtNrku/S8SsjL9ZpXOTt9XDUgTouGMJ6XBV2sx1z2HT9LiUzJGFkpCQwsYGdS9gMoZr/rRJsEHBX4qRvM72kPWaEPTH3L/vrlcZC5nKOH0mAScESgbxY4eSA4VKw40OmoXpzpCK4GiRaBXhnhzBFQs+wor5frNUcT8XAwNSAe4l9/aC8L+om+89j+x2nypU3ChJfTwkfZ7PAeexsea2eQkkLxjcCMDrB0gJ1OlaEwob79te478s0U+y6R7mngXMT7aq4m1/EwxL3Td6kqIZ8IdH0QLpyGWLGh059qlh2aVi/Xaw6l4PkwakA8n4JgAF4WdMVPFrJx3wmypbyXqa9mh54Rj0Et2gzKdTFISaH4RiDyS91qfgejnrdTe/4L+4kt2iRgksCVK/BBMrh88dqo2uyEu5KaFKlikYAtYNVs5yTWF/b3HQ7CHQmk44CAl+s1B8I3Ygg1IEZMgx2ElwVd7bOlrNj1JxmS3c3cN4pCl/vtoPLXh4ofGqSkUHwjcPWlbrHj2u+bGRrxuOdKn0De2r5JU4n4RODiOeiS/N/JvLEREqf2SZJKw1cCF/6GrpFe6vrWNkgY8W+7rxJ1Pxkv12vuZxs9R1QDEj2uURrVy4Ku/eUKFvz2Bw/cG59l7Z+A962/9F2AXC/BcxFPJ4pSVtpJAv8h8G1t+HWifW1y3SkwuIT9Qet+kIINxSYBswTO/Am90tsxWfd+XLlkf6331pg1T4omKBC5Zq2fNl8LSSNqWE4hCXi5XgspcIN2VgNi0GR4WdCNRq5kxi+HSJTgDta9Ww56pIG//4Ksz8CLowxSUii+Ebj6fPqED0CdyXrwgW8m1qeJ/LUXPnrUTs6q2VMH7a8b/gQP5fVp0korrAX+2he8n9NKpPEieCBHWKdkSvBertdMMQg1DjUgoQo6uL+XBf3m2LV8v2Yf8eLG5rcuT0HfrHByP2R8Amp952CWGkoCEQLDKsDviyFpBqg9ET6O+IexdEco1VpMEjBL4I/fgk1yihxwaIMdX50pkD7i7J1ZESuamC5wZBsMyBdUeGUGpCkc01Ucyd/L9ZojCRgwiBoQAybhagheFvTb321gzAr7efbbu1UgjvUY3qNbIU0ReGW6QUoKxTcC1rtm9q+BFNmh1vfQJ5OdWom34Il3fJOmEvGJwL7V8EVpO5mMj8P2ufbXL38Lmcv7JEml4SuBA+uDl7ZaidWYAJki7rXzVaLuJ+Ples39bKPniGpAosc1SqN6WdDvT/6VLxfvDMS9sXN5Eg5/HA6ss0/XWqdttUnAaYGrb+hNVRBqjrcv+7O2Ik2hfFenj6bxJBCawK5FMPxpe4yc1WH9N/bXVYdB9ognuIV2BO0tAWcFdi+HLyO9U+mFr+DRZ509Rgwdzcv1ml/I1YAYNJNeFnSfGVsY8NO2gMbPHcpw/7hnYfcSSJoRmq82SEmh+Ebg6ht6Mzxm/xX56hOGCjSAp/v6Jk0l4hOB32bC1y8Em+Sr77CpPBDy1PRJkkrDVwLbf4KRkRoO1apj0+vles2xJDweSA2IxxMQ+fBeFvTAn7bRe8aWQDgLWpcmzbTasG0W3JMSWm02SEmh+EagVwY4cxQeqQDVvw4+r95azFn/UGqTgEkCv3wP4+raEZXpDLPftb9+qhcUamRSpIpFArbA5qnwzUtBDdWqY5Xh5XrNsSQ8HkgNiMcTYEoDMnTRTj6Y8msgnBlvlOSRBa9HPCL1Xnh7j0FKCsU3Al1TwoUzkL0qVB0KXR6Ai2chxwtQZYhv0lQiPhFYMwomvm4n8+wg+OE1++sn3oUSLX2SpNLwlcCG8TChfjClx9+Bkm/5KkWvklEDErq8GpDQDR0bwcuCtm5At25Et7YfXi9G7pVvw7qv7efddzoKsWI5lqcGkgCXL8P71ht6gTy1oPIA6JEW/j6uRz+rPMwUWP45TIt4OluN8TC6qh1nydbweEczY1ZUMVtg9UiY1DRoULwllIk4cxezZULO3sv1WsjBGzKAGhBDJsIKw8uC/mHNPt4Yuzag8XXDQhTd3AN+/sLW6XgY4t5pkJRCCXuB82egW0o7jUKN4ame0DcLnDwAD5e1b0rXJgGTBBZ9BLPfsyN6dT58Xsr+unATeLK7SZEqFgnYApGbZuv7gq9Chd7ScUDAy/WaA+EbMYQaECOmwQ7Cy4KevvEgjUetCsTxZd38PL5nICzuZwfWZifcldQgKYUS9gKnj0DvjHYaxd+EMu9Bv1xwbBekK2G/GV2bBEwSmNsVFvSyI3rz1+AL3vLWgUr9TYpUsUjAFlj0cfBeJev73DXg2U+l44CAl+s1B8I3Ygg1IEZMgx2ElwW94Lc/qP3likAcA1/Oy9N/joB53ezA3tgIiVMbJKVQwl7g+O5/v3hwYCH4YzNYj+VtMCvsU1QCPhOY0QGuPvmq3W7okxku/q17lnw2zb5K56fuML9HMKWsleDFkb5K0atkvFyveZWz08dVA+K0aAjjeVnQP+/6kxc+WxqIvnfVnLxwfiLM7GBn8/oKuP+REDLTrhK4TuDwZvi0kP3Dcl2haFMYXFLvnlGhmCswuQWsGm7H985R6Js5+BS3l8aYG7cii7kCM9+BJZHOzmV8Amp9F3M9HMzcy/Wag2l4OpQaEE/5rz24lwW9cd9fVPzEfuHgB5UfpdYdc2HKm3aADefCQ/kMklIoYS8Q+a3SFT+C/K/A0PKwZxkkywxNfw77FJWAzwQmNIQN30KcO+Gdw3D1PTbpS0GdST5LVun4QuDHt4L3cloJpS4E9Wf6IjWvk/ByveZ17k4dXw2IU5IOjONlQW//4xRP9J0fyKJ9hSy8mmglfP+qnVWdKZC+hAMZaggJRAhEfqv0c4MhV3X4qhLsnA+J08Ab9hPZtEnAGIFvasDmKZAgCbTdBf9cMlgAGsw2JkwFIoF/BH54HdaOCoKkyA6vLRaQAwJertccCN+IIdSAGDENdhBeFvT+42cp2mNuII43ymTijYd+g7E17MCst1RnLm+QlEIJe4HIb5WuNhKyVYLR1WDrDEiYAt76LexTVAI+ExjxLOz4Ce5NBS1/gS8eh32rIHk2aGJfvqpNAkYJjKsHv0S65CpxWnhjvVEhhmswXq7XwtXs+rjVgBg0k14W9PEz58n9vn3jb6NSGXg78wEY+ZytU/VLyF7FICmFEvYCv/wAwwkvDQAAIABJREFU4+rYadSYAJnKwNhasGkS3JkI3t4d9ikqAZ8JDCkLe1dAskeg6QoYXhF2LQQt6nw20T5K5+vq8Nu0YEJ3JYM2232UoHepeLle8y5rZ4+sBsRZz5BG87Kg/75wiSzvTA/EX7tIWt7Pcxq+LGfnU2kA5K0VUm7aWQLXCKz9Ovgm6XrTIG1R+O5VWD82eI29yCRgksCgYnBoIzyYB16dB1+/CL9Nh7vvh9bbTIpUsUjAFrh6WetVj7jxoeMh6Tgg4OV6zYHwjRhCDYgR02AH4WVBX7lyhQztp3LlCryQLxW9S8SBz4rZgT3VCwo1MkhKoYS9wM9D4MdWdhrWS90ezA2TmsHqEfbP3j0OsWKFfZpKwEcC/XLDsZ2QtjjU+xGuXt5yx13Q4YCPElUqvhG4etYuckLWE9zixPVNil4l4uV6zaucnT6uGhCnRUMYz+uCfrTTdE6fv0TFnCkZ8GRi6J/HzuaJTlAiYrEYQn7aVQL/CCzuD7Pesb99/We4PzNMbQ0rPrd/1uEg3JFAYBIwR8B678epQ5CpHNQYBxObwpqIdyp0OgaxY5sTqyKRgCUwqDgcuu6BHm1/hwSJ5ROigNfrtRDDN2J3NSBGTIMdhNcFnb/LLI6cOs8TWZIztEoa+zn31lbiLXgiYrFokJdCCWOBeT2DL7p88xdIlAoiP7PeesqQ9bQhbRIwRaDbQ3D+FDz6HLwwHKa1heWf2dG13w/x7jYlUsUhAVugf17487p7Pt78FRI9JKEQBbxer4UYvhG7qwExYhrMaECK95zL3mNnKZrxPr6unR26R/yfVOEm8GR3g6QUStgLzOoEi/vZabTZCXclhbldYUEv+2ettsA9D4R9mkrAJwLWtamdrYb4CuSuCc8OhNmdYdGHdoJvbYOE9/skWaXhG4G+WeHk/mvT0YuFHZleNSChM6oBCd3QsRG8LuhyH83nt0OnyJMmMd83LgLvR/wFOm9tqPSJY3lqIAlce7nVIbgjPizoA3M/sHFarIMk6QQlATMELpyFrhENccFXoULva+u1+VpImt6MWBWFBK4K9EgLfx+/1kMvFnakPrxerzmShMeDqAHxeAIiH97rgq48YBHr9v5FlgfuYfobJaHLA3DxLGSvClWHGiSlUMJe4J8XZMWCd4/ZN5wvGQAzO9ipNVkOybOEfZpKwCcCp49C7wx2MsXegLKdYdkgmN7O/tlrSyDFoz5JVmn4RuCD5HDpHMSKA1cu2WnVngQZSvkmRa8S8Xq95lXeTh5XDYiTmiGO5XVBvzh4Kct3/kna++5ifuvS0CsjnDkCj1SAl8aEmJ12l0AkgatPEIqXENrvs39xoydjCU0CJggc+x365bQjKd0RSrWGVV/B5Ob2z+rPhtQFTIhUMUjAFrh8Cd5Pan9tvdzVeoCCtVUfA1kqSClEAa/XayGGb8TuakCMmAY7CK8Lut6wFfy05Q+S33MnKzqUgY9zwPHdkL4k1JlskJRCCXuBG71DYc0omPi6ndorMyFNobBPUwn4RODwJvi0sJ1M+W5Q5HXYMB4m1Ld/VusHyFjaJ8kqDV8InDsVvI8zRY7g07Ce/wJyVvNFil4m4fV6zcvcnTq2GhCnJB0Yx+uCbjJ6FVM3HOSeO+OyoXN5GFgY/tgED+WHhnMcyFBDSCBC4KtnYOeCa98iHXlBV3siZHhMXBIwQ2DvKhjyuB1LxY8hfz3YMg3GVLd/Vv1ryPK0GbEqCglYAqf+gD4P2xYZSsOOnyLq9yPI/4qMQhTwer0WYvhG7K4GxIhpsIPwuqBbfruW71bvI27sWGzrVgG+eAL2rYTk2aDJUoOkFErYC1ytrfuzwuvL7HQ2TYGxNeyvX/4WMpcP+zSVgE8ErGbZapqt7epfkHfMhxGVIn42BHK+4JNklYYvBCJfNpjzRVg/1k6r7AdQLOLSQV8k6k0SXq/XvMna2aOqAXHWM6TRvC7ojj9sYNSy3YEctnZ9ijtGVY74K3UaeOO6lxmFlKl2jvECnxaBw7/CQ/nAeipLoOhmw+gq9tfVRkC2yjGeSQCGCNzobMeNzooYEq7CkACHN8OnEZexFmkKSwfYKKXaQem3BRSigNfrtRDDN2J3NSBGTIMdhNcF3fXHX/li4c5ALOveLUei72vBb9PgrmTQ5rqXGRnkplDCUKBfLji2C9KVgLpT7AR2LoSvKtpf6zrlMJxUH4d8o/s9bnRfiI8JlFqYCexbDV9E3JdUpjPMftdOwGpGyncNs2TMC9fr9Zp5IrcfkRqQ2zeLtj28LugPZ26h/9xtgfyWt3+CFDNfh43j4Y67oMOBaMtbA8dAgd6Z4PRhyFQeanxrA+z5GYaWsb9+pj/kqxMDYZSykQKrR8CkZnZo9WdB6oJwoydjGRm8goqRArsWw/CIp11VHhh8wEe+uvBMxEtgYySMM0l7vV5zJgtvR1ED4q3/NUf3uqAHzdtOz+mbAzHNe+sx0i1pB9Y/vNbW6RjEjm2QlkIJa4FuqeD8SXj0OXhhuJ3KwQ3wWXH766d6Q6FXwzpFBe8jgWWfwfS2dkKNF8MD2eFG7wbxUcpKJcwFrr+k9btGeq+Xg1Pq9XrNwVQ8G0oNiGf0/z6w1wU9fPFO3pv8ayCwqc1LkG1dN1g+yA707X1wZ0KDtBRK2ApcuWI/n/7KZchdA5791E7lyFYYkN/+WjdKhu30+jLwBX1g7gd2alffen6jt6P7MnklFZYCv06Cb2vZodcYD983tt/rlfkpePmbsEzJpKC9Xq+ZZBHVWNSARFUuGvbzuqDH/rybthPsm80nvFaUfNsGwMI+dqZvbYWEyaMhaw0Z4wQunoMuEbVUoCE8HVFj1jtnrHfPWFvpDlCqTYyjUcKGCsx5Hxb2vfb/C61GunMS4ArkrgnPDjQ0eIUVIwXWjYXvI84i1/3RvgTr+vvuYiSMM0l7vV5zJgtvR1ED4q3/NUf3uqAnrdtP8zFrAjGNblCIYge+AusfXmtrvgaSZjBIS6GErcCZP6FXejv8os2hXMRfliM/t75EK3iiU9imqMB9JjCt3Y3PBl+9lDDbs1DtK58lrXTCWmDlMJjyhp2C9aTBSc3h0EZ4MA+8Oi+sUzMheK/XayYYhBqDGpBQBR3c3+uCnvXrIRqOWBnI6Iva+Sl74vt/X/fsYL4aKoYK/LUPPspmJ//Y2/BYO/vrv09Aj9T213pSSwwtDkPTtm5Av9H9cH0yw6lDkKkc1BhnaPAKK0YKLP0UZkQ8brfJMpj8BuxZBvdlgmb2v/Paoi7g9Xot6pGbs6caEHPmwvPH8C7aeoSaQ5cHRPq/lIdKl2b/+8kvBnkplDAVuOZej/ehWAs7kYvnocv99tcFGsDTEZe8hGmaCttHAuNfgY0T/v1EwH654dhOSFsc6v3oo4SVStgLRL5vqcU6mNISts+Bex6EVpvCPj2vE1ADEvoMqAEJ3dCxEbwu6FW/H6PKoCWBfHpVyUm1BCvA+ofX2mp9DxkfdyxXDRSDBQ6sg8ElbYAKfaBgQ/trXVMfg4vC8NS/rn7jdyINKmZf1pIyNzSab3gSCi9GCcz54Np7OKe+Bb9OhDvvhbf3xCiK6EjW6/VadOTk9phqQNwW/z/H87qgf91/ggr9FwYifO+ZbNRNtgXGvGhH/OJoyBrxkjiDzBRKGAr8vhSGPWkHXvlTyFMjmETXlHDhDGSvClWHhmFyCtmXAl89AzsXQOI08Ib9oI7ANrQc7FkOyTJD0599mbqSClOB6e1hWcSDEd7eC9PawtrRECs2dPoTYsUK08TMCNvr9ZoZCqFFoQYkND9H9/a6oHceOU3pPvbNaW2fzMJrafeB9Q+vtenN1I7OdYwebNscGPW8TWC9A8R6F8jVrWc6OHsMslSE6qNjNJOSN0jgiydg30q4Pyu8viwY2IhnYcdPcG8qaPmLQQErlBgvYN3zsWqYzfDOUZjRHlYMtr9vfwDi3RXjiUIB8Hq9FkrspuyrBsSUmQDP7wE5dOJvCnWbExBp/vjDtHz0FHwRcdlVxY8gf8TlWAaZKZQwFNg0GcbWtAN/eRxkLhdMom8WOHkAHi4DNSeEYXIK2ZcCAwvDH5vgofzQ0P7/yMD2TQ3YPAUSJIG2u3yZupIKUwHrxYPrv4E48eCdP2B2Z1j0oZ3MW9sgYcT9dmGantdhqwEJfQbUgIRu6NgIXhf0X2cvkKvzzEA+DUukp0OB2PBpITu/cl2haFPHctVAMVgg8vPp60yB9CWCGP1y6Vn1Mbg0jE3dej+N9Z6a9CWhzuRgmN+9CuvHBhd5xiagwGKcwNhasGkSxE8E7Xbb77HRY/UdKwOv12uOJeLhQGpAPMS//tBeF/T5i5fJ3HFaIKyahdPQ5bFEejGcQfXhm1Cufz79Q/mCqV39S3OqAtBgtm9SViJhLtAr443fIn39ZS5x4oZ5ogrfNwKjqsK2WXBPSmi1GZYPhmkRL3dtvAgeiHjpq28SdjcRr9dr7mYbPUdTAxI9rlEa1YSCfrj9VC5evsLzeR/iw4ppgi+Msx6VWjbipYRRyk47SSBCYOlA+3pka7OeT588a5BmcCk4sNb+x9H6R1KbBEwQ+OfhCFWg6pfBiGZ0gKUD7O+tvzJbf23WJgETBIY9Db8vsl8gbL1IeM1omNjEjqzedEhbxIQowzYGE9ZrYYsXEbgaEINm0ISCzvHuDE6eu0iFHA/wabVHoWsKW6hAQ3i6j0FaCiVsBRb0hrld7PBbrIckaYOpDC2vl2WF7cT6NPDLl+H9JHZyeWpB5YiGw/r+p24wv6f9u5ab4N4HfYqgtMJO4PPSsH81pMgOry2GX36AcXXsNGpMgExlwi4lkwI2Yb1mkkdUYlEDEhW1aNrHhIIu2HU2h0+eo/Qj9zOsbgF4PylcuQy5a8Czn0ZT5ho2Rgn8v5shR1SGHfMgURp4M9LjTmMUkJI1SuDcKej+kB1SodfgqR7B8BZ9DLPftb9vugqSPWxU6AomBgtcfznrttkwqooNcv3TB2MwU1RTN2G9FtXYTdlPDYgpM2HAU7AsilK9f+L3o2colD4pYxsVge6p4dwJyPYsVPvKIC2FErYC09rB8kF2+O33Q7y7g6l8/SL8Nh3uTg6tt4ZtigrcRwKnDkOfTHZCJVrBE52Cya34AqwXvFlbowWQMpePElcqYS3wcU44/nvwwQm7l8GX5e2UKg+EPBFPIgzrJL0LXg1I6PZqQEI3dGwEEwr6yY8XsPngSXKlSsTEpsWhzyNw6iA8XBZqjncsVw0UgwUmNYPVI2yATscgduwgxre19bbeGFwaRqb+507on9sO7fF3oGREw2F9v/Zr+OE1+3f1pkHaokamoKBioEDvTHD6MGR+El4eCwc3wmfFbIinekGhRjEQxbmUTVivOZeNNyOpAfHG/YZHNaGgn/t0MWt2HydzioTMfLMU9M8Df+6AtMWg3lSDtBRK2ApMaAAbxkHcBNDx4LVp6LGmYTutvg088sLtyR5QOKLhsBLWdfXmTvu5k3DnPebGF92RdUsF50/aL3q1Lrn6f410dMfiw/FNWK+FO6saEINm0ISCfvmLZSzZfpRUSRKwqO3j8FlxOLgBUuaGRvMN0lIoYSsw5mXY8iMkSAptd16bxqTmsDriUr/rz46EbcIKPKwF9qyAoWXtFCp9AnlrB9PZOgtGV7W/rzYCslUO61R9E7x1Zmri6/ZlRtacxbTtypV/3795+gj0zmhLFG8JZSLuXYppNg7la8J6zaFUPBtGDYhn9P8+sAkFXX/4z8zZfJhkCeOxsmNZ0FOJDKoQn4Qy4lnY8RMkSg1vbrw2qaltYMVg+2cdDsIdCXyStNIIW4HtP8HIZ+3wqwyFHBENh/X970tg2FP2754dBLlfDts0fRX46GqwdQbEuwfa7/VVareUzMVz0CW5/dECDeDpvnDhLHR9wP5ZwVehQu9bGkofurGACeu1cJ8bNSAGzaAJBd3069VMWX+Au+PF4Zf3n4SRz8H2uXDvQ9DyV4O0FErYCgwtB3uWQ7LM0PTna9OY+Q4s6W//rM1OuCtp2KapwH0isPlH+CaisXjpG3gkouGw0tu/Fj4vZSdaoQ8UbOiTpMM8jat/OLPSiIlnUs8eg57p7Eks2gzKdYHAWZH74MolPdXSgfI2Yb3mQBqeDqEGxFP+aw9uQkG3HreOcav2EisW7OhWgVjf1oJNkyF+Ymj3e2haly/BpklwdDtYX1++CJcv2P97yfr66n8X4M5EUKQJJEoV2jG1t3kC/++yvmveq7AZ7k1pXvyKKGYJrB8H3zWwc649CTJENBzW90e2woD89u+sF7VaL2zV5r3AwELwx2Y7jrf3xrx7QU7shw8jXvBaqi2Ujnjxa/c0cO4vyFoJXhzp/TyFcQQmrNfCmC8QuhoQg2bQhILuNHEjI5bajcbmD54k/uQmsP4biH0HdDoSmtaG8TCh/q2PketleC7ica23vpc+abpA/7zw5/YbP9hgYV+Y876dQfO1kDS96dkoPr8LrBwGU96ws2wwF1LlC2b8Xws9v5uYnt/VpzdaccbEF0Raf+T7JK89S2Xeg+Jv2l9/mA1O7IOMT0Ct70yfRaPjM2G9ZjTQLQSnBuQWkNz6iAkF3X3aJgbP3xFIeW2nsiSe2xZWfmkTdPwD4saLOsfU1rDi81vf/6H80HDOrX9enwwPgb5Z4OQBeLgM1JxwbcxLB8KMiL/WNVkGySP+ihcemSlKPwr8v5o8exx6prWzLtIUynf1o0D45dTlAbh41o779RVw/yPhl0MoEVsPjrHONFtb5EfuDigAR36D1IWg/sxQjhDj9zVhvRbuk6AGxKAZNKGgP579Gx/Ptl8At6Td4zy4tj/M62YrNVsN90U8RSMqbiOfh+1z7KcfNV4IseNe+1+cO+zvrRs+dy648U3KUTmu9jFLoEca+Ps/LgP4eQj82MqO99V58GAes2JXNDFPYH5v+KmLnXeL9ZAkouGwvr90AT5IZv8u/ytQ8aOY52NaxpFvwLZiu/6slWnxRkc8//Xkts9Lw/7VkCI7vLY4Oo4cY8Y0Yb0W7ti+akAuXbpE7969GTJkCHv27CF16tQ0aNCA1q1bEydOnP87VzNnzmT8+PGsWrWKDRs2cOHCBXbu3Em6dBE3ckXau27dunz11Y3fCm4dN1WqqN23YEJBD56/ne7T7Gtn57QqRcaD04OXTdUYD5kiHkcZlcrvlxuO7YRUBaHBrP8e4ep7IuLEg46HCdyQos0/Au8ns+/9yVkdno944tXV7NaMholN7O9emQFpCvsnb2USngKz34NFEY1F6+1wd0TDcTWb/1fP4ZlxeEd98hD0zRzModYPkLF0eOd0u9HvmAcjIh4JHfnJbcMrwq6FkDgtvLH+dkfV5yMJmLBeC/cJ8VUD0qRJEwYNGkS9evUoWrQoS5YsYdiwYVg/Hzhw4P+dK6upGDNmDDly5ODcuXP/Y+8soKUq/jj+oaWRRkq6G6RBQFokRDoFJAREpEH9I9IIiqSUSqeIdIp0d3d3gzT+z+zchfvgvd27+/btzu6bOcdzHnt/84vvjLvzu/ML9u/f79QBEU5IRHMXZ6BGjRrEiBHDrX2hwoaevOk0X/95wKb/wnbFyB7hJPzyvrTn9SZcrlgp3hR+n0RW4Aju4GnmtawnbBohP9GVkFxBWX1aZ2+MzXlCjf6EtMbeU98yrWGgImAOHQ2uNPSA1PDoNmT+EOpMDVQU/Meua0dhZIFX+taeAlmq+I/+ntD0yBKYXkdyqjMNMleWf0+rA0eXQIyE0OWEJySFWx4qnNf8HfyAcUDErUWuXLlo164dP/3008t1+eKLL/j555/Zs2ePzbkIaVy4cIGECRMSLVo0evXqRd++fZ06IOKWJHLkyB7bAyps6Nnbz9F5jnwzMrtVYQokjQwDUkobC7SAykPcs/f6cRhhJG+W6gklu4TMZ+PPsLyXfN56EyTJ6p5MPUs9BETolQjBEiO4mPlDC2Fmffm87kzIVEE9G7RG4QuB+Z/D7imiZgt8e+vNG9mXib2loeEf4QsbFa01hx8J/cJjf5b9c2HOp3J1xJ5MV1r+bY8uiPwW9Lqi4ur5jU4qnNf8BqwQFA0YB6Rnz57069ePkydPkibNq8o5Iowqbdq09OjRw+ZUWBlWHZAnT57w8OFDYsWK9cZNiBU5r9OosKEX7r1I22m7bKr9/ul7lMiYCAanhwfX5JeYuz+wR5fBtFrS5Nebeb0OhLnspfnL0x1Q9Ry1ELh3GX4wEkJLdIHSPYPqd3wlTPlYfvbJb5DNaACnlhVam/CEwOwmcOAPiBoLelx40/Kf88ONY5CyEDRbFp6QUdPWo8th2ievdDMnYaupsee12jVFdoIXwxzK+tcXsONX+fnXNyCS516get4ItTmqcF5TGyHn2gWMA1K+fHnbLcfly5ffsDpJkiTkyZOHpUuXOkdEFHuyeAMSO3Zs7t27R/To0alYsSKDBg0iXTr3k7RV2NCrD1/h01+323Aa2zAf5bMlhYkV4OwmiJcKOuyzhOEbRJtHw9Ju8mNnycUiAf0348q8+ljIZVwluydZz1IJAXN5yDLfQvGOQbU7vR5+NcIFqv8CuWqrpL3WJTwiYO+qHTMxdJYFOoKMsSXh0m5IkgNarw+PCKlls/kFltCs9NdQopNaOoa1NlvHwWLD5pb/QLJcUqI5vLnrGYgeL6w1CVj+KpzX/B3cgHFARHhV1KhRbUnkr4+8efPakspFmJaV4cwB6datm41fvnz5bCFbmzdvtoV5CYdk+/btpE5tqpISgsBLly4h/jOPQ4cO0aBBA5sNQmdfjI0nrlNv3Bab6B9r56ZanuRgDkEQ17aRo7mu2qJOsG2cnNftLLwVN2Qe147AyPfk8w96QzGjBr/rUvUM1RC4vB/GFJVaBfdm8vx2GF9GPq/yE+RropoFWp/whsCkynBmPbydBr7Y/ab1kyrBmQ0QPy20l7fHevgQAfPhW6hRtAOU7e1DhXwgesNPsOIbKbjtdkiYQf69pj+sHSD//vIgxE3uA+UCQ6R2QEK/jgHjgIibB3HTIRLPXx8iIf3q1ascP37cEmLOHJDgmKxYsYJy5crRuHFjfv3VuOJ0IO1///sfvXsH/6XoSwdk19lbVB8lMexfIwd130sF5uZwbbZA4syWcAxCNLk6nFhtLfnNXFu/UBuo0N91eXqGmgiEVB7Srm1I9evVtEZrFR4QEEU4Lu4KuXTplJpwfAXESgqdjoQHRNS28Z/BsNoomyw0LdAcKv+gts6e1u7vAfC38bv55QGIa1TmNOdXhsf+KB7EWTsgoQczYBwQb96AhAS7uBERtxoXL150ujKq3oAcuXyP8j/+Y9P/6w+z0qxYGjj4J8xqJG0yV9RwaqWJ4MeccPuMtQZI//0HfUUjqUeQrQZ8MskVSZpWZQRCKg9p19lcrKDsd1D0C5Wt0bqFBwRGvAfXj4RcPnxWYzg4H6LGhh7nwwMiattoDjMSmuasDTVcaICrtnXWtBO3H+IWRAxzJUnRVHih0RW9xWpIbhSGscZVU5kQ0A5I6LdDwDgg3swBCQl2UYJ34cKFiOR0d4YKG/rsjX8pMXiNTf3O5TPxean0YA6bKdsHirZ3zbxnT6CvKMH7AnLVg+qjnc+3Oyypi0LTxc7pNYV/IHB4McyoK3WtOwMyVQyq9+1z8GN2+Zmzamn+YbHW0t8RGJYd7pyTJaFFaejXx/w2sHsqRIgI39zUfYt8vd4i+VokYdtHpkpQd7qvtfKu/JBKR5vzYxotgLQlvatXAElT4bzm73AGjAMiqlz179/fK1WwQlr0nDlzcuvWLVsTRHeGChv66r1HvNd3lU39tqXS06l8JnjyL/RLJk3K2xg+Gu6aedePwYj8xqGyF5Ts7Hz+hHJwbgvETwftdzqn1xT+gYCzPh/3r8GQ9NKWYh3hg2/9wy6tZeAiMPBdeHgr5D4f5vy2nlcgyluBi4U/WDazARz665Wm7xaHJgv9QXPP6Wh2wr69/copNr8AqjMdMlfynMxwxkmF85q/Qx4wDoiogCUqXYXUB2T37t0IB0Ekj584cYK4ceOSLJlxqH5tFR3lgDx48MDW+0Mkn5vHzJkzqVOnDi1btmTMmDFu7QsVNvT9x8/I/q0sJflp0TR8U8XowWGvde/Ol/mRpTDdqGZUcyJkN8qsOkJpZkM4tECHNbi1kxSetPN3WNBOKthsJaQ0NQwTnz2+B/2NeOVCn0OFfgobo1ULFwj0SQzPH0OOWvCxUUjDbPiKb2HDj/KTzichZoJwAYuyRtq7fdsVTJYbWq5VVt0wUUz0ABG9QKLEgJ6mYjfmCpM1xkFOozR+mCgR2ExVOK/5O8IB44CIhWjVqhVjx461dUIvWrQoGzZssHVCNzsFp0+ftvUJeT1ZfO/evSxYsMC2nitXrmTt2rV89dVXxIsXz/Zf27Ztbc+EI1O5cmWqVatGhgwZbJW3Nm3axLRp00iZMiVbtmyxJcO7M1TY0M+evyB9zyU29UUCukhEtw37l3rsd+CrQ66Zt2kkLOsh53y2Ft7J7Xy++a1ij4sQNabzOZpCfQQ2j4GlXaWerTZAUiPcyq55kE7pzeDDoerbpDUMXARePIfv4kv7REU2UZnt9bF2EKwxekyJMuWiXLkevkNgTDEQxSzsI0F6aPdmdUzfKegFydPrwpHFECMBdDn5SuCFHTDOaEr44TDIbzQr9IJKgSZChfOav2MaUA7Is2fPbL04xo8fz/nz50mRIgXNmzenS5cuLzuWh+SAiMpVwnEJboiyumKeGKLPiHBMtm3bZks2FzcqwvGoUqUKohmi6Kbu7lBlQ2fsuYQnz19QPU9yhtU2nAVzAyNXHYJFX8G28RKW7uchWmznEJkrmbTbCQnc76/iXJim8BoC64bCKqP6myhZKkqXmocoQCAOfCJfKHd9qDbKa6ppQRqBNxB4dBcGpJQfh3Qjt3EELDcaaroEVxHRAAAgAElEQVRbJVBD7zkEfswBt8++4hcrCXQ66jn+/sDp96ogCn7ETQlf7n+l8bWjMNK4dXYnn9MfbPeSjqqc17xkbpiICSgHJEwQ8iJTVTZ0rt7LufPwKeWzJWFsQyN3w1y+r9V6SGrcjFjB5/dqcHINhNTIKzgeOyfDAnnrRNMlkLqIFUmaRnUERHlM4VyK8dURiJ30TY37JoOn/8pQPRGyp4dGwFcI3L0EQ42y4yW6QGnD0TDrs30SLDR6FTVfDSl0ZSFfLZdNbv9U8PjOKxVeD0PyqXJeEm7PoUyYEdpueyX0zgUYZoRVl+wGpbp7SaHAE6PKec2fkdUOiEKrp8qGLtRvFZfvPqJExkT8/qnRENCcvPbJb5CtmnXk7G+kUhaCZjK/xOk4tgKm1pRkNSdB9hpOp2gCP0DAXCKz2zl4K86bSg9MAw9vhpz06wdmahUDBIEbJ+BnoynsB/+DYkYJU7N5e2fBvBbyk8Z/QZoSAWK8H5phDpkzqy+qk0WM5IcGuamyPQxNdEAXndDt49EdGGCECBZuC+WN0EE3xYTnaaqc1/x5DbQDotDqqbKhSw35m1PXH/Deu/GZ1aqwRMjcnbz011CikzXknj2WPT1cDam5tBfGFpcyKgyEQq2sydNUaiPwVwfYYfR1+foGRIr8pr4/ZIF7FyH9B9Bgrtr2aO0CGwHz91DFwVDwszftPbQQZtaXn9edCZkqBDYmKlsnqpWJqmWvj65nIHo8lTX3rG4/54MbxyFVYfh06Svez59BH6NIQkg5TZ7VJGC5qXJe82eAtQOi0OqpsqEr/bSOg5fukj15HBa2M5wAdx0Jdx2X+1dhSAa5OuKto3j7qIf/IzCvJeydAZGiwtfXgrfnp9xw6xSkLgZNF/m/zdoC/0Xg7GaYWF7qX3Uk5Gnwpi0nVsPk6vLzjydADuPm1n+t9l/Nb56C4UbeYqRosnqZGOZu4P5rnXXN7VUr05WGhn8Enfe9aPL7ELLXhJoTrPPUlEEQUOW85s/Loh0QhVZPlQ398eiN7Dhzi3SJYrLqq/dfIfSym7kLoVRHlsD0OpLHJ79CNuOH2hnu4iq9T0LXmhc646mf+x4Be43+t+JCN1OiqFmzkYXg2iFInh9ayJ40emgEfILA8ZUwxSgbHtL317mtMKGsVO+jnyFvI5+oqoUCF3fDL0ZzPVHg4qZRAarNZkicJfxA5Kh3zaB08O91yFgR6s0IP5h42FJVzmseNsur7LQD4lW4HQtTZUM3nLCFdceukzxedDZ0M0r2CdXFWz7xti9GQuhywhpy5goxIhZVxKRaHUMywf3LENxbHKs8NJ1aCIjDnDjUOSrn/Mv7cHEXJMkBrderpb/WJnwhcHABzGooba43GzKWe9P+y/thTFH5uQ4X9e3+EJWfRAUoMUQujuh7IUazFZDSyGf0rYbekf59Enj2CHJ8Ah8bFSjtkn/KBbdOgzs9vbyjvV9IUeW85hdghaCkdkAUWj1VNnSL37ez4uAV3o4RhV3fmH5wF3eGrb9IxMTba/EW29lY+CVsNyoZWS3Ba+c5tgRc2gOJs0Gbjc4k6ef+gMDEinB2IziqzT+xApzdBAkyQLvt/mCV1jFQEdgzA/5oKa1rsgjeLfampeIt+/A88vMy30DxrwIVDfXtOjAfZjeWeuZuALunyL8bzIP0ZdTX3xMavngB370tOYnbOHErZx6ji8KV/fBOHvjsb09IDJc8VDmv+TP42gFRaPVU2dDtp+9iwZ6LvBUlIof7VHyFkLmJXIs1kNyoDuMIw98+glNrwZ1a7FNrwbFlbzZTUmjNtCouIjC2JFzaLcs4i3LOwY2Qati7KEqTawRCjcC2CbCoo2QT0neeOV9NOB/CCdHDNwjs+A3+ai9lizKzawfIv12t3Ogb7T0j9ckD6PeO5FWwFVQcGJTvhPJwbrN+wRNKtFU5r4XSDJ9O1w6IT+EPKlyVDd1t7l5mbDtnU+5kv0pEjBhBKmoujVtjPOT8xDl6w3LAnbOQqgh8KjusWx4L2sHO3yX519chUhTLUzWhogiMKADXj4KjkszT6sDRJRAzEXQ+rqghWq1wgcCG4bDia2nq59sgUcY3zX58H/onl58XbA0VjUNvuABIMSM3/AQrDAfwoxGvekmFVEBAMfU9os6D6zDYaNwbXAGXyTXgxCrHYbAeUSSwmahyXvNnlLUDotDqqbKh/7fgAL9ulJ3fD35XnhhRjVKp5lCD97vD+90co/f0kSzBy3/yOrzaSNfQXt0X/hkk53x5EOIaP/KucdHUKiEwNBvcPQ9pS0Gj+cFrNqsxHJwP0eJAd+kI66ER8AkCfw+Av/sb30EHIG6KN9VwFvLiE8XDqdCVvWH9UGl8oz9f5YNUGACFWocPUEQXeNF7S4xSvaBk56B2z2oEB//U36+h3A2qnNdCaYZPp2sHxKfwBxWuyoYeuPQwo/+WSeY7en1AgljRpKKihnjfJPDiGeSoBR+Pc4ze1cMwqqCkcSc2eus4WGz0G2mxGpLrDsMKbVf3VLHSZNBeqjdiFPjmunty9CyNgCcQWP41bBwuOXU5BTHiB8+1bzJ4+i9k/xhqGjlvnpCvebiGwMKOsN0oLdt2B4wwfjNK9YSSXVzj5a/U5tL35fpCkbZBLZnfBnZPhQgRQTRojGBEOPirvT7SW5Xzmo/M94hY7YB4BEbPMFFlQ/+86hg/rDhqM2p911KkeDvGKwPtDY7eyQufrXFs+OFFMKOepHEnBvfQXyDKtopRZzpkruQZoDUX3yHgqDqLXasF7WHnb/Jf4a2Dse9WRksODoFFX8E2o4pQr6sQ2XgZ8zqtLm2qxv6Z8ynsnwuRo0PHgzAojdSrSHso10cNHcNaC1FBUFQSFKPyUCjQLKjExV1g61j5WY9LENX0+x7WugUQf1XOa/4MqXZAFFo9VTb0+HUn+X7RIRsyK74sQYYksV+hNK02HF0qK2CJ7rKO3p5s/BmW95JzRcKxSDx2ZZzbBhM+kDM+HAb5P3VltqZVDYEgoSqN4SPjzfLrei7pClvG6B9I1dYvPOrzRyvYMx0iRIJvboT8fSdCXkToiyj92viv8IiUGja/zG9IBh32yV5SYuRrClV+VEPHsNbizEaYZBSPqTYGctcNKtEcptbpOMRKFNYaBSR/Vc5r/gyudkAUWj1VNvSUzWfoNX+/DZkFbYuSM0W8Vygt7QGbjVyOzichZoKQEfyrA+yYJJ93vwDRYrmGtjmWVVQ0KdXdtfmaWi0ErCbriiRSkUwqhqOwF7Ws09oEIgIzG8KhBRAtLnQPoXGmsHtUYbh6UIaJinBRPXyDwLgycGE7JMoMn28BKzeuvtE07KQGaZ75G2SrFlTWuh9g1Xfys/a7QDRs1MNlBFQ5r7msuEITtAOi0GKosqHn7TxPx1l7bMjM/KwQBdOanAxzWcpPl0MqI8cjOBx/qyIbQcVKCp2OuI70s8fwfWI5Lzy9wXIdKf+Ycf8aDEkvdXVUrnRNP1hrlI7seAjiGCUl/cNKrWUgIfCycWYy+OpwyJa9PPhmgc83BxIC/mWLPUTYXmVvcHp4cA0yVoB6M/3LFne1NYcuB9c8c8tYWGLkw7gTmeCuXgE2T5Xzmj/Dqh0QhVZPlQ29ZN8lWk/daUNmUtMClMpkOAHiA3On2WqjIbeR4xEcjvaKR6mLQtPF7iE98F14eAsyVYK6093joWepgYDoviu68IpRuheUeK06i13LdUNhVW/5L/2GTo21C69a2Btnxk8H7eV3YrDD/rIlXioZ+qOHbxB43eEQDSJF9cbQ/Ab5xhL3pe6dBfNayPmNF0Ka4kF57ZoKf7aRnzVdCqkLuy8rHM9U5bzmz0ugHRCFVk+VDb3myFWaTtpmQ2Z0/bxUzJHsFUq3z8GP2eW/i3eCMkaN/NdxfPrQKMEL5GkIVUe4h/TIgnDtMFhJendPgp7lLQSuHoJRhaS08v2hsPEj+Lr8TaNgmRFu12YzJM7iLQ21HI1AUATGFIfLex03zhQzpteFI4t101Rf7p///oM+ieDFU8hZG2r8Ai/XLye0WudL7bwne8ev8NcXUl7z1ZDiteqR5m7x9edCBiPP0nsaBoQkVc5r/gymdkAUWj1VNvSWkzeo/YsMIxhaKxc18ppq34tE4n7J4NkjyFoNahnVil7H0XzYLPMtFDe6CbuKt72TepzksqqJHv6LwPkdML601L/KT5CvSfC2WOk+7b8oaM39CQF7SE+qwvDp0pA1n9MM9s+R1Zd6XfYnCwNHV3MH8PdaQqVBMKkynFkPb6eBL3YHjq2OLNk8GpYaPbpab4IkWYNSB8kR+RWyVQ8fuHjYSlXOax42y6vstAPiVbgdC1NlQ+89f5uPRmywKft9tew0KJQ6qOL2hEtR1UrEkAY3Di2EmfXlk1q/Q9aq7iE97zPYOxMiRoZe1yBiRPf46Fm+R+DUOvjtQ6lHjXGQs1bwOukQAd+vldZAIvBDFrh3EdKVgYbzQkZlQTvY+bt8rktH+2b33L0IQ43b0pJdoVQPsFdtjJkIOh/3jV7elhokyXw3xDdKEdv1OLsZJpaX/wpPHeI9vA6qnNc8bJZX2WkHxKtwOxamyoY+duUeZYf9Y1O2V+UsNC/+WpWMGfXh8EKIEhN6XAi+NKWoYiSqGYnRagMkNcK2XMXb3AjMWdUtV3lreu8icHQZTDOcjtpTIYvhjLyuhajjL+r5i9FwPqQr5V09tTSNgB2BAang0R3IUgVqTwkZl6XdYfMo+bz7eYhmKl2u0fQOAlcOwmgjn6F8Pyj8OcxtDvtmQ+S3oNcV7+jhaymrv4d/BkstvjoKsZME1ejyfhhTVH5WYSAUauVrjf1SvirnNb8Ez1BaOyAKrZ4qG/r8rX8pNlA2GexYNiPty2QIitKKb2GDUVO942GIY8oRsVOKGFQRiypGj4sQNaZ7SG8aCct6yLmtN0KSbO7x0bN8j8CBP2C2EXbVYB6kLxO8TuYGlnVnQqYKvtddaxA+EfguoZFTUAdqGM3bgkNiVR9YNyTkQ1/4RM+7Vpv7X1QdBXnqw8IvYbvRmf7r6xApind18oW0ZT1hk5Fz2e0cvBUnqBY3T8Hw3PKz0l9DiU6+0NLvZapyXvNnILUDotDqqbKhb9x/TL7vV8oz//vp6Fohc1CURKiBCDkQo8kieLfYmyj++iGcXgexnZSvdIb/vjkw1+jk6ujQ6oyPfu57BMyhVZ8ug1RGQvrrmukYZd+vldYAnj2B740mbfmbwYdDQ0ZF91bw/Y45sgSm15F61JkGmSuD+QY9vPQUcuZ0PbgOg9NJnIp9CR/8z/dr54caqHJe80PoXqqsHRCFVk+VDf3vk2dk/WaZ9C+KvMv/Pnrt1uH0Bvi1kkSuynDI1/hNFIdmhbsXIHUxaLrIfZTNeQPOyv66L0XP9AYCW8fBYuNtW8t/IJlRkvd12eb9VX0s5DIOFd7QUcvQCNgREOW/RRlwMYq0g3Lfh4zN5jGwtKt8HpqQU42++wjsng7zjXAi+4uxtYNhjbFuX+yFt1/LZ3Rfmroz/2gFe6ZDxCjwzfU39TRXqHzvM6hkhGupa5GSmqlyXlMSHItKaQfEIlDeIFNlQ7948R9pe8i+HbXzp2RgzZxBzb93BX7IaPwwt4dyfYI+f/KvrJQlRt5G8NHP7sN3/RiMyC/nh6aalvsa6JmeQsCcF9R2ByQ0mhK+zt9qtSxP6aX5aASCQ+DOBRhmVBAq2Q1KGaWhg6PdORkWtJVPnDVo1WiHDQLm6k92JzBIRahwEsI7qxEc/BOixYXuZ9/EWpQr/i4B/PccctWD6qPDZj0CnKsq5zV/hlk7IAqtnkobOvPXS3j09AUf5XqH4XXzBEVJfIH1TwFP7kPmD6HO1KDPzcmAH/SGYh3cR/nRXRiQUs4v2AoqGh2y3eeoZ/oKgTX9Ye0AKf3LgxA3efCa6CRJX62QlmtGwPzyo+x3UNTorRAcSkEKJ/wB6Yxy0xpR7yHw9wD4u7+U12E/xEsJu6bAn58bjqGDsE/vaRn2kqZ+AseWQ6yk0OlI8PL6p4LHorjCR1B7ctjrFIASVDqv+Su82gFRaOVU2tB5vlvOrX+fUjZrEsY1Mm4gzFjZGzwlygKfy54hL8ehv2BmA/nPWpMh60fuoyycnX7vwNN/Zb3yT4zEdvc56pm+QsAcj931NER/O3hNrh+HEUbzrNA6sL6yVcv1fwQu7oJf3pd2VP4BCjQP2aYjS2F6bfncUYU3/0dFXQuWdIMtxtt8eyUycRMgbgTEqD8HMpRVV39PaWbPv3TU++RleenS0PAPT0kOV3xUOq/5K/DaAVFo5VTa0EUHrObC7YcUS5+QKc0LvonS7KZwYB5EigY9Lwftz7H+R1j5rZzjicpVP+WGW6cgVRH4dIlCK6ZVcQmBRV/BtvFySq+rEDla8NPvnIdhRt7R+z3gfSO23iVhmlgjEEoEzLlI1cZA7rohMzTnqlX/BXIZzkgoVdDTXUDgj9awZxpEiATf3JDl4Y+vgik1JJOakyC78bcLbP2OdFxpuLADEmeDNhuDV39EAbh+FFIWhGbL/c5EFRRW6bymAh7u6KAdEHdQC6M5Km3oMj/8zYlrD8iX+m3mti7ypsXmWuMd9kG8VK9ozE25elyCqDFCh9jECnB2E8RPC+13hY6Xnu07BOa3gd1Tgx4QgtMmSJWWjvCB4cz6TnMtOTwicGwFTK0pLXfWTFUc+MTBT4wPh0F+o49NeMTNVzZPrwtHFkP0+ND1lNTi3DaY8IH8O6SCKb7SN6zk2hsFJ88PLVYFL0Xc7IkbPkdOSljpFyB8VTqv+Suk2gFRaOVU2tAf/ryO/RfukjVZHBZ/UfxNlMwVR15vFme/Ao6THDoeDD3C9qQ60fiw58XQ89McfIPArMZwcD5EjQ09zoesw+N7MsdIjEJtoIIR1+0brbXU8IrAgfkw26jwV38uZDAOssHhcfUwjDJuisv1hSJGQnp4xc4Xdk+sCGc3Bn1RdfUQjDLKfdubE/pCN2/K/CkX3DoN7xaHJguDl2z/jY6XGjrs9aZ2ASNLpfOav4KqHRCFVk6lDV1rzCa2nr5JmoQxWdPJiIM2Y2V+s1RpCLzX4tVTe3ypoy9AV3Bf3AW2Gk3AdJdhV5BTi3ZqLTi2DGIlgU5HQ9bt+VPok1A+F2+SxRtlPTQC3kbA3Lem6VJIbXTZDk6P2+fgx+zyiQ4b9PZKSXmjisDVA/BOXvhMNtIlSDhnd3i/m29086bUIRnh/hXIUB7qzwpe8rQ6cHQJxEgAXU56U7uAkaXSec1fQdUOiEIrp9KGbjRxK/8cvUbSOG+xuUcwHav/vQmD0kj0zG+pg5TgbQwfDQ89wuYmX47Kt4ZekuYQlghYSY60y+8dX5aJzF0fqo0KS600b41A8AhY7VsjZpu/D0W1LFE1Sw/vImDvPZW2FDSaL2U/ugMDjPDgwm2hfF/v6uQLaf1TwuO7kLUa1PoteA3mNod9syHyW9Drii+09HuZKp3X/BVM7YAotHIqbeiWk7ez7MAV4kaPwp5vywWP0oDU8Oh20Dct5hKqzkpXWsXe/CayyWJ4t6jVmZpOJQSsJEfa9e0rKp89gGw14JNJKlmhdQkvCJiLaTh78fH0EfRNIpEp0AIqDwkvKKlj58vvDFO1xBfP4bv4Use8Hnohpo7FwWsieny8eOa4x8dfX8AOo6Lk1zcgUmTVrVJOP5XOa8qBY1Eh7YBYBMobZCpt6C9n7uaPXReIGikiR/tWDN78cWXgwnaInw7a75Q0BxfArIbyb0+Vozy+EqZ8LHnWnAjZjb+9sShahucQGFkIrh2CFAWg+UrHfAemgYc3IVNlqDvNczpoThoBqwis6Qdrjb5DHQ9BnHdCnqmbu1lFNWzozGGb+ZpAlZ9eyQlPLzOChK82gw+HBo/3sp6waYR81vUMRI8XNusSwFxVOq/5K8zaAVFo5VTa0N3n7WP6VtlF9XjfikSOFPFNpOZ9BntnQsTI0POKfIuyfhis/J+kbb0JkhidhEODs/lWpXx/KNwmNNz0XF8h8GNOuH0G0pSAxn851sIeTpGuDDSc5yuNtdzwjID5kNbtLLwV1zEaL0NfqsqqWXp4DwFz5byiHaBs71eyX+ZElIP6s72nky8kWQ05C9IU9gDENYp++EJnP5Wp0nnNTyFEOyAKrZxKG7rPwoNMWC9LGe7vXZ5Y0YK5ov17IPzdTyLYbickSAd/toVdRmdV0R8kSvTQI3z/GgxJL/no+OrQ4+krDoPTw4NrkLEi1JvhWIvheeDmSUhdDJou8pXGWm54RuCvDrDDCP+zEqYyJBPcvwzpy0KDOeEZOe/bHqR56f+g2JevdPg5H9w4DqkKw6dLva+bNyXeuww/ZJISS3SB0j2Dl77xZ1jeSz77fCskMuZ4U1c/l6XSec1fodQOiEIrp9KGHrLsCCPWHLehs7VnGRLHfutNpPbNgbnN5Of1ZkPGcjCpEpzZAHFSQMcDnkH3xQv4PpGMa81ZB2oYFbE8w11z8RYCroRCvKxlnw9arPaWhlqORuAVAvYb3khR4etrzpEZnhduntANU50j5XmK8ztgfAh9WMaWhEu7IUkOaL3e87JV4ihe2oiXN2KU+RaKdwxeu+0TYaHhpDVfDSnyqWSFX+ii0nnNLwALRkntgCi0cipt6JFrjjN42REbOv90LkWqBME0ExSNjERDIzEqDIBCrcH+FtBKmI0r2NtL+5ornLgyX9P6FgERI9/7beA/yNMAqo50rI+9UVaS7NB6g29119LDJwIz6sPhhfBWPOh2xjkGY4rB5X2QLBe0/Mc5vabwHAJB8gRf63gennpeXDkAo43GwRUGQqFWwWO8dzbMay6fNVoAaUt6bi3CCSeVzmv+Crl2QBRaOZU29MT1p/huoWwiuKxDCTIljf0mUo/uwoCU8nNR+UXE3fYzEjXzNYUqP3oO3ZedW7NCm02e46s5eQeBpw+hb1Ip673PoNJgx3LtTcUSpId2O7yjo5aiETAj8Hs1OLnG+m3uhPJwbjMkyADttmssvYnA/rkwx+g+3/APSGfchggdpteDI4uCdkj3pm7elHV+O4w3yuY76vx+eDHMqCs1qzMNMlf2ppYBIUul85q/AqodEIVWTqUNLRLQRSK6GH+0KUKeVOLtdTBjcAZ4cBXEzUS5PiDeAopRtg8Ube85dO2Nk6LHh64yN0UPP0IgSJ+E15JEgzPD1cOfH0GhVfUTBCaUg3NbIGFGaLvNudKTq8OJ1RD7HfjqkHN6TeE5BLZNgEVGuJEI2UxuCilyNZTOc1p5n9Opf+C3KlJujfGQ85PgdQhCNw5y1vK+rn4uUaXzmr9CqR0QhVZOpQ09f9cFOszcbUNnWouCFElndKZ+Ha+JFeDsJoiXSjodsxtLCk+/VTHXLe91DSJHVWjltCpOEXC1U/TLTr0JocsJp+w1gUbA4wiMLgZXREhVbmi51jn7mQ3g0F+yWpaomqWH9xAwN6u1F0SxS1/0FWwbL//V6ypEjuY9vbwt6egymGY4E47K4F/YAaIvkxgfDoP8xu2Rt/X1Y3kqndf8FUbtgCi0cipt6GUHLtNysgx9mdgkP6UzG022Xsdr/uewewoQAUp2hbUDJEWbLZA4s+fQNdfk77Af4hmhX56ToDmFJQLXjsLIAlJCue+hSDvH0mY3gQN/QNTY0ON8WGqmeWsEgkfgZSW2otB0sXOU5rWEvTMgYhT45rpzek3hOQRWfAMbjN4fnU9CzASveK/4FjYY4cCvP/OcBmpwEt+Z4rtTjAbzIL0RjvW6dubvY09HK6iBRJhrodJ5LcyNDSMB2gEJI2DdYavShv7n6DUaTdxqM2NEvTx8mDOEJlzrhsIqo+a6aDB3XoQqRABbCd5gKme5A4yYY75ib74KUuR3l5Oe5wsEzAULKg+FAkb1tJB0+aMV7JmuD3O+WCstUyLgav8IUVVIVBcSQ9/SencXLWgPO3+TMl8vmfzPEFjdRz5rvxvip/Gubt6UtnsazG8tJTZdCqkLBy/9zgUYZvToKtkNSnX3ppYBIUul85q/AqodEIVWTqUNve30TT4ZI5O9B9fMySf5Q7hxOPgnzGpkoBhBVjmKmxK+3O9ZZA8vghn1JE9Ph3d5VlPNLTgEzmyESRXlk2pjILeRABkSWuaQu29uQsRIGleNgHcR6JcCntyDrNWglnG4daSB6Ksg+iuI0fU0RA8hb867VoQPaeI3SPwWBXdjuuUXWNJZ4tByHSTLGbiYiFAzEXImxmdr4Z3cwdtqtWFh4CIVastUOq+F2hgfMdAOiI+AD06sSht6/4U7fPizrJn+XdVsNCr8bvBImbuU2ynSlITGCzyLrLnOu5U36J6VrrmFFoFjK2Hqx5KL6BKdtapjjku6wpYxkqbHRYgaM7Qa6PkaAesIiLLR38WH/15A7vpQbZTzuUG6Sx+EuMmdz9EUnkHg96pw8u/gK5YFuRVYAqmNMrWekawWlyANBrdBoozB6/f8GfQxwtTyNYEqRviaWtYorY1K5zWlgXKgnHZAFFo5lTb0iWv3KfODTLzsXjEzLUumCx6pJ/9Cv2RBn4mENpHY5slx5zwMyyY5ilyTUj08yV3zCmsEDi6AWQ2llPpzIENZxxLNcdtdTkGM+GGtoeavEXiFwNNH0NfIexMlxisPcY6OyEEQuQhitN0OCTM4n6MpPIPAy2aDwfQNEoUBRIEAMerNgozlPSNTRS5rB8GavlIzZ7mS3yeFZw8he02oOUFFa5TWSaXzmtJAOVBOOyAKrZxKG/ri7YcUGSA7UHf4IAMdPgjhTYogGJoV7l54hWS5vlCkrWeRffZEdkMXI29j+Gi4Z/lrbmGLwJ4Z8EdLKaPJYni3qGN5+m1y2K6H5u4YgQc3YHBaSVPUQtloQRck/OVveMfoSK2xDnsEfsoFt05D6mLQdFFQeSfWwORq8rOPJ0COmmGvj68krPwfrG9kfa4AACAASURBVDde/jlLuB+UDv69DhkrQr0ZvtLYb+WqdF7zVxC1A6LQyqm0oW//+4Tc362wodOyRFq6V8oSMlL2TrN2ijrTIXMlzyM7MA08vAkZK0C9mZ7nrzmGHQIiOVck6YrRYg0kz+tYlrm4wetlNcNOS81ZIyARuH0Wfswh/y7VE0p2cY7M7ukw3+g8bcXJds5RU1hFYOC78PAWZKoMdacFnWUO3/3wR8jf1CpX/6MLErp6CaLGCNkGu9P2bnFostD/bPWxxiqd13wMhdvitQPiNnSen6jShn709DmZv15qM7JR4dR8VzV7yAb/1QF2THr1/POtkCiT5wEaVRiuHrRel9/zGmiO7iKwcQQs7ylnW9kfm0fD0m6SvvUmSGJUbHFXvp6nEXAFgauHYVRBOcPqja65IIeVMENX9NG0ISPw4oXMZwgpXyc8lZxd0A52/i6x+uYWRIwYMm6ji8KV/fKm7rO/9Q5zEQGVzmsuqq4MuXZAlFkKUGlD//fff6TtsRiRi/lJvhQM/iRXyEiZE98iRJQleMOi2ZO9O7buNKzQrrWoSpDY5H2ycaWj4eqNiUU1NJlGwBIC7jRqO74SphiFFj75FbJVtyRKE4USgUd3YYBRpbFQG6jQPyjDuxdhqHGDH+j5g3Obw77ZEDk69LrsGNgJ5eHcZkiQAdptD+UihL/pKp3X/BV97YAotHKqbehs3yzlwZPnVM6ZjJH1HITMHF4MM4yyquJg2WFf2KD6sjdEZFln39HbnbDRQHN1FwFXYpOFjPBUucZdTPW8sEPg1D/wWxXJv/ovkKu2c1lnNsGkCpKu6ijIU9/5HE0RegTM4XLv94D3uwbl+fge9E8hPwvOQQm9BupwmFEfDi+E6PGh6ynHek2uASdWgX6h59b6qXZec8sIH0/SDoiPF8AsXrUNnf/7FVy//4QymRMzoYnRxTo4vMxX3Gnfh0Z/hg2q5spInY5DLCMpPWykaa6eRGBxF9g6VnLs4SQ2WdDsnwtzPpX0Df+AdKU9qY3mpRFwjMCRpTDdcDpqT4UsHzpH7NIeGFtC0lUaAu+1cD5HU4QegUt7YWxxyafiIChoFLuwcxYhWt8ZPVnyNISqI0IvU1UOk6vDidXBlyN+XWd775RocaD7OVUtUlYv1c5rygLlQDHtgCi0aqpt6GIDV3P+1kOKpEvAtBaFQkZKVKgalAae3IfCbaG8UQbQ09ia8wJarYekRpKop+Vofp5H4M+2sGsyEAG+vQURRNNKB8N8q1Z3BmQymhh6XjPNUSPwJgLuOMA3TsDPxk3xB/+DYkbRBY1v2CJwah38ZjiI1cdCrjpvynO1qWTYahx23CdWgLObrIVVzW8Du6eCCJsWzV6dfSeHndZ+yVm185o/gqgdEIVWTbUNXW7YWo5euU/ulPGY/7mTsqlHl4Eod1i8I8RKHDaomg8F9edChg/CRo7m6nkExG2GWL8oMaHnRef8j6+CKTUkXc1JkN342/lMTaERCD0COyfDAqOU+KfLIZWRkO6I891LMDSzpCjRBUobRRdCr43m4AgBc5+PujMhkxEGZ57zQxa4dxHSlYGG8wIXT3EDJ27ikuaEVusc2+nqrXTgouaWZaqd19wywseTtAPi4wUwi1dtQ1cdsZ495++QOWlslnYwQgt8idfpDfCrUd5Xx1j7ciVclz29LhxZDDESQpcTzueb17raGMht5Bg5n6kpNAKhR2DzGFhq5BJYvW19dAcGGMUVwvImOPTWBRaHIM7iMkgVzG39iAJw/SikLAjNlgeW/WZrXtpZCJotc2znyt6wfqik0SHNLu8J1c5rLhugwATtgCiwCHYVVNvQtcduYsupm6ROEIO1nUv5HilziEOZb6D4V77XSWtgDYHfPoJTa2X1KytFCoJUIQrw2v3WENRU3kRg3Q+w6jspsf0uiG80JXSkw/NnshysGPmaQJWfvKlx+JVlLvHdZjMkDqZn1bjSIL5TEmeFNpsCF6th2eHOOUhbChrNd2ynO3s8cJFz2TLVzmsuG6DABO2AKLAIqjogTSdtZc2RaySKHY1tPRUId3p8H/onl3C91xIqDVJo9bQqDhEYXxbOi/4wmeHzLc7BunIARheRdBUGQiGjwZvzmZpCIxB6BFb1gXVDJJ+vjkLsJNZ49kkMzx9Djlrw8ThrczRV6BBY/T38M1jy6HgY4iR7k5/9BUjcVPBlGFVpDJ0Vnpk9KC38eyP4hoyvS9gyFpYYDTat3vJ5RsuA4KIdkNAvo3ZAQo+hxziotqHbTN3B4n2XiR0tMvt6l/eYnaFi1C+5THbPWhVqGQ2XQsVQT/YKAi+bXuWFz9Y4F6kTep1jpCnCDoGl3WHzKMm/+3mIFtuaLHtH7swfQp2p1uZoqtAhsKgTbDOcPdGDKkr0N/nZy9O+FQ+6nQmdPJVn900GT/+F7DWh5gTHmu6aCn+2kTRNl0Lqwipbppxuqp3XlAPIgkLaAbEAkrdIVNvQHWftZt7OC0SOGIHj/YzcC2+BEZKc4Xnh5glIaSHG1de6avmvEBieB26ehNTFoOki58jcOQ/Dskm697vD+0ZXdOczNYVGIPQIBOkofRMiRrLGc2g2uHveWgiMNY6ayhkCc1vAvlkQKSr0uhp8Nac/WsOeaRAhEnxzIzArPomuwb3jSbSslBs+MB9mN5b0uqiLs132xnPVzmsuG6DABO2AKLAIdhVU29C95u9jyuazNvWOfl+RqJEj+h6tiRXh7EZ4+134Yo/v9dEaWENgSCa4fxkylIP6s53PeXADBhtx96KcqShrqodGwFsIzGkG++dY6yht1mnEe3D9CKR4D5qv8Ja24VvO1E/g2HKImRg6Hwsei8WdYesv8llItyT+juLTh9A3qbTCSojy8ZUw5WNJ/8mvkK26vyPgVf1VO6951XgPCdMOiIeA9AQb1TZ030UHGbdOdlPd82054kaP4gkzQ8djdhM48AdEiQE9Lgbmm6zQIaTm7P4p4fFd66Fz5nyfgq2h4gA17dJaBSYCL6u2JYAuJ63b+Mv7cHEXJMkOrTdYn6cp3UdgQjk4t8Vx7wtRUEAkXYvR6VjYlYp334rQz/z3puzHJUbRDlC2t2OeZzfDRCO0uupIyNMg9DqEIw6qndf8EXrtgCi0aqpt6KHLjzB89XEbQlt6lCFJnLd8j9aSbrBltNSj2zl4K47vddIaOEfguwTw4hnkqgfVjfVzNCtIRaGmUOVH5zI0hUbAUwi4m7Q8qTKcWQ9vp4EvdntKG83HEQIvb50KQPOVwVOuGwqrjAN5u52QIF3gYRokbLUHvG+UkQ7J0sv7YYzR30sX+nB5P6h2XnPZAAUmaAdEgUWwq6Dahh799wkGLj1sU29Np/dJkzCm79FaPwxWGuE4bbdDwgy+10lr4BiBZ0/g+0SSJn8z+NCoPe8Mt97x4b/n1p0WZ/z0c42AVQTGfwDnt1mv2mbnO7UWHFvmOBzIqg6azhoCQzLC/SuQviw0mBP8nK3jYHEn+eyztfBObmu8/Ynq+jEYkV9qXLYPFG3vWPubp2C4gUPpr6GEgY8/2exDXVU7r/kQCrdFawfEbeg8P1G1Df3rhlP876+DNkMXty9O1ncUuG3YPR3mGyVZGy+ENMU9vxCao2cReHgbBqaWPIu0g3LfW+Nvr3iWrQZ8MsnaHE2lEfAEAqMKw9WDkDwftFhtnaM9RDRqLOhxwfo8Tek+At8ngWePHFd+2jMD/mgpZQTq74bogC46oYtRaQi818IxpvevwZD0kkbn2bm8/1Q7r7lsgAITtAOiwCLYVVBtQ8/ado4uc/fa1Jvbugj5Ur/te7ROrIbJRrLcxxMgR03f66Q1cIzA3Ysw1GgOVrIrlOphDbGXNe0rQd3p1uZoKo2AJxD4MSfcPgPvFocmC61znP857J4CRIBvb+kcNevIuUf59BH0NXq0FGgOlY08j9e5HV4EM+rJT+vOgEwV3ZOn8qwgOR2jIE99x9oGSVr/DCoZvVRUtlEh3VQ7rykEjWVVtANiGaqwJ1RtQy/Yc5H203fZDJ/SrCDFMiQMexCcSTA3qCvXF4q0dTZDP/c1AkF6evSGYh2saTQ0K9y9AOlKQ8M/rM3RVBoBTyAwOD08uAYZK0C9mdY5Lu4CW8dK+h6XIGoM63M1pesI3LsMP2SS84p3gjJfB8/j1D/wWxX5rMY4yFnLdVmqzzC/nKs5CbLXcKyxKNv7nQhzfaHDXN1YW9XOa26Y4PMp2gHx+RK8UkC1Db3i4BVa/L7dpuC4Rvkpm9ViN+CwxNRcnrVIeyjXJyylad6eQODSXhhrhMpZCQ2wy7T3fEldFJou9oQmmodGwBoCfd+Bpw/A1fA/kZ8m8tTE6HwCYirw0saaxf5Jde0IjHxP6u4o7+HCThhXStJVHgoFmvmnvY60DnLLMxMyVXBuY/9U8PgOZPkIak92Tq8pXiKg2nnNH5cmoByQ58+fM3jwYMaPH8+5c+dImTIlzZs3p3PnzkSK5LiR1PLly5kzZw47duxg3759PH36lFOnTvHuu+8Gu6779++nS5curF+/3va8WLFiDBo0iOzZs7u9D1Tb0BuOX6f++C02e36qk5uquZO7bZvHJoq3Nn0SwYunkLM21DBqu3tMgGbkcQTOboGJ5SRbV8o9jioCVw+4HofvcQM0w3CFwIsX8J0RbmqloZsZnLWDYY2R4/TFXnjbyH0KVwB60Vjzd8tHP0PeRsELv34cRuSTzz5w4RbWi6aEWtS+OTDXcKwaLYC0JZ2z/CEL3Luob5mdI/UGhWrnNTdM8PmUgHJA2rRpw+jRo2natClFihRh48aNTJo0CfH5yJEjHYLdpEkTpk+fTo4cOXj8+DHCwQjJATl27BgFChQgfvz4tGvXzsZ3+PDh3L59m61bt5Ihg3uVmVTb0DvO3OLj0Rtt9g38OAe1C6Ty+Ya1KWDvNpymJDReoIZOWouQEXA1NMDO6ZdScHEnJM4GbeQ+1EMjEOYIPHkA/d6RYgq2gooDrYvcNAqWdZf0rTdBkqzW52pK1xE4ugymGeFUtX6XfYaCG1ZDtVzXQJ0ZO3+HBfI8QrOVkLKAc91GFIDrRyFlQWi23Dm9pniJgGrnNX9cmoBxQMStRa5cuWwOwU8//fRyLb744gt+/vln9uzZY3MuQhoXLlwgYcKERIsWjV69etG3b98QHZCaNWuydOlSDh06ZLtlEUPcuGTJkoWKFSsye7aFTs/BKKLahj548S6Vhq+zafq/KllpUtRocuTrnT6uNFzY4XqJTF/rHV7luxMaILCyd72Pnw7a7wyv6Gm7vY1AkOpAHeGDb61rsONX+OsLSd98FaQwyqJa56ApXUFg7yyYZ1R7cvTWPzROpSv6+JJ2y1hY0kVq0GoDJLUQjWFvnKlf8ri8cqqd11w2QIEJAeOA9OzZk379+nHy5EnSpHl1UBa3GGnTpqVHjx42p8LKcOSA3L9/nwQJElCnTh1+++23IOwaN27MzJkzuX79OrFixbIiKgiNahv69PUHvD/kb5uOXSpkos37Rsk+ly3z8AR7l+K34kG3Mx5mrtl5HIG9s2Fec8m28V+QxigV6UyQqHYmbk/ipICOB5xR6+caAc8gcOs0/JRL8irdC0p0ts7XvNethsFY564pX0dgyy+wxFiflv9AMmPdXqczJ1znrg/VRgUeluYeWVabLf76IZxeB/FSQwdZ8VIPawiodl6zprVaVAHjgJQvX952y3H58uU3EE6SJAl58uSx3VpYGY4ckE2bNtnCu0SoV6tWRj8Kg6n4TIR7CZpChQpZERWERrUNfeXuIwr2W2XTsX3p9HQsZ1QbcdkyD0/4qwPsMPpC9LoKkaN5WIBm51EEdvwGfxlNsVx5K2x3NGMkgC4nPaqSZqYRCBEBc6W9CgOgUGvrYB1eDDPqSvo60yFzJetzNaXrCATJudkDbwefs2ljHOgJ12v6wVojXLDjYYiTzDme0+rA0SWgv2OdY/UahWrnNZcNUGBCwDggIrwqatSotiTy10fevHltSeUiTMvKcOSAzJ07FxGCtWDBAqpUMcr6GUzFZ1WrVrUls3/88ccORV26dAnxn3mIkK4GDRrYbBA6+3rcefiUXL1lXGiL4mnoWVmReOa/B8Df/SU8HfZBPEVyU3y9YN6U//wpXNwFSXNClLccS948GpZ2kzSuxMXrpm7eXFEty47AuW0w4QP5ryrDIV9j69ic/Bt+N/IQdJ8i67i5S7msJ2waIWd3PQPR44XMyZ47mLYUNJrvrkR15y3vBRt/toaF3Yq5zWHfbIj8FvS6oq5tCmqmHZDQL0rAOCDp0qVD3HSIxPPXh7ixuHr1KsePH7eEmCMHZPLkyTRq1Ihly5ZRrpxR2cfgKippiZsYQSMcCUfjf//7H7179w6WRBUH5OnzF2ToucSmY/2CqehbPeQcGkvAeopo+yRYaPSSsJps5ynZmg+8eA6Tq4GorZ+vKVT50TEq/wyB1Ua55Pa7Ib7FXKI/WsOeaRAxMnxzQyOvEfAOAqFxIkLjvHjHusCSYm78+M1NiBgxZPtGFoRrhyF5fmghb/YDaiz6CraNlyb1ugaRozo3T+QribwlMb6+AZEiO5+jKWwIaAck9BshYBwQfQMS+s0QHIf0PRbz7MV/1MibnKG1coeNEFe5HlkC0+vIWbWnQJagN1GustP0LiIg3rKJt21iRH8bupxy3PF5VR9YN0TSdzoGsRJbE2gOtdM/jtYw01ShRyA0YVRXDsLowlKH8v2hcJvQ66M5hIzAjPpweCG8FRe6nXWM1PgP4Py2wC1eMr8N7J4KESLJFzYRIjjfOa7cIDnnFq4otAMS+uUOGAdE54CEfjMExyHHt8u49/gZlXIkZVR9o4562IiyztXcVMqVxnbWJWjKkBC4ehjGloDnj19RtN0BCR0UKFjaHTYbSZ/dz0O02NbwXdINtoyWtN0vQDTXCztYE6SpNAImBEKTSB6aBHa9CK4j4EoS9cuiFsmh40HXZak+42XIamzocd6atmv6w9oBkvbLAxA3hbV5mkrfgHhgDwSMAyKqXPXv39/nVbBmzJjBjRs3AqIKlthf7/VdydV7j3k/UyJ+bWp0nPXAxgsVizsXYJiRjyIq1IhKNXqEPQLPn8nYeJH7YR7VRkPueiHLN1/z28IkHDcFfcloxbewwQjv6nwSYiYIexu1BI1AaErphqaEr0bedQRGF4Mr+2QuWitZMj7EMbMhHFoA0eJCdye3Ja5r4vsZ02rD0aUQMzF0PmZNH/Nt9udbIZEihWasae9TKn0DEnr4A8YBERWwRKWrkPqA7N69m5w5c9qS0U+cOEHcuHFJliz4KhHO+oCIBHORA3L48GFSpJBvDOx9QMRNjEhUd2eouKFLDl7DmRv/UjBNfGa2NEIL3DHOk3NEArTohs5/svOt6ICrR9gjYK44k660LJErRv5P4cNhIcuf2wL2zXI90dFcbODLgxA3edjbqCVoBELTTDA89JtQaYcMywF3zsrS3qLEt6Nhzhf59pa1ECWVbHWmy29VZF6eKyV1t0+EhV9Kzs1XQwpFohyc2arAcxXPawrA4pIKAeOACKtFWdyxY8faOqEXLVqUDRs22Dqht2zZkjFjxtiAOX36tK1PiOjZ8euvRvIVsHfvXltlKzFWrlzJ2rVr+eqrr4gXL57tv7Zt274E9siRI7z33nu2fiDt28vyoqITurj5EJ3QM2Vy7y2Cihu6wo//cPjyPXKliMufbYu5tLnClHhQOvj3OmQoD/VnhakozRy4tBfGlYIXzyBmImizBcaXgVunIEkOaL0+ZJjscdoiX6TraetwulPX3jp3TakRCB6BfwbD6u/lsy+clHZ9ncOLF/BdfPlyJE8DqDpSoxyWCPRPCY/vQpaPoPZkx5KWdIUt8hwQkCGdL3NcssDnm62hHppwQ2sSApZKxfOav4EdUA7Is2fPGDRoEOPHj+f8+fO224nmzZvTpUsXIkeW1R1CckCEMyIcl+BG6tSpbfPMQzgsgq9wcsQoVqwYAwcOtN2yuDtU3NDVR21g19nbZEgcixUdS7prmufnjS4KV/bLxlOiAZUeYYfAs8fwSym4ajQDtPc3mPcZ7J0JESJCt3Mh52i421AwSPnejZAkW9jZqDlrBOwIrPwfCOdXjM4nIGZC17Dp+w48fQDZasAnRr8i1zhoaisIiGp8NmcPyNMQqhrleEOaK5xK4VyK8dURiJ3UihT/obH/Jr6TFz5bY03vIAUXpkHmytbmaSqdA+KBPRBQDogH8PApCxUdkHrjNrPxxA1SvB2d9V1L+xSfIMIn14ATqyBWUuh0RB29AlGTlb1h/VBpWa56UN1IDN86DhZ3kp876nA+sQKc3QQJMkC77dYRMpdbbrEakuvwAOvgaUq3EVjcBbaOldN7XIKoMVxjNTg9PLgGGStAvZmuzdXU1hH49yYMMkp6F2kH5Yxbq5A4bPgJVnwjn7bdDgkzWJflD5TD88DNk5C6GDRdZE1jEbIlQrfEqDEOctayNk9TaQfEA3tAOyAeANFTLFR0QJr9uo1Vh6+SMFZUtvcq6ylTQ8/nZcnBiPD1deuJzaGXHL44iL4GE8vBfy8gTnJovfFVs6+Lu+EX41as9NdQwnBGXkdoTHG4vNf126rd02F+K8mt6RJIXSR8Ya+t9Q0Cf34Ou6YAEcCdXIGfcoGohvVucWiy0Dc2hAep4rAtDt1iOPr+sWOxbQIs6ij/1WINJPd9s1+PLtOQTHD/MqQvCw3mWGN9YQeMM14sVh4KBZpZm6eptAPigT2gHRAPgOgpFio6IG2n7WTh3kvEiBqJg99V8JSpoedjDpP46ijEThJ6nppDUASe/Atji8MNo4Fng3mQvswrGlEVq38KePYQMlaEejOCR/Dn/HDjGKQqDJ8utY7y/nkwxwiLfF22dS6aUiPgGgKzm8KBeRAlJvS86NpcQT2qiAxXdCUUxnUpeoaoxvfL+xIHK+XYAz3foX8qeHzHWj6MffdcOwojC8h/le0DRWVOqx7OEVDxvOZca7UotAOi0HqouKE7z97D7B3nbT2NTvarRAQrzY28genmMbC0q5QkckBELogenkXA3L8jpEpXkyrBmQ0QI4GMlw9ufwzNCncvQLoy0HCedR1D0xDOuhRNqREIisDUWnBsmWvlTM0cAr3hnSr75cQamFxNavPxBMhR07FmQRrYToUsH6piiWf0+C4hvHgKOetADSOE0Blnc0n7kl2hVA9nM/RzAwEVz2v+tjjaAVFoxVTc0L3/OsCkDTIB/8/Pi5IrZTw1EDuyFKbXlrpU+QnyNVFDr0DR4tQ6+M34gRZlHUXoVXCNAM29OtrthATp3kRg4Lvw8BZk/hDqTLWOkCjzKxLYxag5CbLXsD5XU2oE3EXA3tzu7XdlFSxXx+9V4eTfEDclfLnf1dma3ioCB/4A0XxPjPpzIIOTEOHT6+FXI8m6+ljIVceqJPXpbKXpjWIJ+ZpCFaN/kjPNH92BAakkVeG2UL6vsxn6uYGAiuc1f1sc7YAotGIqbujNJ29Q5xdZ0i9rsjgsaFuUyJEi+h61R3dlAqIoC+vqwdb32qutweN7MLoI3BbNuiJAk0XwbtHgdT68CGYYTQir/wK5DKfQTN0nseycnrM21PjFuu1nNsKkipLeWbND61w1pUbAMQKi4tvFnZA4G7TZ6Dpa0+vBkUUQPT50PeX6fD3DGgLmhpHNVkJKI5QopNnmnDUrIVvWtFCDSvweDkgpdSn0OVToZ00vEUbbx2jwmrcxfDTc2jxNpXNAPLAHtAPiARA9xUJFB0TY1nHmbubtumAzs2elLLQokdZTJoeOj/1NZdTY0OUkRI4aOn56tkTA3Lnc2Vux+1dhiFFNpkBzqPxDUBTNpTLFLZW4rbI6zAmSotGhCAPTQyMQ1giMLAjXDkOKAtB8pevS5jaHfbNdb7zpuqTwPWP9j7DyW4mBlapWN07Az0bieZlvobiRkB4IKN67Aj9klJYU7wRlvrZu1fdJZR5f9ppQc4L1eeGcUtXzmj8ti3ZAFFotVTf0jfuP+WDoWm79+5ToUSKxomMJUrztYmnKsMDZXFbRURnYsJAdqDzNh/6EGWV+TZTojq39MSfcPgNJc0KrdUFpxW2KSFQXw5U3c4L+ygF5EyNGhQFQqHWgoq7tUgmBYdnhzjlIUxIay+a0Lg2zA//NTV2hzyXwXCA2FyLpdAxiJXY8+f41GJJe0hTrCB8YzosLIpUlvXkKhueW6lmpCGY2xN7UV5eNdml5VT2vuWSEj4m1A+LjBTCLV3lDz95+js5z9srvt8yJmdA4v+8T0q8chNGFJYRF2kO5Pgqtpp+qYm7+13A+pCvl3BD7G98IkaD7OYga89Uc85u5Ep2hdC/n/OwU5jeWH/wPin1pfa6m1Ai4i8DANPDwJmSqDHWnuc5laQ/YbHRAFw0634rjOg89wzkCC7+E7RMlXa9rzm/Anz6EvkbzwQItoPIQ5zL8hcL8W1i+PxRuY11zXTbaOlYmSpXPa24Z5INJ2gHxAeghiVR5Q//333/UG7eFTSdv2NQfWS8vlXMm8y16//0Hw7LJCkuJs0KbTe7rs2cmPLoN4ocpogI5Lu5bErqZ5qTyTschViLn/LaMhSVdJJ0tX6TYqznmN3NlvoHiXznnZ6cIUqGlG5Tqbn2uptQIuIvA90ng2SPI8Ql8PN51LoHecdt1RMJmxstyyTGg5yXnMsTvhUjUFnmDuepC9THO5/gLxfkdMN7o5/Hhj5DfKF9uRX97B/VkuaHlWiszNA3oHBAP7ALtgHgARE+xUNkBETaevHafCj+t48mzFySKHY2VHUsSN3oUT5nvHp8F7WHnb3LulwcgrhHu4wo3c7JzvdmQsZwrswOLdl5L2DsDIkaWbxWtOGMXdsI446bk9djqIGFUA6GQ0VjQCmoPbsBgI9+oaAco29vKLE2jEXAfAXPOkrtJueuHgQgP8jqZ9gAAIABJREFUEiOkynDua6hn2hGYXANOrILYyeCrw9ZwGZBavmgKtMIl5qqFIRUDCQmhCeXh3GZIkAHabbeGo6bSDogH9oB2QDwAoqdYqO6ACDuHrzrG0BVHbSbXL5iKvtVzeMp89/gc+gtmNpBz3S3H+2db2DVZ8ijVE0oab/Pd08i/Z/32EZxaC3FSQMcD1mwRJSBtDQkfvRm2cn47jDeaF1YZDvkaW+MpqJ48gH7vSPqCraHiAOtzNaVGwB0EglQTagMV+rvOZcsvsKSznNdyHSTL6ToPPcM5AqKDt8hZS5QFPpeVGp2OYTngzln383ucCvARwdHlMO0TKbzWZMj6kXVF3HHkrHMPWEp/OK+pDr52QBRaIX/Y0I+fPafy8PUcv3rfhtzc1oXJlzq+71C0leNNKxswufNW6+kjGJJRdpAVw9VSsb6zPGwkj3gPrh+B5PmhxSrrMiZWgLObIGYiEAmh9oaEJ9fC78aPoZVmYWaJ5hKRrlbQsq65ptQIvELg3mX4IZP8t6s5S3Yuu6aIpknyX58ug1SFNMJhgcDwvHDzBKQqDJ8utSYhULvUH5gPs42XO/XnQoYPrOEhqGY1goN/QrQ4ModPD0sI+MN5zZIhPiTSDogPwX9dtL9s6K2nblJrrMy3yJgkFgvbFSdqZB/mTbwsxxsLupxynoxoBv7gApjV8NUn7+SFz9YotCu8rEr/VNIZc9WZW/41bDRqyLffDfHTSMXNDSPrTIPMRiMwq2Z9lyAwY7at2q/pvIuAJ0q17p8Hc4wY/AbzIL1xA+hdSwJfmjvVmyaUg3NbAi/caPd0mG+EtzZZHHLfpuB2xfw2sHsqRIgIomqb/eVR4O+gUFnoL+e1UBkZxpO1AxLGALvC3p82dLe5e5mxTb4t6Vw+E5+XMsobumKwp2hDU45XhG+JMC77iBYXup0Jn1/C5pAnV6vEmEPhaoyHnEY4wP65MMfo32G1qpZ5X/RLDk/uQ7bq8Mmvntoxmo9GIHgELu+DMUYRhYqDoGBL15EKTTiM69LC5wxzQnnOOlBjrDUcpnwMx1e6ljdijbNvqbZNgEVGX5MWayC50e/EilaLu8BWA78elyCqAiX2rejtYxp/Oq/5GKoQxWsHRKGV8acNfeffp5QZ+jfX7z+x3X4s71CCdxOayq96E1d3y/E+vC2b6D1/ElRbKzXlvWmft2SZ3/66WkveHLry3mdQabDUOkg4ynJIVdA1a+xvOTNVgrrTXZurqTUCriJwdjNMLC9nfTQC8ppuR63yOr0efjVu+qqPhVx1rM7UdFYReHwf+ieX1O+1hEqDrM2c1RgOzoeosaCHbK4bEGPjCFjeU5rSZgskzmzdrJW9Yf1QSR9ef/uso/WS0p/Oa26Y55Up2gHxCszWhPjbhv5z9wW+mLHbZlzR9AmY0qygb3qDuFuOd+fvsKCdXJwU78H5rfJvV6+wrS2v+lSnN8CvlaSeVUdCHiO536rm9gRPczlHc0Juq/WQ1MWiBUNFmeXzkLYUNJpvVRNNpxFwD4Hjq2BKDTm35iTIbvztCjdzVbjKQ6FAM1dma1orCAQp0d0VSvWwMgvMBUe+uWWtyp81zr6lWjsY1nwvdeiwD+Klsq7Puh9g1XeSvv0uiG9UHrTOIVxS+tt5TcVF0g6IQqvibxta9AZpPGkb/xy9ZkNxaK1c1MjrRhlcT6yBufuw1XK89tyRSNGg1m8w3XhT6Wq1Jk/orwKPfXNgrnFYajAX0ruQyCj0F6FWIuRKlPAVDdjEVf76H2Gl0XHYnZKkLxNNi8CnS1RASesQyAiYQwnrzYKMxm2IKzZfOwojC8gZZftA0fauzNa0VhAwl/d2pfFeoDaJNN9idD4BMRNaQVHSmPs46aptlnHzt/OaZcO8SKgdEC+C7UyUP27oczf/peywtTx6+oL4MaOyqmNJ3o4Z1Zmpnn9+aCHMrC/5WmnEdPciDM0K/AdZq0LFwfBDRjm/SDsoZ7xN8rym6nI0X+O33ghJsrmmq7mLetMlkLoIrOkHawdKPh0PQxwXm1fam2SF9+IArq2EpnYXAdGQ9I/P5OzGCyFNcdc53TkvG6SK8X53eL+b6zz0DMcIBLmtHQV5jO9+Z7iZv4++PAhxjTAuZ/NUf76kG2wZLbXscRGiuhAObQ6TbboUUhdW3Vol9PPH85oSwJmU0A6IQivirxt6zNoTDFgiG0EVSZeAiU0K8FaUSN5F9vE9GJjGejneDcNhxddSx9pTZXWmAaIC1F3IWBHqzfCu/ipIW94LNv4sNRHVxGK4WF7Z3I33g95QrAMs6wmbRkieXc9A9HiuWWqv9R/aTveuSdXU7iIg8oiuH4MMZSGil78D3NXZPG/7RFj4pfykxWpIns91rv/ehEFGFbgi7aFcH9d56BmOETi8GGbUlTSuVNcT32/ie06Mz7dCIqPksr/jbW7I62poWZASvnPk/7t6OEXAX89rTg3zIoF2QLwItjNR/rqhnz5/wcejN7L3vOyl8UGWJIxukJcokbxcmteVcryi0o2oePNWXJl4Fzka/PI+XNwVeCUanW08+/O5zWHfbIgUFXpddb0S2LMnsiHh88evyvgu7AjbJ0gJX1+HSFGsaiPpJlWCMxtkXLKIT9ZDXQSePoQfc8CDayAqE1Uf4/oe8rV1njigiv8Pvk8kLcnfDD40Enx9bVsgyd89Dea3lha5krO3fRIs7CDnNV8FKfIHBipzW8C+WRD5Leh1xTWbjq2EqR/LOaLSoKg4qIdTBPz1vObUMC8SaAfEi2A7E+XPG/ravcfUHruJk9cf2MysmvsdhtXKTcSIEZyZ7bnnVsvxXj0Mo4xqTHkbw0dG/wr7l7jIYeh52fXDsucs8Q0nuwMnEhhFIqM7w15nP1YS+OqIPCTsmQ4Ro8A3113nOLk6nFgNcZJDx4Ouz9czvIfApb0w1hSyVLQDlO3tPfmekPT3QPi7n+TUYT/ES+keV92/xj3crM4yh3u22gBJs1ubac5zc6csuDUp3qeaUR8OL4Tob0PX067JN1d+c6f4iGvSAoban89rqiyCdkBUWQnA3zf0xdsP+WTMJi7cfmhDtX7BVHxfLbv3KmNZLccrKn6Iyh9iNFkE7xp1/82HD3cSphXaS26p8nM+uHEcUhaEZsvdYhEk5OqLvTLMzdZlNy50P+s6z+n14MgiiJEAupx0fb6e4T0EzA347FIrDIBCxptq72nivqQV34B4kSGGO2GIdsn2hp5ZPoLak93XR88MHoE1/WHtAPnMatERQRuoPVom14ATq9x7UWPufVNhIBQyGhrqvecQAX8/r6mwvNoBUWEVDB0CYUOfuv7A5oRcv//YZlXLEmnpVjGzd5wQWzne7LJsa6Is8PnmN1dX0PyUE26fhTgp5Jv+iEaomLlpXt2ZkKmCQrvDC6rYm/6JpPxav7snUDgbsxrJuR9PgD0z4PgK9xt/zW4KB+ZBlJjQ86J7OulZ3kHAXApU3CK+eAZEgJoTILsR4uEdTdyXsqgTbBsn5/e8AlHeco/XD1ng3kVIVwYaznOPh54VMgJLusKWMfJ59/MQLbY1tM5shEkVJW210ZC7nrV5qlNNrAhnN0KC9NBuh2va3jwFw3PLOa72f3JNUkBRB8J5zdcLoh0QX6+ASX6gbOjDl+9Se+xm7jx8arOuU7mMtC2dwTtIOyvHa75uLvoFlDXqnwvtzCEkogqWqIYVXoZI4hf5G2IUbAUVjcpVrtpvqy6W5RWfy/vhzHr3czj+ECFc0yBCJPj2pqvaaHpvIjCvJez9P3tXAR7V1UQPEBLc3d3dtUChWIGixQpFCwUKFIq3fxWKtlhxK06hQCnuFHd3d3ePkP87776XvIRN9tluNskbvnwJyb1z5867uztzZ+bMQvGseOu/qBUQGCDS7wjrnK2SO6Uxtpb6vP3vofEaFiWamKks0G6tMVnsWWFrYFlnkdrJs6bnOVnR6d4Tn8vkSsDtI6LPEvst6aEX94GROcSMCl8D1X7QMzvajo0q9lpEPkDbAYlI7YdaOyod6MPXHqPltL145Rsg7fKHuvnQpryMDONKnTuD41UXRYfOHfZ9CQxJJ6Qr3gaoK6diuFJeT+FN5KLxckEmP4D4QWSUlOaBhM4lzDEL+1MXBL7U+cHI9YlIRGQi0ncPgVheRqWy57laA1OrAjcPAMmyA90PAWp4T++EQNvVQNpCrpbCHH9G76SUwUTAgOvGeU2qCNw5BqQpBHTebpyPPdOxBuY3A86t0Z+aGeK2/1vggz5RQ8PjSwEPzhpLnyV4xOA0Qg+lvgBqj4gaOnHxLqKSveZiVYXJ3nZAIkrzDtaNagd618UHaDNzP3z930m7HdmkMBoXd3GjwvDgeAP8gJG5gNePgLBgXdkb5NlNIHMFoO0qDzodLhbl8n/An3XFIvUnAUVkiEsjyy5uA5xcJhoSsnj8yVXRab7DBv3c1g4A9kwQ8/SkWuhfyZ5hRgNMbRyWGXjzFMhZA2j5l+Cm7rJMYALWFiXNYmYl186d21ikDCZIA3xz1vhaSkqM4owZ52TPdKSBGTWBa7v1R1ZfPgRGyJ2+IyNIQlin4feCwNNrQLbKQOt/9J0ZvnZ/SgYEvgMKtwAayP1E9HGJdqOjmr0WEQ/QdkAiQuthrBkVD/Sm03fRac5B+L8LBAGx/mhRDLUK6mxGp/cZhQXHe3YtsKCp4Fb1e6Bir/c50winMW7WANErc0SPP/YXsLSjkMIsOszuP4B1A0PuyMgHIzls/AHY8bvgpbfDb0TrNDqtrzbsynQFaspIUjRu1vQF9k0R2qBBTidET6dmd+rRKtjnuY2ACxud1z49ugSwAWjuWnb/BT3PeUJZ4N4pQG+DUv+3wC+pxEpRCSJ5eHbg1QMgd22g+QI9mhRjbdAE3TqLivaabiWYnGA7ICYVaOX0qHqgVxy9hR4LD4O2SOxYMTDt85KolEvGybdSgQovdZPB1iuCc8+XtANYaE5i8TnhZkOTOkWr/3UgTiJXSOh5PNUQxl32AqnyGJfx+n5gerWQ841+MG4dCmz9VfDSg3ZjXHp7phENXNsLzKguZn78G1CyfTCXdwHAkrYitYnE5n6f/6uvW7MRmYzMmfwBcPuosVx69Xqsfzm9Inz0t8dXAd7ks1id0ULqJHM5I1JHvzlBRf4fAq2W6dv/zymBAF+gUFOgoewY6+PgeaMHpwP8Xgqwh8ZyyqoeKc3oU886UWhsVLXX3PmIbAfEndp2slZUPtAL9l3DgKWit0Tc2LGwrucHyJQ8nmu0f+80MKGM4M1CchaUMzVrRE7A/zWQqRzQbo3jtdX48h23AOlZxxANaO1AYM8fYqNGOparVcRbRqkhoW/wbws0FmhIemnHaGDj92JWdIRG1quviBp/eB7wTxexOlNAGPFSk98bgFEBAhKQcnwkbmr1NqZ09f7GlQAengcylgHarzO+mrNi9ud3gZk1AUZAFIqfEvhiG5A4vfF1o8vMwWkBv1eiaR6b5+mh4dmAVw+NRwv0rOWOsbzZ+zGpqLcr+hnAXh56aXxJ4ME5YzUketeKIuOjsr3mrkdkOyDu0rSGdaL6gZ687SJ+XXNG0kSFHCkwp30p18DzOoLjJRzssk7iKdT5HSjRzvETOb8BmNdY/K3hNKBQEw1PLgoMUeBuveICg24bR/9RVDGtGnBjf7BiirYCPhmvX1F7JgFr+4l5ehqO6V/JnmFGAxt/BHbIHb/DilS9fiI62987KVbyRKAHpQYsu4GbdbX+VvUG9k8Tv/n2HuDlE/zX148BponePSF+lziTyN8npSsKtF1rHP7XzDOMLHPVneaLtwXqjtYn+WjCsF8FslQE2qzUN9cTR9O5H5xaSGa0iHxKZQEWkio/0GWXJ+7S42SK6vaaOxRuOyDu0LLGNaL6gQ4MDETrGfuw/bzoiO3SovTQcLwruotGTYQE/eYcEC+Z46eiRkmp1A+oEqqWQeOzjHTDlKLZpFmBHkfMi6+OqJCbUWjfAzOBlT2FPB02AxmKm5fN5mC9BpSUIzqwA5lSJPfWCb0SYZqnVweeyghT35wHEsg5+dZLpZ/jUBbSPwHy1AGazdM/X5mx/jtg11jxP3VDQyLtza4P3Ngn/patiogEUX8sfiexELj+BPOXAMal9+yZathYI4XkEysAd48DaYsAnbZ59l61SPfqETBcRpgMDS2vZT7HKHWTSTIDPY9pnRWtx0V1e80dD9d2QNyhZY1rRIcDff3RK1T//T+89gtAknixsbFXJaRIoLod1Kgrp8PUcLxVBok6AqJ8OKtFYL46IQmZPmQ0n9apcB44YEwR4PHl8NPT9Igduit2hV5ANTmVSg8fdeSqzWogS3k9s+2x7tLAhHIispG6APDlzvBXPfgn8G93MUZdo+UuWcNb56cUwDs/oFAzoOFk4xI5ql1iauKCZsDFzYJvhpIC8MEnAcDo0NQPgUcXxd/sjtRh6/7BBWC8fBFhBDI8CEFLhos2/pQ9Y+bTm8Dv+YQslQcAlfvrl8sorLH+laLMjOhgr7n6YdkOiKs1rIN/dDnQ07Zfwi+rTkuaqVc4HcY2L6pDSxqHquF4Y/kAAaIzOxrPBAo0DJ/JH6WB+2eiD4Y/U9aYU836mPwNgSYzNSo5nGFPbwC/5w8eUOVboJIBzH3C+RLWl8RmdjlCFbebl9TmYFYD796J/jk8P/k+AT6dHT7H6/uA6R+JMbVHAqVk9DWzcpidT5jun1MILkzRZKqmUdo1Dlj/rZjddZ/oUK0uxGeqC2G+4zJ3X6Z7Z4BpVQHfF6LBXuvlQNYPjEoQdefdOCD0RKozGijRVt9e5zUBzq8HCAvNaHhkJ7VDxsa6jILopb87AMcXA15xgG/v6p0dLcdHF3vNlQ/XdkBcqV2dvKPLgfYPeIeGE3fh2I2nkoZmtCmBD/PIOaw6dRbucAVSVxnEZmh9zgOx44a/ysKWwJmVQOz4wMCbUT8Vgrev7OFAUkOomn0WCrIK+dQYApTtqp/j2TXi1pjUbD6Q52P9PFw948U9Ue/Cwmovb1ev5nn81c5mxd5A1f+FL6P6vJXsCHw80jP2pJarbDegxmDjcu2fDqySYb47bgaYSnh4juDHNMd264CEDt7z1JHbuMmAL7YCSeXXpnFpotbM8xuBeY3EnrRcKIXevYKGGDueqHeL7HT7GDC5otiFUYdenbJsN3zVdCKii72mSRkGB9kOiEHFuWJadDrQp249Q93xOxDwLhDpEsfB+l6VkMDH4i7XajhePjCtTZY2fA/slAsbe50GEsnd0V3x0D2BJ29eJ5QWknz0M1BeTo8xK5tSF0A+4RX+h7cO01XmNJCNjRkiLc7TaGJ5UVBc+kug1lBPk8718lzaCsz+RKxTfyJQpIXzNUfmBl7c8axCYNan/JZXyG62/kudOpi5PHBVTktLmFY4H+E5FVt+BbbJ5yhNQaDdesDbRYiBzp+U5404vgT4W4Z5JgQvAQP0EOsBD/0pZkQFY1sNgU0ELCJh6aV1g4DdMkiIWRREvWtH0vHRyV5z1SOyHRBXadYA3+h2oIevPYMJW0XOc5tyWfBDPVXKjgH9vTdFDcfLP2r9sDo8F/hHvq33tBx1K/QSmsfFLcCc+uK3ViJ/qdNQGkwBCstNIPXs4epuAVdK0mrc6uFvduzLB8CI7IIL0xeIAOWpTfbM7jWs+UR7IuoTqf0GIGMp5ysFNfz0oDSYB+eB8SWE7EZTWZSdn/4XWBTKEGREo+0a5z12mNK2qCVwdrXgRgjrRtOifiTW+akRI9TnzQhUelQzttXv3+wBYuSSRu302v2WNJ3E6GavaVKKzkG2A6JTYa4cHt0O9Bu/ANQasx2XH7xEjBjAks7lUDyzKifarLJZ2zC6oEDcYb4voxkxYznnGqKp2iigZAfncyLziCMLgOWdxQ7YDM2qvPO7p4BJ5UXxP1NJCDGql24eAqZWEbNCN7jTy8sV4y9tA2bXC+ZceSBQWYYNdsV6nshz7QBgzwQhmRrxKTxZV30D7J8qRvS7ErIWIqL2eOsIMKWSWN1oKosi+4VNwFxVrZl3AuDzFaIJoxZ680zUObA3A8nKyKSW9T15zH8jgc0/CwmN9AZSAwT0PAEkyejJu3Uu25nVwMLmYlzzhUDuWs7nhB4RumYpZW79PKLZjOhmr7ni8doOiCu0apBndDzQey49RLMpeySN5UyVAKu6V4S3VxgQnkb0yhqC/0YAH/TR/sb88iEwIptYrUwXoKbcidvI+pFhzvbfgE0/Ckm7HQBS5LRO6is7RXGy0eJxOjETywp5avwKlJWb3VknoTlOuycA6wYE82AzORo1seOY4xuZZitFvSyopjOhhfZNBVZ/I0YyxSiTnAKoZa6rxlzdBcyUjTez0Tb1JQZBMD5bot+xZ3ExkbHePgVixARaLgFyyMXXrtJBZOAbFsSxVtl3/wGsk+HVu+wBUslpd1rne9o4dUqaoyagWuQ9MANY+bUYacOda9EYoqO9pkkxOgbZDogOZbl6aHQ90AOWHsOCfaIvwNfVcqFHNQsNYKMPbVgWgA3DWFhM4yEq05p+wN5JYocDbgA+CT1ntw8vAuPkbvRVvwcqyoW9niLh8q7Akbkhpak7Fij+uadI6Ho5xhYVHb0JK9tho7b1Lv8HMA2L5Cn6OrsWWCCnCTb5E8gvpyVq21HIUX6vgfGlgNePgIZTgTy1jXABzq0H5n8qulzHSQJ0+s8uSl/xFXBIRlozUsPBueRB0poyaOzpuWfWoTnAim7m9nNsMbBUjvRHh7RjC55MdLXXLFBdEAvbAbFSmyZ5RdcD/fS1H6r9tg33n79F7FgxsLp7ReRMHcFGsNLJ26rGfCbPhkun/9UaOPUPwDQRon55EllZGOyKfU3+ALh9FEiYDnjzFPB7CaTIDfBmNaxmfK6QI6J4sis1++YEBgCFmwMNZEfWmTxEDhspXzSYRZxytpaWv/PZTa8B3Bfw4Gi/EchYUsvMsMcQ1peOSJxE5vhsHwVs+knwKNYaqDfOHL/IPlsBtyCq4cAb+nej7lEUFaC9904B1sgQ5513AAQu0EvqNC5PRRvUuycXj4+u9pqVarUdECu1aZJXdD7Qa0/cRue5hyQNsg5kcaeyiBkzhkmNmpi+7Evg6HyR+jDoDuDlgmaJJsSzdCo7U1/fK3oVfHXQUtammVnR5de0EGEwCPAX/S/YY4b9LxKkAfbJzetaLAZyVXfVyp7DV124/eG3ItVRC7E+i1FGdh2P6CgjnyOjDBc3CcnZBb3pXM8p+qau6OjeOSagwXufBuIk1qLlqDnmz3rA5W1A4ozA1yf071EN42s20qV/detn7BgNbJSbvBqpiaFE1/YAM2oI2Yx2U7d+Zx7NMTrba1Y9GNsBsUqTFvCJ7ge605wDWHdSNEH6+ZP8aFU2iwVaNchCfevYZa9z5BqDy3jENBbqP7nmWZCoimJ8Xwojn1S6M1BrmEeoTBLi/lngDxnxiY0WCzYW6WIsumchPwv6ozqp+7Q0mQXklyGTteybEYfre4DEmYCvj2uZYf0YGvesRSGyEiltYYFU5R3f+rXMcGQfkZU9BQezBfJm5PCEuUrUMXUB4EsZ3liPXGpju954oFgrPbM9b6wawcoobDyjdeOKA0+uAl5xgR6M6rqgN5fnac+wRNHdXjOsONVE2wGxQosW8YjuB/ruszeoNmobnr/1R3zvWJjZthSKZExibVG61mfFlCSmJpGazgPy1tE6M3KNowH2SyogwBco2ETAfXoSvQsAfkomJCreBqg7xnOkO/E3wKZmpGYLRJ6/uvdJp+1A2kKeI68rJFGj5+jdrzqXf+CtiDH690wC1sqoZUyjY9PARGldoSlzPN8+B0blEV3SaXgz1YbQgdGRxhQGHl8BMlcQ3eT10t2TwMRyYlbNoUCZL/Vy8Kzx6qJ8M4hyajTEUp2A2sM9a58eJk10t9eseBy2A2KFFi3iYR9oYP7eaxi4LPg2lIhYBdIlQtFMSVE0UxLpOxsXxnD1h68afanaD0AFGSHEomftMWzUKU7lvgKq/+IxogUJ8lMK4J0fUKgZ0FBOcfIEKZmXz0gZqccxURx8fR8w/SPxu0JNgYZTPEFS18mg7qA84Cbgk0D7WrvGA+sHifFGYZq1r/b+yHPrgAXNRMSKqU3t1nq2w/hvT+DgTLEPK2pUzOguIucOzSxS95gq12yefkkY7WXUl1RlEFCpr34enjRDDWn97T3j6cK87JlQFnhwFojlLdJxk2TypJ16lCy2vWb+cdgOiHkdWsbBPtDAu3eB6Dz3INafEqlYjihVQh8Ukx0S1osUyuCCKAmLRwfzJjRQdJZlh9moSOrbwBpDgLJyA0ZP2uuQDIDvcyBffeBTuYOxJ8g3vylwbi3AYtgB14NvpKd9BNzYB8T0Eo5J4vSeIK1rZJhVB7iyXRThszZBD6lz8Y02qtSznnrsnePAjJoiooAYQPMF2mG6ja5pdh7BDph+RCrcAmgw0SzHyDefTRqliGggUKQlUF/uP6NnJ5Hh0kXPfhQkPtYr/u+RucjYyeXAYhnBLyp/7unRbxhjbXvNvBJtB8S8Di3jYB9oocrAwEAcuPoYh6/x6wkOXXuMu8/ehqnnOLFjSg5J6azJUSZbMhTOmARxYmtoOOjsySm1ERnLAO3XORsdOf9+YSMwt5GQ3WgXXVfvfHh24NUDIFctoMVCV6+mnf/vBUSTy9DnQ52+F9ULOpkW9Py2sfoh9U10hV5ANbmQVvsTMDby+R3RX+OZjPjmif1lwtoZ5b55EPCKA/Q+4xkNHI09BWOziFY2VL6VL9MVqDlEPx/WO/ycQswr3haoO1o/D0+asbgtcHKpNSiGdPCmVhbIfjFiAV33ASlyeNJuPUYW214z/yhsB8S8Di3jYB/osFV5++lrHLr6RDgl15/g+M2n8PV/53AC07aKZkyCMtmSo3S2ZJJzYsghmdNQIOPtpu1tAAAgAElEQVTESw70vWTZc/YoRofnAv/IUQ8W32aWc6M9SUjF0M9WGWCjLU+g10+AYZmFJCXaA3V+C5aKqQwsRmeeuk9ioNdJz+qtYpX+3r4AfpWjO0YMORo7v2YQ0MVG02n07sX3FTCrNnDrsPzs2gEf/2bu1livDGbGq3s+1BwGlOlshlvkm/v4KjBGrqsykz71S2rA/w1QoDHQeHrk04Na4vnNgHNrADZB7XPB/F7ObwDmNRZ8CjQSF1M2vacB214zfyhsB8S8Di3jYB9o7aqk83Hq9jPsu/wQey89wr4rj/D8jX+YDknj4hnQ66NcSJFAB5zu6r7BsKp9LwPx5GJo7WJ6/kh2id8s130YhXB09S6JzvLwAgIzlcW7NmsQKyLhmZW9qrtm04At2T6kFvZOBtbIueUWF7oyQrj6+B3cf/4G+dMnRr60iRDfx8vVT+F9/rePAZMrit9XHwyUk5uh6ZFkciXg9hEgeU7gqwN6ZuofS4dncWvgtIxOlv1DoMVfQKzY+nlF1Ayiwo3KK7qjs99M172Rx3myQmfqNLRaw4HSnYxxHZEDeHkfyFUTaLHIGA9PmaXAErNeo6cFaHIEJmF6IhHqSJ13AmkKeMpuPUYO214z/yhsB8S8Di3jYB9o46oMeBeI07efYc+lh9h7+RH2XX4ENjhUU0IfL3SvmhOfl8uiDVlr31QB0UmKqkWf6gLGgbcQGDuepL8EPl4okN5Deg1MLA/cPYFzsXKgaeCv6FMjD5qXyuh6IILwjqO6+Ve79UCm0iFHMzrwez7RnJAws90PA7HMOwmskfpp5SnM2nUlaD3iMWRLER8F0yeWnhm/8qdLhIRxXGxYqxu6NV8E5K6p/wW8tBNwbKFI95D67Xjr56F1xobvgZ1yuk3KPED79ZGzn8bqPsA+GdzAU6OWWp+J3nFq2GczKaNjigCPLwOZywNtV+uVwrPGKzVnPNN0SK2gKzuAWR8LTrlrixopAPeevcHWc/dRLntyZEgaz4qVIi0P214z/+hsB8S8Di3jYB9oy1QpFbOfufMcey8/xMJ913H27vMg5lmSx8PA2nnxUb7U4RuxF7cAc+qLefUnAUWaWyegp3Ba2BI4s1JKFdrV5BCGrTuLo9efSNJVy5sa/WvlQY5UOpCNLN4Xb/sfjq6IFE+P48y7jKjpK/qAVM6dEsMaFULqRHEsXlEjuxXdgUNyQXz/6467XW/8Adjxu2DYeCZQoKFG5o6H+Qe8Q7+/j+PvQ9q6P9MpoTNCh5tgDZbTthHAFjl61u2g5lzxZ2/8JLQ7vg5rPJqPGJvlLt/sHp8qr+ViSgyPzAeWy3Cr8VIAHTcBSSOwz5CZXaoR+gp+CjSaaoabW+bygoiBS9Pohdt/Azb9KGQ2czM/qaJo7Miu4YQ0jsw0sQJw9ziQrqhAk7OKZtcHLm2RuN37dCXGnUuKRQeuS6nPCeN4YULLYqiYM6VVq0U6Pra9Zv6R2Q6IeR1axsE+0JapMgQjGm4L91/HbxvO4dFL36C/8Rbnuzr5kDdtIscLP7kOjJZDzxV7A1X/F6aAr30DpJSwEzefSvUpL974I2vK+MiZKoFkwGdPmSBi0mScqXRqVeDmAdz0yoTyL4a+N5rpTs1KZkTParmQMqH29DU6gIxG/XvsNmLHioHPymRGrtQJnUkT4u/P3/hhwNLj+OxMF5SJeRpX3qVG9YAx8A0QtT+J48bGT5/kR73C6cwbNrokAyDrDUkyAz2POZ797LaA+ySEcPriQIdNhtNl3voHoPuCw0GNOpPH98bgBgUkcAaeN5678/degIZeaPKKGQP/q5sPrcpktlZP6ujFt3c1pTI9eeWLVtP3STKTuqc7i16PZINSbyNDrc+MKSW/5QOe3wJi+QBtVgIZ5QaSWnnoHMeatSUHbuCVXwDalsuCVFY7ykoTR+6HzefiJ9cpoXuG8wJh2eGbGLL6jIRc1bh4RrQsnQkZkxm8PV/6BXBskRwxu20ccnbmx8DVHUDSrECPI+5RhqtWGVsMeHTR+mjOjYPAtA8lqXe+K4CWvgND7ICfDT/Wyy+9t0dHsu0180/ddkDM69AyDvaBtkyVDhkxJWv85vNS+opfgDDUeCvXtGQm9K7uoD6EOePswu3/GshbD2g6R5qjOBvHb7AYXjgdF+47Nv7UgqRPEldyRhSnJGfqBMifLrGxAnkLVHX+7nMkn1oMyfzvYUdAfnzmN0jqbVa/SHqwKeSuiw+DVmFjyC8+yI6OH2RFPO+wU4muP3qFJQdvSLf0Nx6/DppPvnULpZNS4LREVKjTbvMP4crDV/gz9lBUinUMr+OkxoMvjqD34qNSip1CHxdMi5/rF0Cy+C5M31HrWyqeTg/4vXJePL2sM3BUpC+g7Vogc1ndT+6Vrz86zTmI7ecfSHPTJo6DuR1KS06tmt74BUhpiNTdiZvPJCOfTrFCdCR//CQ/fLwsQIgjU8UJS5Yd6H7I6b4evniLltP2SpFJhbLGuI0tPr2l//p/0B9eHw5wykf3gAfngfElxLSy3YAag3Wz0DKBTvf2Cw8wd89VbDp9F4ovGM87FjppeO1oWSNozNGFwDK5/oG9e9jDx8OI7wXs6aScW0U8vhdUzpVSMlwr506lr6ZLiVyYrRlSILQZDet70cM0p1Mc1gTRuc5RDfjsb52THQ8/eespJmy5iHpn+qBGLFGb1dx3EB6lLINSWZNhzp6rQRPblc+KQR/n1fccLZEyYpnY9pp5/dsOiHkdWsbBPtCWqTJcRpcfvMSQ1aexQdVrhDUPDYulR8wYMfDW/x1448zv/a+0R0bfS7jqlQXdk07Aizd+4HwHF81Ba/IDNo5XLLz2C3C6Ia5bI38afFIknZRX6xUrptM5ZgfcePwKozeex7JD13DG+3PEjhGAvwMqYG3OH/FN9dzInSahBIXMXN+hq8+ESF9jDxYW8zcpkTHoA4cO2dqTt7H4wI0QTosjOenwfVIkveSIZE0R/70hXHfe3mtSnYOCcjY/wRiU898LxE0G9LsspdfN2HkZw9edDRpDcIFhjQqiat7UZtXjfP7DiwLlilSpH1Al5M1gCAbsNzGpgviVAaSnp6/80HbWPhy6JtLiqLM57Utpzr9effw2ev91NOgsMhVr4mfFkCqhydQ1RhWIAsYal5w1gJZ/hau3e8/foOXUvVKUhlQic1IpjeO/s3dwyqctfGL4Y7NXBcRp/ifKZZchUp0/CW0jDswAVsqNRFsuAXLKjSK1zXY6ilHVvw5cl9LKrj16Feb41Il80Lt6bjQqlsG8scY+RYRAZkO+5DmAbgcMR9ccCczXGEE9EsTx0i0rI84zd16RIs7KeyCh0pPH98HNJ8GXElyXlzItSmfCpyUyOo+wEl1OuhB6A+StCzSdG+6z8Qt4J70/BAQGSu8ZjA6Kn4FEq79EvLNL8S5WHDztdR1JTV5eXHnwEiPWn8W5O8/Rt2YeKb3XbaQ0ZtSgE2cyHbz6GH9suYDNZ+5JQ3PFuI613v0RM0YgniQvikRdNiNmrJhYe+I2ei46gjd+Ihr9YZ5UGNu8qFQ7GF3IttfMP2nbATGvQ8s42AfaMlVqYrTzwgP8vPJUiBvZ0BPHxx6DOrH24k1gbOR9OxOBCOkg0NngTbRSAMzv+dIlAiMGt56+wYV7L8BIw8X7/P5CMsBCF8cra6ZI4I06hdKhXpF0Eoywlnxp3npfuv9S4k9HgPJwnsi3ZoQnhsSe3/njgSuPJUOJaUzJ8RQH44i8+DsFOyNNI1FfoSZ+aC85eB2j1p/DvefBvVhypU6AjhWzST1aVh69jedvQyKQ0VFpWCwDiD7GwkUaI+ztohDD9w2Kpkf3D3MiU3KRjqGkXK08djtoXPNSmfCL/2+IdWqp6FY96FbQ36jXXn8dDUrn4R8+LZFBSqtTF2C/fOuP649f4drDV5KBqHzFihEDrcqKW1hddGoF8FcrMeXT2XiapbYkQ1zvmEgUJ7aUGpYobuzgyNbsT4BLzM2OIboLJ8+uabn7z9+i9Yx9UlSDlCdNQsxpX9q5oRaKO+d3nH0gKCKVJlEcTGldXGrgaZhePgRGZBPTnfRjuPP0DVpM3YNLD15Kw8tmS45pn5cAIwNrTtxBrr+rIweu4fS7TKjlOxQNi6aXblST60GsC28jSp8EFrr3v2oJJDIdZRprjHYQkUxJC1TEqJgzhXTDz9f6yHVnQ7x2mPI5qHZeVMhp0tFaOxDYIzdI/fxfHPUqhBVHb0npn7G9YiB2rJjy1/s/03+kbPxiWtzjV354wv+/8hXfX/uBY3iWaUzXKpBGktdZ9IzRN6ZNKil21Ad1Mbh+QWRIGhfbzt/H3N1XsfnsPYm/QkzT5EUMdVY6azLH731qx/+DvsCHgxw+9Qv3nku39/8euxUU6Q49cLDXdLT02iT9Ovfb2fioYEZ0rZIj7HTcMM4XLwjGbj6P2buDo+p8n+XzbV8hq6b3cMOvQWXiz6mAgLdAoaZAQxmcIBRTvo8/fPkWD5774sGLt9IX31/Ez+J3t+XPK/VUPotxPhOQ6soK8WuixuWqIf147MYTdPjzQNDZ5vsTX9fRpTjdttdMn1zYDoh5HVrGwT7QlqlSMyO+MS+S60P4Jqz+QOSHbc+Yi9AhUIS1P084DU/ipEN2ubi3YAb9EKg0XPiGf/7ecylVZtXxO0FF32qhMyaLK9U2MFrA2gka0Wonhh+ydGaY5hBeNCY8RXyS5gHGPOkuhjjpKcA0oOnbL2PStot46es4skMjgoXrTUpkwAc5U4aI5nDfOy48kBwRNpdUiPUJdFJofPz470kp5YpEB25Iw4LS/rG8C3BkHuCg0y9vOXljN27zhaD6B96qlsySNMjRoL7Do0q5UkoGr+YalS2/AttEvcz0okvw28EAhzphPxoacFW9jmHoa1HnsDdFQ9wu/4tUFE6DLCwnkzfFn03bK0XbSEUzJcGsNqWQOJ4xZCve0neddwi7L4m0Oh+vmBjaqCAaFM2g+bUSYuC1vcCM6uJXjmCI5cGMtrWYujcoMkBjdEqrEojrHZwG5rewNWKf+QdvZSf/HYTeBtTKI92MxzQDu0wrd2Qu4OU9IH0JUXyukXhmaYjTMGNNh/T9CX9+g+M3n+DcXRHNUShpvNiSvLzRz5w8OLrH187U/y5j8n8X8Ur12qmSO6UEhpFTZ21U0IL3zwF/lJT+u927Ilo9k4vsNe5P7zCiCFbNmwq1CqYFXzPq3kq8/Bi98Rym7bgc9DqkPr79OJ8UWQ59znkuFuy7Jr33hn59ZksZX6o74wVGCNj0M6uAhS2E2A4QsE7deia9F6w+cTuEc+Non/295qOz10rpT0XeTMYTiPo0vn91+zAHimQM3znn+868PVcxetN5PHkl0BY7x1qBKrGOYITfpzgQmAeflcmEH+rmd21Um1EhqTM8myq2AeqOkT4reOlAJ5BfJ28+05QirNYTQT66VcmBElmSAXT8xpcEAgNE0f4X/wExxUUcXxftZx0ISvXk85raujiKZnIB6IXeA+vi8ba9Zl7BtgNiXoeWcbAPtGWq1M2Ijsiz137ShyoNx6BeE+pc68+WAjmq6ubtbALD97y5/OfITVy8LwxONbHg+KGqeN4ZP2d/z54yvpRqVdPnGGLM/1QMb/InkF9G/AqHAW/Nxm46j/n7rgUZGuxDQaeDzoKzOgwltev3Dedw7IYoRA5NvEkjwko2pcaB6TNMoyF998BhsfPxG0/R668jQSk+znRA4+jZG/+gPfB5E9r362q5nN68+89vAa9zq/AKPijwZjpoMIdPgVjn3Q+5Y97A60BvlH47Hs+QQDKuimdOIjXKpENCxCqePzqarabtlSJopPI5kktGu+5eH+zTsWssULQVkK0SaDQNXnU6BITvFx9kQ7+aeXSn2eDwPOCfLmLbrVdI/EMTI07Np+4JSrthmgaf63tNQVUOXYfEU7DxbnBtCw3BAulFn5P43l7S9wQ+saQ6JKZ78P+MpGROHs8x7PD9s8AfcsF5+Z7AR3LBeyhheS6Z5rby2C2cu/s8yNHQkkbJZ0djs1aBtOHWcymRQKZrKZcG9K2alcqEFqUySbVRWhum0jGlAVzjQHuUxCn4BsZC2bfj8RD6obO9Y8VEknixkTSet+TgJokbW/p/Ap/YOHj1EY46eJ1S51XypELtAmkl/X+/4mSI9LP6RdJJkUhnUSymSK07eUeqKVDXdfHx8HKC0ZemJTNKaEuxdowCNv8sntyXu4HU+aQf2ZyWjsfG0yJtSCGeHTrujHTy9U1Hlj/ze5nr01Hu2iRpaNcUs7DqRsj6MTrKjIiEjsbwnDA9afDq01LkWaHSSV9g0esvpP8yWt7Zrye2visqOWrjWxR1GST2y+dPEH+UKALfmrQxfgloLb1/qKNLzt4LeXHE9DiCjLA+sV2FrO9DsK/4Cjg0W7AKhehHh6fHwiPYePqu9Gd+fo5qUhh1C6dztnSk/rttr5l/fLYDYl6HlnGwD7RlqrSOkQoJBGYaX2mQiB9uLBpeceSW5JDwpjUs4m1kdrmgncXsNF54a8wPHho35CV95z/p/+LnuLFjSbd7Uq3JwT+Bf+UIiKNeFuHIfOn+C2w9e18qSDTSL4TybTp9D79vPIeTt4ILpXl7/L86+UIaYupUkwE3wkyhYTraqPVnMXv3VcmxYIQhU/L4yJQsLjIliyd9EX2H35mixRQuGhLch0LUK29A25TP8l66CW+yybv2llrIhLs48i476vv+LOWxM92CBrGS1kKoWf5Mp5bfyz9dhd5vRbrMV77d8O+79zvO0xDIly4xbjx6FeRwVs+XWsqt1mqYhnhkSoOyhOmAr08G3VrSAP522YmgtKEPcqXEuGZF9UVXNv4I7JC7v399Ckgsd0SXBeD5YOTjzjNxhmvkT41xzYs57r9z4m9gSTtpXEDT+Zj1MB9+W382zEibo2NJY7V0tmTSDTa/glCW1L18WKDLQl0V0Vj75/BNLD9yK9z6DfUcGrNMY6uSJyVals6sO22Ht9OsQQtdnE1nJEvy+FINFqNxdMRzpUko/Y5rsraCxi+NdWVu3Zi7MM57vCTe6tSdkaneQKkHjP+7QMnh9PMPhN+7d+/9rKRX0elgfUZ46Z6MVqw9cQesJ1JqkcJ6a+BrgZFLGt56iY4f00OXH7kZFFVQeKRLHAfTE05G3gfrgJhewMDb2HvtOcZvufCeHstkS4avPswp1dSFua89E4G1/QX7zjux91Vah7xYq8T3A+7n9G2+X5zCzgvB4ByJ4nihR7Vc+DxgKby2yHDSBFRALHzt+6X0OudznNGmJNIliatXJWGOZ+R7+o7L2LD/BHbGEo7PeP9PMNK/aYg5PFNMEeaZ4Pq89EiR0AcpE9Dh8Jb+z88Np+m+T28AY4sCAb6iaSghs1V9jfh+O3ztGUz+71LQ+m3LZ5HeGxn1e+nrL6UIv3wbAL6P8nf8Tgef9Wj8DMuZiudefJaFB3SiLPD4pa8U2WGas/LFs7rh60rmoqYan5Jtr2lUVDjDbAfEvA4t42AfaMtUaR2j109EsS2p1BdA7RHW8Q6HE4sm9195JDkiVx6+RKZkAtJXeaNmQavTDw1nkm4dBmwdIkb1OAYkdT+cIh2RdSfvSkWNTMNiesd7pDZ2v7kAJAjfuOGtKg02rR3Tt527j8GrToVIqWEK3IBaeaXcd4IRsDB+4tYLePXiGU7FEcby8hjV8Kz6KOmG1lluPF7cB0bmkObdzNwAf6buh0NXH+PYzadBhfSh983UleGNChlL4WBqxtBMgK+cJtRxC5BeLpwHpNodImsxokWiIZIjVXzpJpRRrOQJvMHIW7L4PqqfvZEknrfQ66JWwOkVgFdcYOCtIOeGvOjYtZi2N4h3nUJp8XvTIlI9gkO6cwKYVF78qdoPQIWvpdSOX1adxsZTdyX96yUafXREOtz+AUmurBZGaz/WfyQAC+L/PXpbijg6isKxfonOa9rE/IqDNInjSMab9D1xXOmmWOvZCk9unrshq06HAHlwNJ43ynzt0+BSomLKuFzJvfGPb0fE9Xss+pp8dTjEs9CrN2fj+VzW0Rk5cUd6f1Ju2nkkiIbUq3ouTcZjeOvwImH9qbtYtP9aCGN/tfcA5It5VYIM/zrFFOy7EoyER350EugslGTakDM6PBf4p6sY1W4dkKmM9CN7INGpUQOU8PfsqXP54cug/dLhZb1Kj6o5RQH7hLLAvVOAVxxRJA/gHWJgkF87LAioCp6p6Z+XBNN2zRDTzJjKxzo56ZIlxn3s8OkhsRzl/yk2pGglXQiJmsREknOsxZjXJNOa/sDeiWLoJxOAoi3fm7Zw3zV8u/yE5AAbJdbQ8PWXK1VC5EidQPqeLIE3Lt9/GeRwXLz3IsysgO19qxiHedYhtG2v6VBWGENtB8S8Di3jYB9oy1RpLaMROYCX94FsVYDWy63lHZHc1KlNg+4CsU0iI7lqL2pHqecJIElGy1dSesUwNUyd7sYUDub9Kzf5xWKcw1KfH6T1/aoPRexyOvLuJ1cCbh8B4qcCep+VDEWirdGoYEEznQJ+Z28PRlRYyGq4/kGdekRhHaB1sTi809yDDmuQwlIwDU06IUsCeyPbu6u44Z0Nf+SZLTsr3lI6zoh1Z4N0yILy4Y2dOFF+b4AhaYHAd0DhFkAD2ciRhaBDydvSF2/9pRtU8Z23qPxdgBRh2nvpoXQTHjJlKhAHfTojeYznuBqvALZVnCcZlgSfCG0f0aFnzVX9ounBlELTzr3GE0ojkv1yeAYIT8woAL/Cc7r4DJia1KpMFumWP+bG/4lUO5KL0kQdbYeOHC8PiPzEFExToAZh6ItpfIsPXseS/Vew1bclfGL4YVVAKXT16xk0g1FCOh661j+5HFj8ueDhABntzJ1nUiE7U/JCnxU6tgNq5wmGwb57EpgoRzRLtAcylBTpiTzPAH71a47JAXWl6POYZkVQPX8ajadDDOMlDWu3Jm27hP/OBUdr+beqyR9h+stu4v2o2i+IXcGFcMwv7gFjCgv4cfZP+eqQQ2d318UH6DLv0HtRLMpIx53vEfxiSiWd65uPX78HYqJLQfJgpg3mSJkAgxsUlKKIribbXjOvYdsBMa9DyzjYB9oyVVrLaEYt4NouIHFG4OsT1vKOSG4LmgNnVwNxkwL9rkSkJOGvvWM0sPF7MUZHx20jG2LqFPPJZ+648h6yET/gxuQ4jErn5KhRm1VAFhliV8tim34Gto8UIzttB9IWem8WjQ0iKjmNqDhb78gCYHnn4FFpCgGdt783i7fNYzadx64LDySngcXq6kJpR8vEwDuc9mmLOA6MQfX4piUySuk4mqIFTO94dEk0bOy42dnuHP6de6Hxs+HUPakPR5IXF7Dep5801lF6CtPtahVMI/W9KZ0tuTY5DUmmbxKdEiK1nb3zXPqiQ0KDmIYwo0lEhguRzqNGh7IAilWftO4Z7X/vPLwmiF4uYwIaYbR/IwkxsGuV7MiTJoxGsuGJdmETMLehGOGgoF2ZylobRj6XH74lRZ8JGlA+Ryj0sg3fAztHiylKr5/T/4q0QqYsAZjgXw/D/ZtKjq1WhCyeA9bHTN528b06HIJsdK6UHVUS3kTMaVXE2nV+B0qI6KzLaN0gYLdI+UM47398LfLsEmxCcTb4M8EvQjv3fM/jBQ9BHRg9JVrkOYKs3H0hXTaEJkYllea+/K58MWLrrosDymTba+ZPme2AmNehZRzsA22ZKq1l9E834LBoQohBd4DY1uXyWiuoTm5TKgO3DgOp8gFdduuc7MbheycDa/qKBTvvBNLI3eldKAJvXoetPYNVx2+DhmqHitnQrkIWJNzUH9g/TaxMp43Om1a6uhuYWVOMrvo9ULGX1pn6x63uC+ybHHKeg1oNR4yZq03ITjojdEoevqBj8lb+7ovApzcw8oZAI5oS2ABD3jZ5jw2Lsn+qV0B7BEdxhr0TAgOum+5pwRTG2xvGIP1u4bi29B2Ane8KgnU2VXKnkiIdLIo3VFuj/2m4foYC9UyoYdb7JHKQyuh6KVy3wumVwCKR8vOq/nT45/lEgrw2TNf3A9PleqC6Y4HicjQkDIasp3GYQsimImMKAU+vA4kzAT2OBkcFLm4BFrYE/ESx+ryAqvjWr60E5c46PNaMqWHTJah0gnXLkOk0xhVUQEUsRl++rJwNxTPLaWZXdgKzaos/N5gMFG5mWCWaJqojq4WbAw1EIb8riI4J6yCJ9kioaNZCse7RU3qN2Paa+aduOyDmdWgZB/tAW6ZKaxntHANs+J/g6SYD2NoNhMGNjcye3wayfwi0WuaWJQ0tcnAW8K/Ic0aHTUAGuau1IWb6JhEOl6hAQQhUM2oC13YDiTIAvU7qYxbgDwzPBrx9CmSuALRdpW++ntHTPgJu7As5Ixy4XD2spZ4mNHhJ9SfCt0AzPH4loif8YloFi3d13Uaqb5E1OkpOZV70GcCb6JixcbPzGVx8EohCGRJLKWRRjtQpRVW+BSr1iVpb/G8EsPkXsacue4FUeczt795pYIKo+0D1wUA5kcakm9SXChW+FjVMarq+D5jXWDTsBLAysDx6vu0Ef2hv2EenmVG6TpWyIUeqUKlF5zcC8xqJFT+dDeSTX5e6N6JjgvLewvqvb84BcQxEoHQs56lDbXvN/JOxHRDzOrSMg32gLVOltYzOrAYWNhc8NcLVWiuAC7ixSPnnFCJPuUhLoP4EFyxiEUs1FLLetCeLRJDYsOKWhd1vn2nq/u1waaV4m0XRfS+75sM7wA/4NYMohqVzeWWHSAXJWR1oudi8RhgBWtVb8Gm/Acgow9ya4axOGbOijoE302yU+PoxkKks0G6tGek8fy6f+e/5gRd3RaooQSXkXg2eL7wGCZe0B04skZxJDLrtEIpbA5fgIUR1or5IlQcAlWVELF1M6FGoIMK/3AWklnmq+RBkYU4D0YsGwME4ZXthG/kAACAASURBVNAHPfEWPlJ9B8u13ymohTKCIX/HdCWm3BEWl4AIDkndFNVBLYve7Wgar0ZPrDtG9B+JhmTba+Yfuu2AmNehZRzsA22ZKq1lpGr4hQ+/BT6IAreLz+8Ao3ILPVXsDVSVIzzWas4abieXAYvlDzkHUKrWLKKBy5NrwOiCYmCFXkA1uS5Fw9SgIepoTtN5QN46emZrG3vnODBJrk3hc726C7iwEYjlA/S7DHgHN8nTxjDUqLUDgD2yw0onKp4G1CFnC908CEz9UIyqORQoo6O43xFvNbJWOF2znYkVqf6+8Qdgx+9CZJ2w2h6/z4nlgbsngJR5ga57zIurRjcs2w2oMVg/T39fYFQu4eSmyg902RU2D9bpzK4PPL0mxmSvCvC9jDlYZujoImCZgOENrybDzBLvzX3zTHx2sBidBfcdNlrKPrIws+0180/KdkDM69AyDvaBtkyV1jLiB83gNKITbKFmQMNQufXWruYebqz9YA0IqfZIoFRH96xrZJWza4EFMr69q4x2LXKdXQMskHOsG00HCjbWMivkmCfXgdFyDUvxtkBduXhVP6ewZ6hvKJlaR+Nn9TdifLP5QJ6Pza02rwlwfr214AVvn4uoDUnu6GxKSHWfhzAaJZri74mTbx0BpsgNIct9BVSXU5Y8UVY9MjF1kShpjOLlbwA0maVntuOx6g7ixVoD9cbp56l+X9JS0/X0JjCnPvDgnFjri61AuqL611XPODATWCkjghG8gSAO7qBlXwJH54uVrEiJc4fMFq9h22vmFRqlHJCAgACMGDEC06ZNw/Xr15ExY0Z06NABffr0QaxYsZxq68SJE+jbty927Nghja1QoQKGDx+OAgVCFr22adMGf/75p0N+XDdDBvmD1OmKIQfYB1qnwtw5PAilpwTQcZM7V3bNWmpjuulcgOg5nkos5uQHN8mo4W/F3qzKQ/+jNHD/jCha7XnM/C1o6L392xM4OFP8lhEK35fBTg+7on8io9gY1YnyWrD69vO3/MCzG0CmckC7NUalE/NY/HtmJRDLG+h/LeoAR4SnFaYIjmZB9DUBk9r9sPVny9xTMTb7wXlgvFz3VXkgUFkgm5mmwelEgXj+hkAT+fWih6mSFsY5PY8DSTI5n315O/CnHPWsNQIoLUcvnM90PGL3BGDdAPE3NgdMldcoJ33z1MXvUcnZ1aEF217ToawwhkYpB6RLly6YOHEi2rZti3LlymHXrl2YOXMm+Ps//hBdiMOi8+fPo2TJkkiWLBm++kpgaY8dOxZPnjzBvn37kDNnzqCpigNCJyRmqDzbhg0bIl68eIaejH2gDanNPZPmfQqcXwfESSwampkNnbtH6rBXOTBD5C+T3FzYrXvr6kLPMBpg6eZpZALTwJgORqN2IPPQtReShlhODWXZdT+QMpcRacKeo/QboRHa44gYN7ECcPd4iB4khhZVRwOtRsFhnvzFzUC85EDf4I7KuuVk/cfwrMCbJ64v9tctnIsnqJvFfbkbSJ3PxQu6gb26zsHKGryRuUTNTI6PgM+W6NvI2xfAyJwiDUlPjREvA37NKKLpBZsAjWREPX2rB4/+bySw+WfxfyJwsRmlO4jO7rhiAjo7fkqg12nzdTnukNvCNWx7zbwyo4wDcvz4cRQuXFhyHsaMGROkmR49emDcuHE4evQoChaU87cd6K1x48ZYu3YtTp8+LUVOSIxm5M2bF7Vq1cLixcHFm4oD4ufnBy8vg0aIAxnsA23+QLuMg9po7HMRiB8KC95lC7uI8ZYhwLZhgjlhOxMbi9q5SLqQbNXpYlYhORkRfHxJkT4RRk8NzSxpZNPYJtX4FSjbRfNUpwP93wJD0gPv/ELe7BJBiBEcUofNQAaDqRrq22ir66HUtSVmXmO3jwKTPxB7rdQfqCLfEDtVXhQYQMCBWXKKXZVBQCUZvjoyb23bcGCLXKPRdR+QUq5dM7unccWBhxf0ORDKmsf+ApbKaat635N4NnlGGTFh5MQMqXsLfXMeSJDKDDd9c9XOjxWpnWGtfvMQcOMAUPQzwNvY5a6+jWkbbdtr2vQU3qgo44AMGjQIQ4YMwaVLl5A1a9agPV++fBnZsmXDwIEDMXiw40KzFy9eIHny5GjWrNl7qVWff/45Fi1ahAcPHiBBggQSX8UB8fX1xevXr6Xfh46EGHk09oE2ojU3zVFHDJRmU25a2iXLrOgOHJLTCL+9D3h5MDSpGjKzxhCgbFeXqCRcpn6vgSHpwuzWrUsgdv4elgXwfy2KUVst1TU93MHqYu6PfgbKdxfDbxwEpslF3gRRoPNghNSpe8zFZ06+VaTOZ2+zGshS3hjn3X8A6waKuRGJmmZMenOzWNvAm/lXD807yuYksW724rbAyaXWIWApkimRwtQFgC936pNXqYMiml3vc0D85Nrnr/oG2D9VjOfchKm1zw09cu1AYI+c3THgBuDj+g7gQSKwpoX1bERSzF0baL7A+D7CmsmI0W95BYxxpX5AFfl1bf1Kujna9ppulb03Ico4IDVq1JCiHHfu3Hlvk6lTp0bRokWlCIcj2r17t5SyxfStzp1V3YOZuTBxopTCxTFlygjccMUBSZgwIZ4/f464ceNKURLWi2TPnt3wU7EPtGHVuX6iOneXBYssXAyLiIrCELUV6ECu2pmSUhYvBdD3oqtWsYYvw/ysOyAR1YmoXe4m3sJNlTsOm+kboMitGDBecURDQ6uaW6ohctXGN9OSfssjUk5SFwS+FHVuumnXOGC97Lx03gGkCTuqrJu3OtVO762yerH5zYBzawBJt1eB2HF0ixKpJ/zTFTg8V2yBcLxJM0fq7WBCWeDeKesbps6qA1zZrj8S8fIBwPQtplHlrAG0/EufftXRE7P1d+p6r+8eGk8L1beD4NFzGwMXNgBsgMk0LDPOlCMZ1BD4zpDGjO7B4DzbXjOoONW0KOOAML3K29sbBw8efE8rxYoVA9OlmKbliP7++28wBWvFihWoWzdkMS5/98knn2DJkiVo1Eg0/Onfv7/Er3jx4vDx8cGePXukNC86JAcOHEDmzM7f8G/fvg1+qYnpX5999pm0B8pskwdp4NltYcCRyvcAPvpJ/MybGYbTmSakfD2+Im7rms4BctfyoE2oRJlUEbhzzJwx6q6dPbslbsFIEXULdmgOsEJuVtZqOZBddkaM6kDd3d1KaOHlXYEjND5jiI7i6hvRf7oBh+cIiXueAJKIVFNdxIaQhBImDbxlHtJXvfirR6J2g1S6M1BLThHUIyAjAMOyimaPWSoCbVbqmR01xqrRmaxO8XO3hoiARQTC0CmFVsixoDlwdjUQN5mAp9ZK+6YGo8oZAcXg58OYwmI1swXcSzsBxxaKurTv7mvdgXXj1A0w+ZnIz0YrSf1+Q750chKls3IFw7xsB8Sw6oImRhkHhJEHRjpYeB6aGN24d+8eLly44FBjc+bMQevWrbFu3TpUr149xJj169eD0RWOoXMQFm3YsEGay5StWbOcwwT+8MMP+PHHHx2ysx0Q8wfbcg6MaBAm1PeFwKJPU0A4HMwhDoviJgVYCJooreXimGY4IqdojGWkANP04joZqA3Tct2B6nLRpU42poari3vN1CcoQhAal0WcpDJdgJq/mhIvaPKEcsC9k0CK3EC3UJ3Qz6wCFrYQQ41CLyu3xgnTAb1PWyOzmsuIHMDL+0C2ykDrf/TzV9cLRZUaCL1aYIrfiOzivSpzeaDtar0cPGe8ugeT1c9z6RfAsUXisuh/D7TveXp14PpeIHZ8oM95/U44P0sYQeH7b8YyQPt12tcOPVJpbEpwFKK9uZtYczYqD/D6EZAiF8AaHasAWqgnNot8djN4V/XGA8VauXuXDtezHRDzjyHKOCDujICEpXZGRBjVuHXrltMnY0dAnKrI8wYoOcNhScYPMjomvFG7KEP1Zq0E8Mbck7oSs2vyzynZ2huwApbV1U/K95XoA0Aq1QmoPdzVK77PXzG8E6QGvpFx/M1IwQ/XsUUA3obyg7vbfjPcxFwJYSeDyMl21K+Gf2d0IOAtkKOaaISml2hsPL/tuujCzI+BqzsAow7OzrHAhu/ErtquATKX07vDqDH+r8+BU8uBGDEBFidHVtCMU/8Af8nprp/OAfLVs+75rOoNMGWR9O09wMvHOW919KLgp0AjuZbD+cyQI4Jgon0A1m4YrcFTUqASpgV6n9ErhTXj1Zcz7TcAGUtZw1fdUFXhmO8T4NPZ1vA3ycV2QEwqkHH6wEB+EkZ+cmcNSFjaIgTvypUrweJ0I2QfaCNac+OcjT8CO34TCzLnlRCXbCSlfKXKJz7EmG8/u57ILyapi4HdKG6YS7F48HcZnjMydImmPn9KKrZT7HOg3lj3apFvkcOziVu+7B8CbO5nBakNICty9a/tAWbUEJLVHAaUCVnPJv1eqT1hygZ7hPgIYA1NROjRX9OLoa5qokhoaAI+kPpfB+Ik0iRa0CCltskrLtD/qjajUt8KkWP08SXA3+2FrM5q1jx5R1uHAVuHCAm7HQBSBMPhmxZ7w/fATrkRqNao5vZRwCY5/bbFYiBXyIwJzTLtHANs+J8YbgaVTnHYk2UTfV8igtSOgtGmjo7kVqNsxUkiYLV9EguIbqMQ6Bbqx7bXzCszyjggRLn69ddfXYKCtXDhQjx8+DAIBSsstRcqVAiPHz+W4HuNkH2gjWjNjXOY2nBtF+CdUEQ6wiscppE/sZx402RkpMNGIF0RNwobzlJqRCQzxb7u3A0jNuyEHBGd6NX1P2ZzttU6UyNK1fkdKNHOnEbV3b/DuoncPx1Y1Uuso7cA9vYxYHJFMdeKQnxHu1XXxujtT8N6AaKL+T43nsJl7gl4zmzWpg3PLmonjBRKW70TplLFjAUk1wnSYlXvHWcGLo13GvHhES8iWBB//7ToVdP7rPHeF2rABTN1OlOqALcOAUaQvKx8xkp2gHcCESH2jm+e+/QawPU9ovdWma7Bjmi7dUAmAQgUkWTba+a1H2UcECJgEekqrD4gR44cAR0EFo9fvHgRiRMnRtq0wbn5LDBnDciZM2eCOpkrfUAYXWGhOunly5dS7w8Wn6uJUL2E8e3UqRMmTZpk6MnYB9qQ2jx3krqBVvKcQKdt1rwxm93x6ZXAopaCS7MFQJ7aZjm6fj6bd719BkRECP78RmCeAKBAg8lA4WbW7JcRBRrMNBLz1AGazTPH9++OwPG/RHSOaR2OMPPV0a8inwH1w2/QGkKgE0uBJW3Fr5ovAnLXNCevo9nqrvd6m06qHWure5RYv1PXc5zbCLiwURQo89bYnRCt6t1RhvlNxUUMkdNS5NC+9z/KCIPfFQa22tnttB1IWyh8ue6cACbJ0NAlOwAfj9K+j9AjCevNdMl3/gLKmpDWRkjRT4aS4pIrokhdmF9/IlBErjUzKg/r/ljHxHRSdqpncfuUSoKbGRhxo/I4mGfba+aVGWUcEKqCELqTJ0+WOqGXL18eO3fulDqhq52CK1euSH1CQheLnz17FqVKlZL6gXTvLrDz2QmdkQ92Qs+dWzQ/oiPz8ccfo379+lJ3dCJvEaJ3/vz5UgPDvXv3SsXwRsg+0Ea05uFzVnwFHJJzVou3AeoGN8mMMMnVHxYdtwDpIwHimlKcnKsm0GKRe1W3YzSw8XuxptXQs0ptCaNqNBKN5oJTtnElgIfnnRtrCgIaOxizD4HW+qRtI4Atvwg9dDuoz5DU+sRCRJt0Ag6on1O79UCm0lpXjZrj1H1VGs8ECjR0/z7fPgdoJD+7od94ZK3a4LTCQS/QGGg83Vr5j8wHln8peGrpO8OUKaZOkay4hVeiF4kyAL1OGtvb6ELAk6tA1g+Az/81xsOKWYSeH5lb1JdZAXxwbDGwtIOQjJc+rLcZxcL9+yLl+YutVkhtiodtr5lSnzQ5Sjkg/v7+Ui+OadOm4caNG1Iko0OHDujbt29Qx/KwHBAq49ixY9JYOi6kChUqYNiwYVLkRCH2Genduzf2798vFZszokLHg/C9bIaYIoXxDtn2gTZ/oD2OAwt/2flWQcvSm/biig2pu+f2OuOZKF2h9/17AeDp9YhJrVEiC2w6RuhZLcWqWp+b2mg20zTvzTNgqAyr6wxYYMsQYJsMcdt+I5CxpDZpFchPRli+vWs8/SS81ZjmMjSTiHbpdTaVG//Y8QQiUKzY2vYVVUe9uCfQlgg2UaAR0FiurXHnflf3AfZNCV6RkWACLmhBSrp3BpggO5GuiGid/hdYJCNbtvgLyCXXTznSD+vQRhcUjhQ7mLNmS8sewtO1unj761NAYrm+Ss/zUdAM9b5W9KyhdeySdsAJGdjiq0P60+3U6/zdATi+WMCJ97kgQBSU9x+O++YCkIBAKhFHtr1mXvdRygExr46I5WAf6IjVv8tWJzTotI/ETZ4EzbsrYrHMlUZlRMhhF3QPKOhzqnvldt8sbKXThRwMcFUjNC6lTuuo8DVQ7QcjEgKX/wP+lHsYOavrUTdVZFNHNnfUQlOrAjcPAMmyA90PaZlhbMy0asCN/UDSLECPo9p48LZcqv94YS1QgLbVPXeUkkcvRdguWus8O9v1tb0yKEIonJsue4BUcl+f8HicXAawBoTUdB6Qt46zFfX9XZ3u56yfx9VdwEy5p1OFXkA1OSKqb8WQo2ms02gnMQWLqVh6aQih4Z+bS+PSu2ZY4y9uBubIe9DzvhKaH3v5MP2KURV1apkaWKHBFKBwU6skN8THttcMqS3EJNsBMa9DyzjYB9oyVXoeI/VNd0RD8yo3xVZByrpD2xMrAHePA2mLiFoadxFx7oekE7naBZsAjWTYTqvW540/oW1f3BFdxZniZYTUqDpMT2CaQlgkdUXPK9bU2l2Ycg7LLBpvurqoWd1McdBtbV3ir+8HplcTO676PVBRLrQ3osuoNEcNS9xyCZDzI/fsjoAdBCx4IENWVx4YXETMnyv3cy7Hll+BbUPFOLM36o5WCwHGMQpgXUdYpO44rtWBcrbDJ9eB0QXEKBZZ15TRvpzNU/7O1+RPyUVH9iItgfoTtM50zTg6DmywyEg1YYG/PimAB/SSGs2vyrdApT6Cw8uHwjFhRM8MBLJeecIYb9tr5hVpOyDmdWgZB/tAW6ZKz2NEo2/OJ+KmmuSKrrFadz2xPHD3BJC2MNBJlkfr3Igap9y+swlk1z3uk0INMVntR6BCT+vXDjK4IZB1EqbRv4bS94EFx1JfASc9DVZ0Bw79KdbpeVyklYRH0oe/jBJkxFjSsyO1M6W15kYNj6oXPUuPbJFt7KNLwFjZGXUnhPXmX4D/RghtEd2NjS+ZDvbqgXanl/0/2AfEK45IfTRizIb3vO6fBf5Q9axg7xmidElfOUSkj9/ZeZuOAm/krSyGpwPxWz7g+S0gfQmgo9w7SusZ8/cFfpHTkMwWxWtd09k4dXqnUYdXDXf/xbaQ6JFTPwRuHhQoZEzD0lq/5kxuA3+37TUDSgs1xXZAzOvQMg72gbZMlZ7JyFOgednT4tVD/Tn2EalVpVg7aVagxxH3SXJ0IbCsk1iv5d9ATvmW3UoJ1OhSRhFklGJUrQWaagjgWiOA0l+EvyMpnUbueeAsxcusbs6tA+Z/Krg4S41R1mLqB1NACAPa74pd/6F+BhPKAfdOAhLowFnrDfnQz5tphUQsYtSQRn3XvaKfy789gIMy2pOWnh7jSwEPzpqLDIZ3Ftng9Lc8IqoXLsUQt+4kpkgyVdIqUpwsIoTx4iB2HO2cXz8RUUmSlfDg2iV4f6S6UaNRxEIl2p0gjWiuqK61UTs4EQygYttrZg6KmGs7IOZ1aBkH+0BbpkrPZRQCmjeHiEBYgZmudcdMKfollRjtKahcWmRX0sbc3fF3/bfArnFCQlcV7KshJ40UC3P+8KxCxhLtgTpys8zw9Erji3P832irmTg8D/ini+DYegWQTYbE1PLs9I55dFl0iSdpaZTJm2AaYn6vgBwfAZ8t0bti1B6vNtqsQG8KT1tMw2END3tTkJovBHLLtRPqGoEPvwM++CZsTnymQ4iA5aLUR2VlRojOrBIgIQ8vii9GJMKinieAJDLYgxWnZtd4YP0gwUkvcpsaMa5SP6DKQCskMs+DtWiM9NOposMbP7l2nmqYcEdgGtf3AdPlNEJ1epb2FSwbadtr5lVpOyDmdWgZB/tAW6ZKz2akhuZlLitzd92F2PPkmkBzIVUeAFTu79m6UqRb2BI4s1IU8fOG212k3KzHTSZgcs0i34QlN0EKbuwT+2NXZj3pJuyzQAeNVG88UKyVNu2wN8O5tc77RLCJ3Np+IsJAMorYo00qgEbskPSA/2sgbz2g6ZzwZ6pzxiMytVHr/tw9Tt1Asmw3oMZg10mgNqhDO9MEChiZU6QyOUv/vHcamCA3m3PmrFi9GyIX0jGRnBJ+XRLoVzyLpTpau5raoK7+i4hkaCU6S+NkCHWrIzNaZXA07thfwFJZT3rRy9TQ0Y4QI9lslHUgbPAbEYAkqv3a9pqZQyLm2g6IeR1axsE+0Jap0rMZhYbm5RspITKNwDDq3an6A489SRgFiQykQDwSYpWFye4i5q2/uAtkqQi0Wem6VbcOCy7S1VvDwFx75tyTOu8E0siFrc6kVX/YfzpbNHlUiB/0Z1cD+6cBl1VF/+xK3PeK63OvJ1UAWH+TMo9I4QmP1PvvuBlIX9zZzqPX31lrMIb9Iq4JZLHuR1zjSNNoZ7oXHUc60l33vw+VqiDw8QlQjmRy5C70E1GnJTabD+T5OGo+M0ak2ZAwwBfIWxeg0a2V1Ah6tYYDpeVUUa3zXTWOTRZZjM73TZ9E4jlrjYIsaC7edxg96XfZcfNMIqMRIY0ojrwU4lmLALLtNfNKtx0Q8zq0jIN9oC1TpeczunsSmNs4ONzPorqGU4EcVV0rO4s6mXdMcoZ971pJ9HFXIyN9/9g1BlRoiV7cB0bKXZtLfwnUkhF59EmubbQakUcrSpDCWYkOecUVeeRaYZXVKRyFWwANJgLP74ridDonoVNRUuQS4AlKSo22nRkbpfQBYO+VQXfCjxD+WU84STR2+l7Wvn9jkkXOWWsHAnvkrvd6nFStu6WTM5vPQQa1YPO4ws3en31+AzCvsfh9eNEqddqYKxCwtO7LHeOU6Kejmofw1lcjv9UbBxST39fdIbOzNfZPB1bJSHRaQSuInMa0UKZSZqsMtP7H8SrqdFCj8MXO5Nfwd9te06AkJ0NsB8S8Di3jYB9oy1QZORi9fCBC1UpqC5suVeoLMJ9XTwqOnt3unQys6StmsP6EqRCRgVb2Ag7InZDZu8RMx3Ct+720FZgtRwX0pDZp5a8eJ2Hf5wBePwIylAI6bNDOZVRe4SxkLA20X699HkdOrgTcPgIwxYwf+qdXiLx7hdh0kLfPTD1hFMhVKWihpVZ3XedNeko21HNAvEEemlncuntCMzZ92nffaHUfC1ekXh6aA6zoJvaTvSrw2d+OzwprO3jO3z4VkSpGrBzRolbiLLoKAct9mne+0rpBwO7xYpwWRDqF46VtwukjaQVrcC6NNSOYbscUOqawEZmPoANJ5YL5sFZQp5LW+BUoK9echR7//A4wKrf4bdHPgE9kx9oayTVzse01zaoKc6DtgJjXoWUc7ANtmSojDyManoQQ5Y2fgrTCPiHsN5FALha3cjcbfwB2/C44fnPeNWtYKa/CS32D2/+6QNVxNakNA3cgrihpZkwtYB1IvGTOd6j+MDYSpdk6FNj66/vrsEcM0/P4RRhSd5M6Use0lOwfAuyb8PQG8PSa+M7/P7ooYDlJenPo3b2niFyP7zMKDG7qgsCXBvvNONoDzyDhbIkmFTu+gMkOD9ZZ3dE6rKLu8SVFD5E0hYDO2yNSc65fW33W9TgSZ9cCC+RmfJ6YpqbeV6GmQMMp4etyTT9g7yQxxlnUS0HKIihJr9PuuxhR7cC218y/NGwHxLwOLeNgH2jLVBn5GPG2nWknL+8L2RmOZ11IlvLW7mXZl8DR+QBvtr974PpcfqukV2PDE/89gYx/bxX/0HzOrAYWNhe/jZ8K+PqE894aZmU5Mh9Y/qXg0ngmUKChc45qOF0j3YGlPPIKwc5v5gpAyfYiH91dwAiOdqnu0RDLBwh461wXWnuGOOcUNUeowS/YYZ71II5IScMjBPU7P9ELI+hL7o2ROGNwlHbRZ8DpfwUnLbUI6teWo5tuRrUGpxUN9rQYrpH9aalTIUt1AmoP17ajo4uAZTJ8dqtlwkn3JGJaHhHRbh5gubEccS/kWEKOZb+ax5eBZNmA7ofD38mG74Gdo8WYL3cBqfO7fee2vWZe5bYDYl6HlnGwD7RlqoycjPhB9Hd74OpOIT9vwokAU76ndY7C7PrApS1AovRAr1ORR0/bhgNbZPQePWkKRnb44DzAhldvn4ln0Gq5a2FnFRnV0Yz8DYEmM51Lr86VDy9VKTxOx5cA3DOL0FPnc76mO0YwhYPFuYQJDotYH8JzzNv23LXDTtlwh7yRYY1z64H5TYSk1QcD5eSUKf6fBiABKvZNEc3/6HiER0yrYU+eRGkBXp6QmDrYbq3z9FHm+hPJyPeFYyQj1sdNLCd4Rpeu9r8XEB3Etfbx4fOaURO4LjdlpcFOw93T6MpOYFZtIRUdJDpKjojvP+NLiL9oieRe3g78WUeMjyDkO9teM3/YbAfEvA4t42AfaMtUGXkZEX2IhvYOVS+HnDUAIlbxw94s/VEGuH8aSFcM+GKLWW7um6/ujq2liZlRyd48A6ZVFekfpNCGmlG+WucpnX45XktaxbwmwPn1gHdCoP816xxVrfK6ctyh2QC/WJ/C3guJMwC8eafDwZ+ZJuaqWilX7iuieDOyMJyG/3MgU1nhLBCxiA4oHY87x0JKxigsoyRMc1Mis2HJToek03YgVR5tu1vSHjgh92sJ3V+H8vAihqTuI6KNc+QctbgtcHIpQKeaKabe8cLflooWBQAAHExJREFUh7pZp9bLiojSjAL3zfV5mZO9yvuSqOGbtURzWEvEgnU6sa5GKAxDb7a9Zv5A2Q6IeR1axsE+0JapMvIz4m0lw+vEzCcRfrZ8D4ETb6ZxIQt2iaGe+2Og+fzIoyd18byrUm3evQP+aiX6jZAKNBa1OO4qvOaaNw4AM2qIQnDCSxKxKCx4Zt6CsqD31YMI+xCOPAfIllTSgGLoMiWmdGfg2MLg9xhFRZnKCdABdRoeu27TEZGa9Sn9MeT/0wisNUwfDKy6PqD2yJD9NQgpTWhlUnhQvVHpke6ZJHrtkNqsDj/1lu9TTJtkd3um0nbbDyTP7rnauHsKmFQeCHwnQE86bn3/okRpXsgaIsLvevk434+C/hceZK9zLoZH2PaaYdUFTbQdEPM6tIyDfaAtU2XUYMQiWxYms0GdQiy6Y3Onws313/7ytnNwGsFJa8dsT9HkwT+Bf7sLadpvBDKWtF4ydT8JFuoSUcrZTaT1UgiQAIIFkFiT8fkKx8+a52O03PODjimLsG2yNRCeBk78Ld5TQhMhnAt9KhyBNHKjUi2apBNMZ1lvvZDvK5GGRcjV0DfYimHJS5cBN6NWVC8snRJIgdFPkrOmgupGfwSJYHTc0ykIRt0BYhejzoxm8BzlqQM0m6dtNwdmACu/FmObLQDyyKle2mabHmXba6ZVaDciNK9C6zjYB9o6XUYZTrzt4i3lpp+A56oGfDQSmB6UrZL2rT66DIwtIsZX+Rao1Ef73IgeqS64/HwlkLWitRJJ/QmYHx8oIg9fbA27SNfald/nxmc+t0Fwbn2VQQKeOTSdWiEiNiStReuult3m79kaePtcoGHR8CcxxapkR6BoS/c3dGM/IkZCWGfV+2wwIt+44iLKkrYI0EnVBNOzNWtOOqYUDc0oap5Yz9R8gWN+HMdaiSdXBUQxaz8iAqVO726JWsfnyv0lySxgeRUodXU0rO5YoPjn2rg/vioabJIi4ELNtte0PabwRtkREPM6tIyDfaAtU2XUY8Tu6cyTZS2E38vg/eWqJYrwwuqToNbE1d3AzJriN67ua2H1Ezi5HFgsfzC1/BvIWc26FZhWMrWKgBGlMcQeBhGNKMOC9InlRXoVZWJaRuayIfeshlSOLqkq1j316MuJ/RaY4pmjmviKGTNidKGOxtT5HSjRDpAQsNKIdB1GeRvIsKwRI6F7V51RC7i2C4iXAuhzwXHq576pwOpvhFxMyeV7f2ShDf8Tn1+kmsOAMp3Fz/90BQ7LHeBD1wM525sC18y6sB7H3Joua9trzh6O87/bDohzHblthH2g3abqyLsQDVPmSEtv2IFiH8wD5od35f5A/BRh7+3EUmBJW/F3q414V2tUjXnfdB6QV0ZAMbvu2xfA9I+AezIiWLUfgQo9zXK1Zv75jcC8RoJXogyiH4K6NwibJBKBiBEbdgB3Z62KNTu0uURnDTAawxom3opnqwK0Xg5IsNAy9LgnvRbd8ZzUBrojVCteQo0pAry8B/gkBnoc0dYryB2ya1mD9YyUnzWI8ZKL+h7vBMBveYAXd0XqH+v79NDaAcCeCWJGt4NAihx6Zpsaa9trptQnTJfAQCZx2uQJGrAPtCc8hUgiw53jwPpvg9N0KDZzptkZtmxXx+lDuycA6waIDbK4OY1cPxAZtqzuSq6nWVd4e+Nb3+I2wKnlYlS++kCTWZ5lyKubIbIo+NM5Qj7KPoyAAk/Dh7eMDM/WljH6amBBC+DsKnGJwlv/i5uDEbBa/AXkqhF9dHN6JbCopdivo54+/40ENv8s/l71f0DF3pFPN7vGic8t0gd9gDwfA1Mqi/9X/Aao+p2+Pam7p9ccCpSR+yjp42JotG2vGVJbiEm2A2Jeh5ZxsA+0ZaqMHoxohLJ2gW/oD84G75kpO+zpwMLk9MWDf7/+O2DXWPH/PpeA+Mkjj56u7RHoUKRP/hCOllnaMRrY+L3gkiof0H4D4JPALFdr5zPnmxGa20cE349/E40CmTY2rpj8wd1bGCQ22RqIbBpQ13YxLfTxFWD7SLELptQkzRzZdmRc3hf3gJE5xfzQNQ2vHgFjCoveRGyMyuiHGTRE41Kam8keMKxhYc8TXpgVbgawmJzE99+MpfTxJ79hWQD/1yKdkOmzbiLbXjOvaNsBMa9DyzjYB9oyVUYvRuwdwkJ13i7dPxNy75nLA+W6AzmrA8sJu7kIIGzhd/c966bf2RO7dTj4piw0bKezuY7+fmETMK+xyDWPkxjouMVzoSzpbEz+QGDes/CUsjJlTOmVYGVKmhFd2nNsDRjVACN47E3Cxoc5PhLwq4TBjk4IWGrd0cmgExY6HUl9eWTF+5/R52XFvCMLxGeRmpiS9c15/ciO5DG3MXBhg3hv7HcFiB3XCimd8rDtNacqcjrAdkCcqsh9A+wD7T5dR8mViJ7EN+KdY4GroXJpU+QWt0RPrgGJMwFfH49cKlBDzhJFhbdlCVMb2wPT12Z9LNKX2A+h5WIg50fGeLlrlvqmOGVeIHM54MB0sfrXp8LuFeIu+ex1bA0Y1cC8T4Hz68TFCGvYiPantSO40TU9dd7fHYHjfwngCTYkZET22S1gbFFRK0PUsq77gxGkPHUf4cn1LgCYVFH0MVGoUFOg4RRju1H3UGEEhJEQN5Btr5lXsu2AmNehZRzsA22ZKm1GxJVnRIQQh7zlV1OGUkCHDZFPR0s7iUgPiTeERIaKk0jfPu6fA2bWEuhSpA+/Az6QUWX0cXL/6GWdgaOh4DmZjvHNucgVzXK/5uwVPVkDh+cB/3QJKWHhFkCDiZ4stWtkU6NctV4hYNb/7QEcnCXWazgNKES48EhOEux54+BNmKnre3ABGC+nGpfpAtT81S3Kse0182q2HRDzOrSMg32gLVOlzUjRAMP5LD4/PCcY+79gE9HhO7IR6yHmNwkuvM/6AdByibauudwr+6DQ+VD6qZT6Aqg1PPIY70QNYirWo0vBTy5XTaDFosj2JG15bQ0Ea4D1Dax9YCM6hQgvS5jZ6Ea3j4rXOIkNZ/M1AP4oBQQGAKkLAJ22RxxsspXPgvWL7H5+hfuJDfQ5b7wPDXkxdY29UVLkEp3h3UC2vWZeybYDYl6HlnGwD7RlqrQZhdYAP+RZ7Mf0o8oDgFR5IqeOaITPqhNclJ2/AdBohvMPZaYxzKgpPqRIRVqKXigR1QPBqPZZCzPtI5EzT+KzJPyyTbYGIrMG5jQQCFgKtVgM5KoemXdkTHbW8w3NJHo95awBeMcDTi4TvKIaKhjfkzf9DOSoChRURUOMaG5lr+CUVDeBF9j2mpEHFXKO7YCY16FlHOwDbZkqbUZRWQMv7gMzqgdHApxFMjh+Vm3gwTmhFclpmW6s4NET9Lr7D2DdQCFJm1VAlgqeIJUtg60B4xpgihFTjRTqeRxgc7noSLxgYWTAK66o2yNlKgu0XRN5orXufm5n1wALmgk0w7pj9KNpGZDXttcMKC3UFNsBMa9DyzjYB9oyVdqMoroGmE41vbpoykUKq5aDza9m1QXuykX3vFVsOjdyF3Ey5YBoZiTCWNpkayCya+DlA5GGxXo1NqcbcCP6GtubfgK2jwr5RNuuBTKXjexP2XXy+70GXj0EEmdw3RqhONv2mnlV2w6IeR1axsE+0Jap0mYUHTTAfOmZH+P/7d0HrBVVHsfxPzyVPCVmVwjiioKgQXRtaGxgiSWQiIgFwbYUC9iCsWBNLLEkYlTEApYom/eWqMjGiAvYie+pq0gsRMSCWFBUMJoVURTZ/M5z8HU4c87cueU7iVHhzH9mPufce89/5pwztvZ/DVerIVX9z/jzyjVc65/DzJYvaPgzzRnRMIYCLdNYCVXANSIQTSBZDavA73OIdv6xAi2ZazZjxJ/RmOcVSzZqHPpr4ZwkIOGG0SLQoKNREqhSBJbOb1hNZd3ahrcpj/yXWd/BZrojVju8YSiDNq38dca/i+9Fg5VST1wnAhsT0FMQDaXR2887d9tY6fL9+9WrzCb1/uP6OpiNrzPr/vfyvd4SvTL6a+EVRwISbhgtAg06GiWBKklg0SyzmWPNbH3DuGm916N+csM7UbRpyd5Rs82q/1JJKlwrAgiUqkAyD6T/P8yGTinVqyjr86a/Fl69JCDhhtEi0KCjURKo0gT+O81szsSWV60XMI75T8MLztgQQACBUhDQqoUaYqphox2rSuGMK+4c6a+FVzkJSLhhtAg06GiUBKpEgeaTN/XWYK0cs/XfKlGDa0YAAQQQyEiA/lo4LAlIuGG0CDToaJQEqkQBrQ6lpTwXTjfbukfDk4+/9qxECa4ZAQQQQCBDAfpr4bgkIOGG0SLQoKNREqiSBVYsMuvSh9WuKrkNcO0IIIBAhgL018JxSUDCDaNFoEFHoyQQAggggAACCCCQiQD9tXBWEpBww2gRaNDRKAmEAAIIIIAAAghkIkB/LZyVBCTcMFoEGnQ0SgIhgAACCCCAAAKZCNBfC2clAQk3jBaBBh2NkkAIIIAAAggggEAmAvTXwllJQMINo0WgQUejJBACCCCAAAIIIJCJAP21cFYSkHDDaBFo0NEoCYQAAggggAACCGQiQH8tnJUEJNwwWgQadDRKAiGAAAIIIIAAApkI0F8LZyUBCTeMFoEGHY2SQAgggAACCCCAQCYC9NfCWUlAwg2jRaBBR6MkEAIIIIAAAgggkIkA/bVwVhKQcMNoEWjQ0SgJhAACCCCAAAIIZCJAfy2clQQk3DBaBBp0NEoCIYAAAggggAACmQjQXwtnJQEJN4wWgQYdjZJACCCAAAIIIIBAJgL018JZSUDCDaNFoEFHoyQQAggggAACCCCQiQD9tXBWEpBww2gRaNDRKAmEAAIIIIAAAghkIkB/LZyVBCTcMFoEGnQ0SgIhgAACCCCAAAKZCNBfC2clAQk3jBaBBh2NkkAIIIAAAggggEAmAvTXwllJQMINo0WgQUejJBACCCCAAAIIIJCJAP21cFYSkHDDaBFo0NEoCYQAAggggAACCGQiQH8tnJUEJNwwWoT6+nobOHCg1dTUWL9+/aLFJRACCCCAAAIIIIBAHIHFixfb6aefbnV1dTZgwIA4QSssCglIEVV4bW2ta9BsCCCAAAIIIIAAAsUtoBvGp512WnGfZJGeHQlIEVXMypUrbd68edarVy+rrq7O/MySDJ4nLplTt3oA/PNx11Gxz88ef+zzFcj36Hz35Ocf037NmjW2bNkyGzRokHXt2jW/iyrhI5OAlHDlhZ46YxhDBcP2xz/ML2Rv7EP0wvfFP9wwbQTs08rF2Q//OI5pomCfRi27fUhAsrMt+sh8GPOtIvzz88c+P3sdGf/8/LHPz562j32+AsV1dBKQ4qqPgp4NP0QF5W5xMPzz88c+P3s6YdjnK5Dv0fnuyc8f+/zsWzsyCUhx1UdBz4YPY0G5SUDy5W5ydNp+vpWBf37+2OdnT/KNfb4CxXV0EpDiqo+Cns1XX31l06ZNs3Hjxtl2221X0GNzMDP882sF2OdnryPjn58/9vnZ0/axz1eguI5OAlJc9cHZIIAAAggggAACCCBQ1gIkIGVdvVwcAggggAACCCCAAALFJUACUlz1wdkggAACCCCAAAIIIFDWAiQgZV29XBwCCCCAAAIIIIAAAsUlQAJSXPXB2SCAAAIIIIAAAgggUNYCJCBlXb1cHAIIIIAAAggggAACxSVAAlJc9VGQs1m3bp1NmjTJHnzwQfv8889thx12sLPOOssuu+wyq6qqKsg5VMJBfvzxR7vtttvszTfftAULFtiKFSts1KhR9sgjj7S4fOokXouQdU1Njb3wwgv2ySef2FZbbWW77767XXnllXbUUUc1ORDu8dyTSIsXL7brr7/etXst+dqxY0fr3bu3jR492s4991zr1KnThoPiH9+/eUR9Do488kj3xx9++KHtvPPO+GfEvmzZMttpp51ajX7mmWe639xko+1nVAl/LPN9ww032NNPP21ff/21denSxfbff3/32oFtt93WHRj/7Pw3NTIJyKZKlVG58847z+677z4bM2aMHXzwwfbKK6/Yww8/bPrze+65p4yuNN9LSX6M9I6Vfffd12bPnt1mAkKdxKurk046yebPn28nnnii9e/f35QIqn0vWrTI7r33XtcJTjbc47knkZ555hmXeB9wwAHWo0cP90NfX19vM2bMsGOOOcaeeuop/OOztxpx7dq1ttdee7kbTatXr26RgND+41ZE8p1/3HHHmb6HGm9K/A488EDaflzyFtGUZB966KFWXV3tbnroO+jbb7+1V1991d143WWXXdw+tP2MK2ITwpOAbAJSORV599133Q/ShRdeaJMnT95waRMmTLApU6bY22+/bXvssUc5XXJu1/LLL7/YypUrbfvtt7fffvvNNt9881YTEOokbhWps7vffvs1udO+Zs0a23vvvd0P0TfffGObbbaZ4R7XfWPRLrjgAneD4/3337e+ffvivzGwCH9/yy232J133mmnnnqq+3fjJyC0/wjAzUIkCcjVV19tN954Y5sHwD6+vSKuX7/e3fjQTQ/dhOrcuXOrB8I/G3/fqCQgvmIlXl5fjDfffLMtXbq0yaNiDVXRMImrrrrKbrrpphK/yuI7/fYSEOqkMPV1ySWX2O23326fffaZG3aIe2Hck6PoqYiGeb722muuk4B/tv6ffvqp7bbbbnb33Xeb/lvD4honIPjH92+cgMhXm+7EN9+wj2+viMlwQz1lHTJkiP38889uCOgWW2zR5ID4Z+PvG5UExFesxMsPGjTIPeXQfITmm8ZG7rPPPjZ37twSv8riO/32EhDqpDD1dcopp9jMmTPt+++/d/NCcM/W/aeffjL9o6E/r7/+up1//vnuKeBHH33kOmX4Z+uvYUB62qchtko+micg+Mf3TxIQ3XnX0E9tGnp10UUXufafbNjHt1fEiRMnumFWL730kruZqrbfoUMHd8NDN58OOuggd2D8s/H3jUoC4itW4uU1vEp3AzRBtPmm8fK//vqrGxrBFlegvQSEOolr3Vo0TYzWECzdFXviiSdcEdyzdb/uuutcpzfZ1Am4//77bc8998Q/W3o330wJiBI/zT9L6qLxExDaf/xK0NPVsWPH2rBhw6xnz5725ZdfuonnWhjj0ksvdZ1jvnviuycR5f7kk09a165d7ZBDDjHddFIdaEK6bobo86B2T9vPrg58IpOA+GiVQdk+ffq4VSB0Z6D5pgnpumOmO5RscQXaS0Cok7jWzaP98MMP7s6XVmTS078dd9zRFcE9W3cN89Q/q1atckMj3nnnHdOchMMPPxz/DOk130mrvh199NFu1R9trSUgtP8MK6FRaM1HOOKII6yurs4++OAD972DfTb2WuXw+eefd6u+PffccxsO8vLLL7uJ6cOHD7fHHnsM/2z4vaOSgHiTlfYOZP751B9PQPJxV2dMj9vfeOMNN7TwsMMO23AifBYKWyd33HGHXX755S4J7NevH3chM+K/5ppr3Gpv6uzqTnBbCQjtP6MKaCWs5iQMHTrUJYTnnHMObT8j+mOPPdY9/dNS91ryvvHWq1cv0++BluWl7WdUAZ5hSUA8wUq9OGMf86lB5oAU3l1LkOpHX3ffZ82a5YZfNd74LBS2TvTD37179w0LXeAf31/DTbSYiOYc6N1OyXbXXXe5VQ51d1gdMZXBP75/WxH19E+rT2qBF81NwD4b+/Hjx7skb86cOTZ48OAmB9ESyAsXLjT9LuCfjb9vVBIQX7ESL68vPw2DYBWswlZkewkIdRK/LuStdfh157G2ttZGjhzZ4iC4x3dvL2IyQVfvYdEdevzj+7/11ltuIZH2Ni3AoAnS+Mf3byuiboDovUSaD6IXEmKfjf1DDz3kEu8HHnigSQKuo+l9INq++OIL/LPh945KAuJNVto7aPiDfqDaeg+IfsCSSaKlfaXFdfbtJSDUSdy6+v333917Dx599FE36fnss89u9QC4x3VPomkeWbdu3VoET1aoSYZH4B/fX/Odnn322RaBNe798ccfd09B1BHTZF384/t/9913ts022zQJrGE/AwYMcC9C/fjjj90S4NjHt1dEvXdLk/81xErvg6qqqnIH0rAsDc9K3kaPfzb+vlFJQHzFyqB88phSb0LXF6M+qHpT9Lhx42zq1KllcIXFcwlag1/LvqpTfO2117rk74QTTnAnqOFBSbJHncSrs4svvtg030DzPRoPQ0mOoMm5WohBG+7x3JNIxx9/vJt4rsnm6myp/c+bN88N/xk4cKC9+OKL7kWQ+Me3bytia5PQ8Y/vr+92rbak4T5K9DQkbvr06W7EgUYeXHHFFRsOyndPfH9F1AuWNQRRq2CdfPLJtnz5ctMQRD350+qf+k6i7Wdj7xuVBMRXrAzK6278rbfe6h4H63GkvijVUdMdyqRjUAaXWRSXoPHWeglYa5uSvtGjR7u/ok7iVZc6vnoLblubOsDJSky4x3NPIunJk55yaNy73jzfqVMn23XXXW3EiBHuyav+P9nwj+/fWsS2EhD84/prCJASjiVLlpiehuh9IFrefsKECe6GU+MN+7j2jaPV1NS493689957tuWWW7oV4ZQAau4T3z3ZuftGJgHxFaM8AggggAACCCCAAAIIpBYgAUlNx44IIIAAAggggAACCCDgK0AC4itGeQQQQAABBBBAAAEEEEgtQAKSmo4dEUAAAQQQQAABBBBAwFeABMRXjPIIIIAAAggggAACCCCQWoAEJDUdOyKAAAIIIIAAAggggICvAAmIrxjlEUAAAQQQQAABBBBAILUACUhqOnZEAAEEEEAAAQQQQAABXwESEF8xyiOAAAIIIIAAAggggEBqARKQ1HTsiAACCCCAAAIIIIAAAr4CJCC+YpRHAAEEEEAAAQQQQACB1AIkIKnp2BEBBBBAAAEEEEAAAQR8BUhAfMUojwACCCCAAAIIIIAAAqkFSEBS07EjAggggAACCCCAAAII+AqQgPiKUR4BBBBAAAEEEEAAAQRSC5CApKZjRwQQQAABBBBAAAEEEPAVIAHxFaM8AggggAACCCCAAAIIpBYgAUlNx44IIIAAAggggAACCCDgK0AC4itGeQQQQAABBBBAAAEEEEgtQAKSmo4dEUAAAQQQQAABBBBAwFeABMRXjPIIIIAAAggggAACCCCQWoAEJDUdOyKAAAIIIIAAAggggICvAAmIrxjlEUAAAQQQQAABBBBAILUACUhqOnZEAAEEEEAAAQQQQAABXwESEF8xyiOAAAIIIIAAAggggEBqARKQ1HTsiAACCCCAAAIIIIAAAr4CJCC+YpRHAAEEEEAAAQQQQACB1AIkIKnp2BEBBBBAAAEEEEAAAQR8BUhAfMUojwACCCCAAAIIIIAAAqkFSEBS07EjAggggAACCCCAAAII+AqQgPiKUR4BBBBAAAEEEEAAAQRSC5CApKZjRwQQQAABBBBAAAEEEPAVIAHxFaM8AggggAACCCCAAAIIpBYgAUlNx44IIIAAAggggAACCCDgK0AC4itGeQQQQAABBBBAAAEEEEgtQAKSmo4dEUAAAQQQQAABBBBAwFeABMRXjPIIIIAAAggggAACCCCQWoAEJDUdOyKAAAIIIIAAAggggICvAAmIrxjlEUAAAQQQQAABBBBAILUACUhqOnZEAAEEEEAAAQQQQAABX4H/AzDptrZIT+T2AAAAAElFTkSuQmCC\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b05968cb9d0>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict(X_test)\n",
    "#pred = do_inverse_scaling(pred,Y_un,'std')\n",
    "sct = get_score(model, X_test, Y_test, Y_un, 'std')\n",
    "sctr = get_score(model, X_train, Y_train, Y_un, 'std')\n",
    "scv = get_score(model, X_val, Y_val, Y_un, 'std')\n",
    "scv2 = get_score(model, X_val2, Y_val2, Y_un, 'std')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(0.0,20)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=40,restore_best_weights=True)\n",
    "h = model.fit(X_train,Y_train,epochs=300,batch_size=512,validation_data=(X_val,Y_val),callbacks=[es],shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [50,100,150,200,250,350]\n",
    "scs = np.zeros((int(X_val.shape[0]/576),len(reg)))\n",
    "sctr = np.zeros((int(X_train.shape[0]/576),len(reg)))\n",
    "sct = np.zeros((int(X_test.shape[0]/576),len(reg)))\n",
    "for i, j in enumerate(reg):\n",
    "    print(i)\n",
    "    model = get_model_XGB(j)\n",
    "    model.fit(X_train,Y_train,eval_set=[(X_val,Y_val)],early_stopping_rounds=40,verbose=False)\n",
    "    \n",
    "    scs[:,i] = get_score(model, X_val, Y_val, Y_un, 'std')\n",
    "    sct[:,i] = get_score(model, X_test, Y_test, Y_un, 'std')\n",
    "    sctr[:,i] = get_score(model, X_train, Y_train, Y_un, 'std')\n",
    "    #if(np.mean(sct,axis=0)[i]<0.13):\n",
    "    #    model.save('models/Gij_0_1_S2.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"models/Gij_2_0_S1_XGB.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, Y, Y_un, which):\n",
    "    #pred = model.predict(X,ntree_limit=model.best_ntree_limit)\n",
    "    pred = model.predict(X)\n",
    "    pred = do_inverse_scaling(pred,Y_un,which)\n",
    "    Y    = do_inverse_scaling(Y,Y_un,which)\n",
    "    npts=576\n",
    "    sc = np.zeros(int(Y.shape[0]/npts))\n",
    "    for i in range(0,sc.shape[0]):\n",
    "        sc[i]=np.sqrt(mean_squared_error(Y[i*npts:(i+1)*npts],pred[i*npts:(i+1)*npts])/np.mean(Y[i*npts:(i+1)*npts]**2))\n",
    "        #sc[i]=r2_score(Y[i*576:(i+1)*576],pred[i*576:(i+1)*576])\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score2(model, X, Y, Y_un, which):\n",
    "    pred = model.predict(X)\n",
    "    pred = do_inverse_scaling(pred,Y_un,which)\n",
    "    Y    = do_inverse_scaling(Y,Y_un,which)\n",
    "    npts=576\n",
    "    err = np.abs((pred-Y)/Y)\n",
    "    sc = np.zeros(int(Y.shape[0]/npts))\n",
    "    for i in range(0,sc.shape[0]):\n",
    "        #sc[i]=np.sqrt(mean_squared_error(Y[i*npts:(i+1)*npts],pred[i*npts:(i+1)*npts])/np.mean(Y[i*npts:(i+1)*npts]**2))\n",
    "        #sc[i]=r2_score(Y[i*576:(i+1)*576],pred[i*576:(i+1)*576])\n",
    "        sc[i]=np.quantile(err[i*576+80:(i+1)*576-80],q=[0.9])\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = do_inverse_scaling(pred,Y_un,'median')\n",
    "sct = np.zeros(int(X_test.shape[0]/576))\n",
    "scs = np.zeros(int(X_val.shape[0]/576))\n",
    "sctr = np.zeros(int(X_train.shape[0]/576))\n",
    "\n",
    "Y_test = do_inverse_scaling(Y_test,Y_un,'median')\n",
    "for i in range(0,sct.shape[0]):\n",
    "    \n",
    "    #sct[i]=r2_score(Y_test[i*576:(i+1)*576],pred[i*576:(i+1)*576])\n",
    "    sct[i]=np.sqrt(mean_squared_error(Y_test[i*576:(i+1)*576],pred[i*576:(i+1)*576])/np.mean(Y_test[i*576:(i+1)*576]**2))\n",
    "    \n",
    "    \n",
    "pred = model.predict(X_train)\n",
    "pred = do_inverse_scaling(pred,Y_un,'median')\n",
    "Y_train = do_inverse_scaling(Y_train,Y_un,'median')\n",
    "\n",
    "for i in range(0,sctr.shape[0]):\n",
    "    #sctr[i]=r2_score(Y_train[i*576:(i+1)*576],pred[i*576:(i+1)*576])\n",
    "    sctr[i] = np.sqrt(mean_squared_error(Y_train[i*576:(i+1)*576],pred[i*576:(i+1)*576])/np.mean(Y_train[i*576:(i+1)*576]**2))\n",
    "\n",
    "    \n",
    "pred = model.predict(X_val)\n",
    "pred = do_inverse_scaling(pred,Y_un,'median')\n",
    "Y_val = do_inverse_scaling(Y_val,Y_un,'median')\n",
    "\n",
    "\n",
    "for i in range(0,scs.shape[0]):\n",
    "    #scs[i]=r2_score(Y_val[i*576:(i+1)*576],pred[i*576:(i+1)*576])    \n",
    "    scs[i] = np.sqrt(mean_squared_error(Y_val[i*576:(i+1)*576],pred[i*576:(i+1)*576])/np.mean(Y_val[i*576:(i+1)*576]**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model):\n",
    "    pred = model.predict(X_test)\n",
    "    sct = np.zeros(idxT.shape[0]-1)\n",
    "    scs = np.zeros(idxV.shape[0]-1)\n",
    "    sctr = np.zeros(idxTr.shape[0]-1)\n",
    "\n",
    "    for i in range(0,sct.shape[0]):\n",
    "        sct[i]=r2_score(Y_test[idxT[i]:idxT[i+1]],pred[idxT[i]:idxT[i+1]])\n",
    "        #sct[i]=np.sqrt(mean_squared_error(Y_test[idxT[i]:idxT[i+1]],pred[idxT[i]:idxT[i+1]])/np.mean(Y_test[idxT[i]:idxT[i+1]]**2))\n",
    "\n",
    "    pred = model.predict(X_train)\n",
    "    for i in range(0,sctr.shape[0]):\n",
    "        sctr[i]=r2_score(Y_train[idxTr[i]:idxTr[i+1]],pred[idxTr[i]:idxTr[i+1]])\n",
    "        #sctr[i]=np.sqrt(mean_squared_error(Y_train[idxTr[i]:idxTr[i+1]],pred[idxTr[i]:idxTr[i+1]])/np.mean(Y_train[idxTr[i]:idxTr[i+1]]**2))\n",
    "        \n",
    "    pred = model.predict(X_val)\n",
    "    for i in range(0,scs.shape[0]):\n",
    "        scs[i]=r2_score(Y_val[idxV[i]:idxV[i+1]],pred[idxV[i]:idxV[i+1]])\n",
    "        #scs[i]=np.sqrt(mean_squared_error(Yval[idxV[i]:idxV[i+1]],pred[idxV[i]:idxV[i+1]])/np.mean(Yval[idxV[i]:idxV[i+1]]**2))\n",
    "    return sctr, sct, scs, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ACCU_0_0_S1.h5')\n",
    "nfs = 16\n",
    "i1=0\n",
    "j1=0\n",
    "X_train, Y_train,_ = get_CNN_training('./data/CaseC_smooth/',0,60,60,nfs,i1,j1)\n",
    "X_test, Y_test,_ = get_CNN_training('./data/CaseC_smooth/',60,24,60,nfs,i1,j1)\n",
    "Xval, Yval, _ = get_CNN_training('./data/CaseC_smooth/',84,36,60,nfs,i1,j1)\n",
    "X_train, X_test, Xval, Y_train, Y_test, Yval = scale_data(X_train, X_test,  Xval, Y_train, Y_test,  Yval,'std')\n",
    "\n",
    "\n",
    "#X_train = np.reshape(X_train,(X_train.shape[0]*X_train.shape[1],nfs))\n",
    "#X_test = np.reshape(X_test,(X_test.shape[0]*X_test.shape[1],nfs))\n",
    "#Xval = np.reshape(Xval,(Xval.shape[0]*Xval.shape[1],nfs))\n",
    "#Y_train = np.reshape(Y_train,(Y_train.shape[0]*Y_train.shape[1]))\n",
    "#Y_test = np.reshape(Y_test,(Y_test.shape[0]*Y_test.shape[1]))\n",
    "#Yval = np.reshape(Yval,(Yval.shape[0]*Yval.shape[1]))\n",
    "Xval[:,15]=1\n",
    "a1u1 = model.predict(Xval)\n",
    "\n",
    "X_train, Y_train,_ = get_CNN_training('./data/CaseC_smooth/',0,60,60,nfs,i1,j1)\n",
    "Xval, Yval,_ = get_CNN_training('./data/CaseC_smooth/',84,36,60,nfs,i1,j1)\n",
    "\n",
    "a1u1 = a1u1*np.mean(Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_au():\n",
    "    out = np.zeros((20736,3,3))\n",
    "    nfs = 16\n",
    "    \n",
    "    for i in range(0,1):\n",
    "        for j in range(0,2):\n",
    "            print(i,j)\n",
    "            model = load_model('ACCU_'+str(i)+'_'+str(j)+'_S1.h5')\n",
    "            X_train, Y_train,_ = get_CNN_training('./data/CaseC_smooth/',0,60,60,nfs,i,j)\n",
    "            X_test, Y_test,_ = get_CNN_training('./data/CaseC_smooth/',60,24,60,nfs,i,j)\n",
    "            Xval, Yval,_ = get_CNN_training('./data/CaseC_smooth/',84,36,60,nfs,i,j)\n",
    "            meanY = np.mean(Y_train)\n",
    "            minY = np.min(Y_train)\n",
    "            maxY = np.max(Y_train)\n",
    "            \n",
    "            X_train, _, Xval, Y_train, _, Yval = scale_data(X_train, X_test,  Xval, Y_train, Y_test,  Yval,'std')\n",
    "            #X_train = np.reshape(X_train,(X_train.shape[0]*X_train.shape[1],nfs))\n",
    "            #Xval = np.reshape(Xval,(Xval.shape[0]*Xval.shape[1],nfs))\n",
    "            Xval[:,15]=1\n",
    "            out[:,i,j] = np.squeeze(model.predict(Xval))\n",
    "            out[:,i,j] = out[:,i,j]*meanY\n",
    "            #out[:,i,j] = out[:,i,j]*(maxY-minY) + minY\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G_L(direc,ist,nt, delU,nfs):\n",
    "    \n",
    "    Gij, _, _, _, _, _, Lij, _, _, _, _, _, _ = get_training_data_time(direc,ist,False,False,delU)\n",
    "    G = np.zeros(((nt)*576,3,3))\n",
    "    L = np.zeros(((nt)*576,3,3))\n",
    "    \n",
    "    G[0:576,:,:] = np.moveaxis(Gij[:,:,:],-1,0)\n",
    "    L[0:576,:,:] = np.moveaxis(Lij[:,:,:],-1,0)\n",
    "    \n",
    "    for i in range(ist+1,ist+nt):\n",
    "        Gij, _, _, _, _, _, Lij, _, _, _, _, _, _ = get_training_data_time(direc,i,False,False,delU)\n",
    "        G[(i-ist)*576:(i-ist+1)*576,:,:] = np.moveaxis(Gij,-1,0)\n",
    "        L[(i-ist)*576:(i-ist+1)*576,:,:] = np.moveaxis(Lij,-1,0)\n",
    "    return G,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gij, Lij = get_G_L('./data/CaseC_smooth/',84,36,60,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = np.zeros((36,3,3))\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        for k in range(0,36):\n",
    "            \n",
    "            scs[k,i,j] = r2_score(outD[k*576:(k+1)*576,i,j],out[k*576:(k+1)*576,i,j])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIUJ = get_au()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((Gij.shape[0],3,3))\n",
    "outD = np.zeros((Gij.shape[0],3,3))\n",
    "\n",
    "for i in range(out.shape[0]):\n",
    "    out[i,:,:] = np.matmul(AIUJ[i,:,:],Lij[i,:,:])\n",
    "    outD[i,:,:] = np.matmul(Gij[i,:,:],Lij[i,:,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Lij[0:576,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Gij[:,0,1],AIUJ[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot(Gij[0:576,0,0]*Lij[0:576,0,0]+Gij[0:576,0,1]*Lij[0:576,1,0]+Gij[0:576,0,2]*Lij[0:576,2,0])\n",
    "#plt.plot(AIUJ[0:576,0,0]*Lij[0:576,0,0]+AIUJ[0:576,0,1]*Lij[0:576,1,0]+AIUJ[0:576,0,2]*Lij[0:576,2,0])\n",
    "\n",
    "#plt.plot(Gij[0:576,0,0]*Lij[0:576,0,0]+Gij[0:576,0,1]*Lij[0:576,1,0])\n",
    "#plt.plot(AIUJ[0:576,0,0]*Lij[0:576,0,0]+AIUJ[0:576,0,1]*Lij[0:576,1,0])\n",
    "\n",
    "plt.plot(Gij[0:576,0,0]*Lij[0:576,0,0])\n",
    "plt.plot(AIUJ[0:576,0,0]*Lij[0:576,0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gij[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Gij[136:439,0,0]*Lij[136:439,0,0])\n",
    "plt.plot(AIUJ[136:439,0,0]*Lij[136:439,0,0])\n",
    "#plt.plot(Gij[0:576,0,1]*Lij[0:576,1,0])\n",
    "#plt.plot(AIUJ[0:576,0,1]*Lij[0:576,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(Gij[0:576,0,0]*Lij[0:576,0,0]+Gij[0:576,0,1]*Lij[0:576,1,0],Gij[0:576,0,0]*Lij[0:576,0,0]+AIUJ[0:576,0,1]*Lij[0:576,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Gij[0:576,0,1]*Lij[0:576,1,0] + Gij[0:576,0,0]*Lij[0:576,0,0] \n",
    "s2 = AIUJ[0:576,0,1]*Lij[0:576,1,0] + AIUJ[0:576,0,0]*Lij[0:576,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(s1[200:350],s2[200:350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lij[0:103,0,0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot((Gij[0:576,0,0]*Lij[0:576,0,0]-AIUJ[0:576,0,0]*Lij[0:576,0,0])/(Gij[0:576,0,0]*Lij[0:576,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(s1,s2)/np.mean(s1**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(outD[0:576,0,0])\n",
    "plt.plot(out[0:576,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_CNN_training('./data/CaseC/',0,60,60,nfs,i1,j1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot((a1u1[0:576,0]*np.std(Y_train)+np.mean(Y_train))*Xval[0:576,0])\n",
    "plt.plot((Yval[0:576]*np.std(Y_train)+np.mean(Y_train))*Xval[0:576,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval, Yval = get_CNN_training('./data/CaseC/',84,36,60,nfs,0,0)\n",
    "Xval = np.reshape(Xval,(Xval.shape[0]*Xval.shape[1],nfs))\n",
    "Yval = np.reshape(Yval,(Yval.shape[0]*Yval.shape[1]))\n",
    "\n",
    "T11 = np.copy(Xval[:,0])\n",
    "T21 = np.copy(Xval[:,1])\n",
    "T31 = np.copy(Xval[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval, a1u12 = get_CNN_training('./data/CaseC/',84,36,60,nfs,0,0)\n",
    "Xval, a1u22 = get_CNN_training('./data/CaseC/',84,36,60,nfs,0,1)\n",
    "Xval, a1u32 = get_CNN_training('./data/CaseC/',84,36,60,nfs,0,2)\n",
    "a1u12 = np.reshape(a1u12,(a1u12.shape[0]*a1u12.shape[1]))\n",
    "a1u22 = np.reshape(a1u22,(a1u22.shape[0]*a1u22.shape[1]))\n",
    "a1u32 = np.reshape(a1u32,(a1u32.shape[0]*a1u32.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = a1u1*T11[:,None] + a1u2*T21[:,None] + a1u3*T31[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = a1u32*T31 + a1u22*T21 + a1u12*T11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = 19\n",
    "i1=1\n",
    "j1=2\n",
    "X, Y, _ = get_CNN_training('./data/50_new/',0,150,1,100,nfs,i1,j1)\n",
    "#nT = [i for i in range(0,int(X.shape[0]/576))]\n",
    "#np.random.shuffle(nT)\n",
    "\n",
    "X_train = np.zeros((576*75,nfs))\n",
    "Y_train = np.zeros((576*75,1))\n",
    "X_test = np.zeros((576*45,nfs))\n",
    "Y_test = np.zeros((576*45,1))\n",
    "X_val = np.zeros((576*30,nfs))\n",
    "Y_val = np.zeros((576*30,1))\n",
    "\n",
    "\n",
    "for i in range(0,75):\n",
    "    X_train[i*576:(i+1)*576,:] = X[nT[i]*576:(nT[i]+1)*576,:]\n",
    "    Y_train[i*576:(i+1)*576,:] = Y[nT[i]*576:(nT[i]+1)*576,None]\n",
    "j=0\n",
    "for i in range(75,105):\n",
    "    X_val[j*576:(j+1)*576,:] = X[nT[i]*576:(nT[i]+1)*576,:]\n",
    "    Y_val[j*576:(j+1)*576,:] = Y[nT[i]*576:(nT[i]+1)*576,None]\n",
    "    j=j+1\n",
    "j=0\n",
    "for i in range(105,150):\n",
    "    X_test[j*576:(j+1)*576,:] = X[nT[i]*576:(nT[i]+1)*576,:]\n",
    "    Y_test[j*576:(j+1)*576,:] = Y[nT[i]*576:(nT[i]+1)*576,None]\n",
    "    j=j+1\n",
    "\n",
    "X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = np.zeros((X_test.shape[0],3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/ACCU_0_2_S2.h5')\n",
    "accu[:,0,2] = model.predict(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gij():\n",
    "    #nT = np.loadtxt('NT')\n",
    "    #nT=nT.astype(int)\n",
    "    nfs = 23\n",
    "    DNS = np.zeros((576*16,3,3))\n",
    "    PRED = np.zeros((576*16,3,3))\n",
    "    for i1 in range(0,2):\n",
    "        for j1 in range(0,3):\n",
    "            print(i1,j1)\n",
    "            #X, Y, _ = get_CNN_training('./data/CaseF_scaled/',0,80,2,100,nfs,i1,j1)\n",
    "            #nfs=20\n",
    "            #npts=576\n",
    "            #X_train = np.zeros((npts*30,nfs))\n",
    "            #Y_train = np.zeros((npts*30,1))\n",
    "\n",
    "            #X_val = np.zeros((npts*10,nfs))\n",
    "            #Y_val = np.zeros((npts*10,1))\n",
    "\n",
    "\n",
    "            #for i in range(0,30):\n",
    "            #    X_train[i*npts:(i+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "            #    Y_train[i*npts:(i+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "            #j=0\n",
    "            #for i in range(30,40):\n",
    "            #    X_val[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "            #    Y_val[j*npts:(j+1)*npts,:] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "            #j=j+1\n",
    "            #nfs=23\n",
    "            \n",
    "            X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un = get_data(i1,j1)\n",
    "\n",
    "\n",
    "            \n",
    "            #X_test, Y_test, _ = get_CNN_training('./data/50_new_scaled/',0,80,5,150,nfs,i1,j1)\n",
    "            #X_test, Y_test, _ = get_CNN_training('./data/CaseF/',80,20,2,150,nfs,i1,j1)\n",
    "\n",
    "    \n",
    "            #meanY = np.mean(Y_train)\n",
    "            #stdY = np.std(Y_train)\n",
    "            DNS[:,i1,j1] = Y_test[:,0]           \n",
    "\n",
    "            #X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "            model = load_model('models/Gij_'+str(i1)+'_'+str(j1)+'_S2_test.h5')\n",
    "            #model=pickle.load(open(\"models/Gij_\"+str(i1)+\"_\"+str(j1)+\"_S2_XGB.dat\", \"rb\"))\n",
    "            \n",
    "            PRED[:,i1,j1] = model.predict(X_test)[:,0]\n",
    "            PRED[:,i1,j1] = do_inverse_scaling(PRED[:,i1,j1],Y_un,'std')\n",
    "            DNS[:,i1,j1] = do_inverse_scaling(DNS[:,i1,j1],Y_un,'std')\n",
    "   \n",
    "    return PRED, DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_S2_ANN, _ = get_Gij()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.figure(figsize=(14,10))\n",
    "    k=8\n",
    "    x = np.linspace(0,0.423e-2,576)\n",
    "    x=x-0.423e-2/2\n",
    "    x=x*100\n",
    "    for i in range(0,3):\n",
    "      for j in range(0,3):\n",
    "        plt.subplot(3,3,i*3+j+1) \n",
    "        \n",
    "        #plt.plot(x,(DNS[k*576:(k+1)*576,i,j]-min(DNS[k*576:(k+1)*576,i,j]))/(max((DNS[k*576:(k+1)*576,i,j]))-min(DNS[k*576:(k+1)*576,i,j])),'--x',linewidth=2,markevery=12,markeredgewidth=1,markersize=8)\n",
    "        #plt.plot(x,(PRED[k*576:(k+1)*576,i,j]-min(DNS[k*576:(k+1)*576,i,j]))/(max((DNS[k*576:(k+1)*576,i,j]))-min(DNS[k*576:(k+1)*576,i,j])),linewidth=2)\n",
    "        #plt.plot(x,(PRED_XGB[k*576:(k+1)*576,i,j]-min(DNS[k*576:(k+1)*576,i,j]))/(max((DNS[k*576:(k+1)*576,i,j]))-min(DNS[k*576:(k+1)*576,i,j])),linewidth=2)\n",
    "\n",
    "        #plt.plot(MERRS[:,i,j]*100,linewidth=2)\n",
    "        plt.plot(x,RSS_DNS[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),'-x',linewidth=1,markevery=10,markeredgewidth=1,markersize=6)\n",
    "        plt.plot(x,RSS_ANN[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=1.5)\n",
    "        plt.plot(x,RSS_XGB[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=1.5)\n",
    "        \n",
    "        #plt.plot(x,(PRED[k*576:(k+1)*576,i,j]+PRED[k*576:(k+1)*576,j,i])/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=1.5)\n",
    "        \n",
    "        #plt.plot(x,RSS_LIPM[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=1.5)\n",
    "        #plt.plot(x,RSS_LSSG[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=1.5)\n",
    "        #plt.plot(x,RSS_SLM[k*576:(k+1)*576,i,j]/max(abs(RSS_DNS[k*576:(k+1)*576,i,j])),linewidth=1.5)\n",
    "        \n",
    "        plt.locator_params(axis='y', nbins=3)\n",
    "        plt.locator_params(axis='x', nbins=3)\n",
    "        #plt.title(str(i+1)+','+str(j+1))\n",
    "        \n",
    "        #plt.gca().get_yaxis().set_major_formatter(ticker.FormatStrFormatter('%0.0e'))\n",
    "        #plt.gca().get_xaxis().set_major_formatter(ticker.FormatStrFormatter('%0.0e'))\n",
    "        #plt.grid(alpha=0.5)\n",
    "        if(i==0 and j==0):\n",
    "            plt.legend(('DNS','ANN','XGB','LSSG','SLM'))\n",
    "        #if(i==1 and j==1):\n",
    "            #plt.ylim((\\))\n",
    "            #plt.yticks([-0.5, 0, 0.5])\n",
    "        #plt.ylim((-0.1,1.1))\n",
    "        plt.subplots_adjust(wspace=0.05)\n",
    "        plt.subplots_adjust(hspace=0.05)\n",
    "        plt.xlabel('$Y (cm)$')\n",
    "\n",
    "        if(i<2):\n",
    "        #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            #plt.gca().axes.get_xaxis().set_visible(False)\n",
    "            plt.xticks([-0.2,0.0,0.2],\"\")\n",
    "            plt.xlabel(\"\")\n",
    "        if(j>0):\n",
    "            #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            plt.yticks([0,0.5,1],\"\")\n",
    "        plt.grid(alpha=0.5)\n",
    "        #x = np.linspace(min(Gij[i,j,:]*eps/K),max(Gij[i,j,:]*eps/K),10)        \n",
    "        ax=plt.gca()\n",
    "        plt.text(0.1,0.9,str(i+1)+','+str(j+1),transform=ax.transAxes,bbox=dict(facecolor='white',alpha=0.5),size=15)\n",
    "        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + \n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "            item.set_fontsize(15)\n",
    "        #plt.plot(x,x,'k--')\n",
    "    #plt.savefig('Gij-ANN-XGB-S2.png',dpi=300,bbox_inches = \"tight\")     \n",
    "    #plt.close()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(DNS[i*576:(i+1)*576,1,2],PRED[i*576:(i+1)*576,1,2])/np.mean(DNS[i*576:(i+1)*576,1,2]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i=10\n",
    "plt.plot(DNS[i*576:(i+1)*576,1,2])\n",
    "plt.plot(PRED[i*576:(i+1)*576,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,45):\n",
    "    MERRS[i,0,0] = np.mean(e3[i*576:(i+1)*576])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERRS = np.zeros((45,3,3))\n",
    "STDERRS = np.zeros((45,3,3))\n",
    "for i in range(0,45):\n",
    "    A=np.sqrt(np.sum((DNS[i*576:(i+1)*576,:,:]-PRED[i*576:(i+1)*576,:,:])**2,axis=(1,2)))/np.sqrt(np.sum((DNS[i*576:(i+1)*576,:,:])**2,axis=(1,2)))\n",
    "    A = np.sort(A)\n",
    "    MERRS[i,0,0] = np.mean(A[0:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERRS2 = np.zeros((10,3,3))\n",
    "STDERRS = np.zeros((10,3,3))\n",
    "for i in range(0,10):\n",
    "    for j in range(0,3):\n",
    "        for k in range(0,3):\n",
    "            \n",
    "            MERRS2[i,j,k] = np.sqrt(mean_squared_error(DNS[i*576:(i+1)*576,j,k],PRED[i*576:(i+1)*576,j,k])/np.mean(DNS[i*576:(i+1)*576,j,k]**2))\n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERRS_XGB_S1 = MERRS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(MERRS2[:,1,0])\n",
    "#plt.plot(MERRS[:,2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i=20\n",
    "plt.plot(PRED[i*576:(i+1)*576,1,0])\n",
    "plt.plot(DNS[i*576:(i+1)*576,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EANNS2 = np.zeros(16)\n",
    "EXGBS2 = np.zeros(16)\n",
    "\n",
    "for  i in range(0,16):\n",
    "    EANNS2[i] = np.mean(E_ANN_S2[i*576:(i+1)*576])\n",
    "    EXGBS2[i] = np.mean(E_XGB_S2[i*576:(i+1)*576])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "np.random.shuffle(MERRS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(EANNS1[0:10],'-x',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "plt.plot(EXGBS1[0:10],'-x',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "plt.plot(EANNS2[0:10],'-o',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "plt.plot(EXGBS2[0:10],'-o',linewidth=4,markersize=10,markeredgewidth=2)\n",
    "\n",
    "#plt.ylim(0,0.4)\n",
    "plt.ylabel('$\\epsilon_T$')\n",
    "plt.xlabel('Sample')\n",
    "plt.grid(alpha=0.2)\n",
    "ax=plt.gca()\n",
    "plt.yticks([0, 0.10,0.20])\n",
    "#plt.legend(('$\\epsilon_{3,1}$','$\\epsilon_{3,2}$','$\\epsilon_{3,3}$'),prop={'size': 18})\n",
    "plt.legend(('$\\epsilon$-ANN-$\\mathcal{S}$1','$\\epsilon$-XGB-$\\mathcal{S}$1','$\\epsilon$-ANN-$\\mathcal{S}$2','$\\epsilon$-XGB-$\\mathcal{S}$2'),prop={'size': 16})\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + \n",
    "            ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(20)\n",
    "plt.savefig('eps-S1.png',dpi=300,bbox_inches = \"tight\")     \n",
    "    #plt.close()\n",
    "#plt.plot(MERRS[:,2,2]*100,'-x')\n",
    "#plt.plot(m*100,'-x')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i=13\n",
    "j=0\n",
    "k=0\n",
    "#plt.plot(err[i*576:(i+1)*576,j,k]/DNS[i*576:(i+1)*576,j,k],'o')\n",
    "plt.plot(DNS[i*576:(i+1)*576,j,k],'o')\n",
    "plt.plot(PRED2[i*576:(i+1)*576,j,k])\n",
    "plt.plot(PRED[i*576:(i+1)*576,j,k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_RSS(direc,ist,nt,stp, delU):\n",
    "            _, Tij, meanVelGrad, b, Sij, _, Lij, eps, K, _, _, _, _ = get_training_data_time(direc,ist,False,False,delU)\n",
    "            for i in range(ist+stp,ist+nt,stp):\n",
    "                _, Tij1, meanVelGrad1, b1, Sij1, _, Lij1, eps1, K1, _, _, _, _ = get_training_data_time(direc,i,False,False,delU)\n",
    "                Tij = np.append(Tij, Tij1, axis=2)\n",
    "                b = np.append(b, b1, axis=2)                \n",
    "                meanVelGrad = np.append(meanVelGrad,meanVelGrad1,axis=2)\n",
    "                Sij = np.append(Sij,Sij1,axis=2)\n",
    "                Lij = np.append(Lij,Lij1,axis=2)\n",
    "                eps = np.append(eps,eps1,axis=0)\n",
    "                K = np.append(K,K1,axis=0)\n",
    "            \n",
    "                \n",
    "            return Tij, b, meanVelGrad, Sij, Lij, eps, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RSM(Gij,Tij):\n",
    "    RSM = np.zeros((Gij.shape[0],3,3))\n",
    "    #Gij = np.reshape(Gij,(Gij.shape[0],3,3))\n",
    "    #Tij = np.reshape(Tij,(Tij.shape[0],3,3))\n",
    "    for i in range(0,3):\n",
    "        for j in range(0,3):\n",
    "            for k in range(0,3):\n",
    "                RSM[:,i,j]=RSM[:,i,j]+Gij[:,i,k]*Tij[:,k,j]+Gij[:,j,k]*Tij[:,k,i]\n",
    "    return RSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIPM_model(C0,CIPM,alpha2,alpha3,beta1,beta2,beta3,gama5,gama6,b,Tij,meanVelGrad,eps,K,lambdaij,Sij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "    for i in range(0,K.shape[0]):        \n",
    "        #P = - 0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) + np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))\n",
    "        #To be used when normalised by eps/K \n",
    "        P1 = b[:,:,i]*Sij[:,:,i]\n",
    "        P = -2.0*P1.sum()*K[i]\n",
    "        B3 = np.matmul(np.matmul(b[:,:,i],b[:,:,i]),b[:,:,i])\n",
    "        \n",
    "        alpha1 = -(0.5+3.0/4*C0)+3.0*alpha2*np.trace(B3)+0.5*CIPM*P/eps[i] #P is non dim so no omega here\n",
    "        \n",
    "        pred[:,:,i] = (alpha1*np.eye(3,3)+alpha2*b[:,:,i] + alpha3*np.matmul(b[:,:,i],b[:,:,i]))*eps[i]/K[i] + beta1*np.eye(3,3)*np.trace(meanVelGrad[:,:,i]) + \\\n",
    "        beta2*meanVelGrad[:,:,i] + beta3*np.transpose(meanVelGrad[:,:,i]) + gama5*np.matmul(b[:,:,i],meanVelGrad[:,:,i]) + \\\n",
    "        gama6*np.matmul(b[:,:,i],np.transpose(meanVelGrad[:,:,i]))\n",
    "     \n",
    "        pred[:,:,i] = pred[:,:,i]+0.5*C0*eps[i]*lambdaij[:,:,i]\n",
    "       \n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSSG_model(C0,C2SSG,C3SSG,C3SSGp,C3starSSG,C5SSG,b,Tij,meanVelGrad,eps,K,lambdaij,Sij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "    # To be used when normalised with delta and delU\n",
    "    for i in range(0,K.shape[0]):        \n",
    "        P = - 0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) + np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))\n",
    "        B3 = np.matmul(np.matmul(b[:,:,i],b[:,:,i]),b[:,:,i])\n",
    "        alpha2 = 4.0-1.7*P/eps[i]\n",
    "        alpha1 = -(0.5+3.0/4*C0)-1.0/4*C2SSG*np.trace(np.matmul(b[:,:,i],b[:,:,i])) + \\\n",
    "        (3.0*alpha2-3.0/4*C2SSG)*np.trace(B3) + 3.0/8*(C3SSG-C3starSSG*np.sqrt(np.trace(np.matmul(b[:,:,i],b[:,:,i]))))*P/eps[i] \n",
    "        alpha3 = 3.0/4*C2SSG-3.0*alpha2\n",
    "        beta1 = -0.2\n",
    "        beta2 = 3.0/8*(C3SSG-C3SSGp*np.sqrt(np.trace(np.matmul(b[:,:,i],b[:,:,i]))))+0.5\n",
    "        beta3 = 3.0/8*(C3SSG-C3SSGp*np.sqrt(np.trace(np.matmul(b[:,:,i],b[:,:,i]))))-0.5\n",
    "        gama5 = 3.0/2-3.0/4*C5SSG\n",
    "        gama6 = -3.0/2+3.0/4*C5SSG\n",
    "        \n",
    "        pred[:,:,i] = (alpha1*np.eye(3,3)+alpha2*b[:,:,i] + alpha3*np.matmul(b[:,:,i],b[:,:,i]))*eps[i]/K[i] + beta1*np.eye(3,3)*np.trace(meanVelGrad[:,:,i]) + \\\n",
    "        beta2*meanVelGrad[:,:,i] + beta3*np.transpose(meanVelGrad[:,:,i]) + gama5*np.matmul(b[:,:,i],meanVelGrad[:,:,i]) + \\\n",
    "        gama6*np.matmul(b[:,:,i],np.transpose(meanVelGrad[:,:,i]))\n",
    "        \n",
    "        \n",
    "        pred[:,:,i] = pred[:,:,i]+0.5*C0*eps[i]*lambdaij[:,:,i]\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SLM(C0,eps,K,Lij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "\n",
    "    for i in range(0,K.shape[0]):\n",
    "        pred[:,:,i] = -(0.5+3.0/4*C0)*np.eye(3,3)*eps[i]/K[i] + 0.5*C0*eps[i]*Lij[:,:,i]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tij, b, meanVelGrad, Sij, Lij, eps, K = get_data_RSS('./data/50_new/',15,80,5,100)\n",
    "LIPM  = LIPM_model(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b,Tij,meanVelGrad,eps,K,Lij,Sij)\n",
    "LSSG = LSSG_model(2.1,4.2,0.8,1.0,1.0,0.4,b,Tij,meanVelGrad,eps,K,Lij,Sij)\n",
    "\n",
    "SLM = get_SLM(2.1,eps,K,Lij)\n",
    "#LIPM  = np.zeros((576*45,3,3))\n",
    "#LSSG  = np.zeros((576*45,3,3))\n",
    "#SLM  = np.zeros((576*45,3,3))\n",
    "\n",
    "#Tij = np.zeros((576*45,3,3))\n",
    "#j=0\n",
    "#for k in range(10,150):\n",
    "LIPM = np.moveaxis(LIPM,2,0)\n",
    "LSSG = np.moveaxis(LSSG,2,0)\n",
    "SLM  = np.moveaxis(SLM,2,0)\n",
    "Tij  = np.moveaxis(Tij,2,0)\n",
    "#    j=j+1\n",
    "\n",
    "RSS_LIPM = get_RSM(LIPM,Tij)\n",
    "RSS_LSSG = get_RSM(LSSG,Tij)\n",
    "RSS_DNS = get_RSM(DNS_S2,Tij)\n",
    "RSS_XGB = get_RSM(PRED_S2_XGB,Tij)\n",
    "RSS_ANN = get_RSM(PRED_S2_ANN,Tij)\n",
    "\n",
    "RSS_SLM = get_RSM(SLM,Tij)\n",
    "#LIPM = LIPM_model(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b2,Tij2,meanVelGrad2,eps2,K2,Lij2,Sij2)\n",
    "#LSSG = LSSG_model(2.1,4.2,0.8,1.0,1.0,0.4,b,Tij,meanVelGrad,eps,K,Lij,Sij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i=1\n",
    "#plt.plot(RSS_LIPM[i*576:(i+1)*576,0,0])\n",
    "#plt.plot(RSS_DNS[i*576:(i+1)*576,0,0])\n",
    "#plt.plot(RSS_ANN[i*576:(i+1)*576,0,0])\n",
    "#plt.plot(RSS_SLM[i*576:(i+1)*576,0,0])\n",
    "plt.plot(Gij_ANN2[i*576:(i+1)*576,0,0])\n",
    "plt.plot(DNS[i*576:(i+1)*576,0,0])\n",
    "\n",
    "\n",
    "#plt.plot(LIPM[20*576:(20+1)*576,0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2 = np.zeros((476*16,3,3))\n",
    "for i in range(0,16):\n",
    "    err[i*476:(i+1)*476] = err[i*576+50:(i+1)*576-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.boxplot(err[:,2,1],showfliers=False,whis=[5, 80],meanline=True,showmeans=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
