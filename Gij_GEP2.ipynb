{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import time\n",
    "os.environ[\"PATH\"] += \"/group/w47/ddalakoti/jupyter-dir/geppy\"\n",
    "import geppy as gep\n",
    "import operator\n",
    "#from deap import tools, creator, base \n",
    "import random\n",
    "import sympy as sp\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Lasso, SGDRegressor\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, GaussianNoise\n",
    "from keras.losses import logcosh\n",
    "from sklearn.svm import SVR\n",
    "import glob\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "#from numpy import exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(loc,d,delU):\n",
    "    Gij = np.loadtxt(loc+'/Gij_'+d+'.dat')\n",
    "    Tij = np.loadtxt(loc+'/Tij_'+d+'.dat')\n",
    "    K   = np.loadtxt(loc+'/k-eps_'+d+'.dat')    \n",
    "    meanVelGrad = np.loadtxt(loc+'/mean_vel_grad_'+d+'.dat')\n",
    "    Lij = np.loadtxt(loc+'/lambda_'+d+'.dat')\n",
    "    Reyn = np.loadtxt(loc+'/Reyn_'+d+'.dat')\n",
    "    rho = np.loadtxt(loc+'/rho_'+d+'.dat')\n",
    "    mv = np.loadtxt(loc+'/mean_vel_'+d+'.dat')\n",
    "    \n",
    "    #mvgg = np.loadtxt(loc+'/mvgg_'+d+'.dat')\n",
    "    \n",
    "    idel = [3, 6, 7, 12, 15, 16, 21, 24, 25]\n",
    "    \n",
    "    #mvgg = np.delete(mvgg,idel,axis=1)\n",
    "    delta = np.ones(Reyn.shape[0])*np.sum(rho*(delU/2-mv[:,0])*(delU/2+mv[:,0]))*7.34e-6/(0.68*delU**2)\n",
    "    #delta = np.ones(Reyn.shape[0])*100/np.max(meanVelGrad[:,1])\n",
    "    x = np.linspace(0,0.0423,576)\n",
    "    x = x-0.0423/2.0\n",
    "    eps = np.copy(K[:,1])\n",
    "    K   = K[:,0]\n",
    "    index = np.where(K>0.05*np.max(K))\n",
    "    t_time = np.zeros(576)\n",
    "    t_time[:] = int(d)*3.38e-7\n",
    "    \n",
    "    loend = index[0][0]\n",
    "    hiend = index[0][-1]\n",
    "    #loend = 100\n",
    "    #hiend = 476\n",
    "    #Gij = Gij[loend:hiend,:]\n",
    "    #Tij = Tij[loend:hiend,:]\n",
    "    #meanVelGrad = meanVelGrad[loend:hiend,:]\n",
    "    #eps = eps[loend:hiend]\n",
    "    #K = K[loend:hiend] \n",
    "    #Lij = Lij[loend:hiend]\n",
    "    #Reyn = Reyn[loend:hiend]\n",
    "    #delta = delta[loend:hiend]\n",
    "    #x = x[loend:hiend]/delta\n",
    "    #t_time = t_time[loend:hiend]\n",
    "        \n",
    "    \n",
    "    return Gij, Tij, meanVelGrad, eps, K, Lij, Reyn, delta,x,t_time\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time,mvgg):\n",
    "        # basis for CNN just, Tij and meanVelGrad\\n\",\n",
    "        basis_vect = np.zeros((b.shape[0],3,3,51))\n",
    "        C = np.transpose(meanVelGrad,(0,2,1))\n",
    "\n",
    "        basis_vect[:,:,:,0] = b\n",
    "        basis_vect[:,:,:,1] = meanVelGrad\n",
    "        basis_vect[:,:,:,2] = C\n",
    "        basis_vect[:,:,:,3] = Lij\n",
    "        basis_vect[:,:,:,4] = np.matmul(meanVelGrad,Lij)\n",
    "        basis_vect[:,:,:,5] = np.matmul(Lij,meanVelGrad)\n",
    "        \n",
    "        basis_vect[:,:,:,6] = np.matmul(C,Lij)\n",
    "        basis_vect[:,:,:,7] = np.matmul(Lij,C)\n",
    "        \n",
    "        basis_vect[:,:,:,8] = np.matmul(C,b)\n",
    "        basis_vect[:,:,:,9] = np.matmul(b,C)\n",
    "        basis_vect[:,:,:,10] = np.matmul(b,Lij)\n",
    "        \n",
    "        \n",
    "        \n",
    "        basis_vect[:,:,:,11] = np.matmul(meanVelGrad,b)\n",
    "        basis_vect[:,:,:,12] = np.matmul(b,meanVelGrad)\n",
    "        \n",
    "        \n",
    "        \n",
    "        basis_vect[:,:,:,13] = K[:,None,None]\n",
    "        basis_vect[:,:,:,14] = eps[:,None,None]\n",
    "        basis_vect[:,:,:,15] = Reyn[:,None,None]\n",
    "        basis_vect[:,:,:,16] = np.trace(np.matmul(b,b),axis1=1,axis2=2)[:,None,None]\n",
    "        \n",
    "        basis_vect[:,:,:,17] = np.trace(C,axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,18] = np.trace(np.matmul(C,C),axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,19] = np.trace(Lij,axis1=1,axis2=2)[:,None,None]\n",
    "        \n",
    "        basis_vect[:,:,:,20] = np.trace(np.matmul(meanVelGrad,b),axis1=1,axis2=2)[:,None,None]\n",
    "    \n",
    "        basis_vect[:,:,:,21] = np.trace(np.matmul(b,Lij),axis1=1,axis2=2)[:,None,None]\n",
    "        basis_vect[:,:,:,22] = np.trace(np.matmul(meanVelGrad,Lij),axis1=1,axis2=2)[:,None,None]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return basis_vect       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_time(dir_loc,time,normalise=False,normalise_const=True,delU=100):\n",
    "\n",
    "    files = glob.glob(dir_loc+'accu*.dat')\n",
    "    indexes = [F[-7:-4] for F in files]        \n",
    "    loindices = np.zeros(len(indexes)+1)\n",
    "    Gij, Tij , meanVelGrad , eps, K, Lij, Reyn, delta, x, t_time = read_data(dir_loc,indexes[time],delU)\n",
    "    loindices[1] = K.shape[0]\n",
    "    \n",
    "    b = np.copy(Tij)\n",
    "    b[:,0] = b[:,0]-2.0*K/3.0\n",
    "    b[:,4] = b[:,4]-2.0*K/3.0\n",
    "    b[:,8] = b[:,8]-2.0*K/3.0\n",
    "    Gij = np.reshape(Gij,(Gij.shape[0],3,3))\n",
    "    Tij = np.reshape(Tij,(Tij.shape[0],3,3))\n",
    "    meanVelGrad = np.reshape(meanVelGrad,(meanVelGrad.shape[0],3,3))\n",
    "    b = np.reshape(b,(b.shape[0],3,3))\n",
    "    Lij = np.reshape(Lij,(Lij.shape[0],3,3))\n",
    "\n",
    "    Sij = np.zeros((b.shape[0],3,3))\n",
    "    omega = np.zeros((b.shape[0],3,3))\n",
    "    \n",
    "    for i in range(Sij.shape[0]):\n",
    "        Sij[i,:,:] = 0.5*(meanVelGrad[i,:,:]+np.transpose(meanVelGrad[i,:,:]))\n",
    "        omega[i,:,:] = 0.5*(meanVelGrad[i,:,:]-np.transpose(meanVelGrad[i,:,:]))\n",
    "        \n",
    "    b = b/(2.0*K[:,None,None])\n",
    "    if(normalise):    \n",
    "        Gij = Gij*K[:,None,None]/eps[:,None,None]\n",
    "        #Gij = Gij/(eps[:,None,None])\n",
    "        \n",
    "        Tij = Tij/K[:,None,None]\n",
    "        meanVelGrad = meanVelGrad*K[:,None,None]/eps[:,None,None]\n",
    "        Sij = Sij*K[:,None,None]/eps[:,None,None]\n",
    "        omega = omega*K[:,None,None]/eps[:,None,None]\n",
    "        Lij = Lij*K[:,None,None]\n",
    "    \n",
    "    if(normalise_const):\n",
    "        \n",
    "        Gij = Gij*delta[:,None,None]/delU\n",
    "        #Gij = Gij*delta[:,None,None]/delU**3        \n",
    "        Tij = Tij/delU**2\n",
    "        meanVelGrad = meanVelGrad*delta[:,None,None]/delU\n",
    "        Sij = Sij*delta[:,None,None]/delU\n",
    "        omega = omega*delta[:,None,None]/delU\n",
    "        eps = eps*delta/delU**3\n",
    "        K = K/delU**2\n",
    "        Lij = Lij*delU**2\n",
    "        t_time = t_time*delU/delta\n",
    "  \n",
    "    #basis_vect = get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij,eps,K,Lij,x,t_time,mvgg)\n",
    "    #basis_vect = np.moveaxis(basis_vect,0,-2)\n",
    "    #Gij = np.moveaxis(Gij,0,-1)\n",
    "    #Tij = np.moveaxis(Tij,0,-1)\n",
    "    #Lij = np.moveaxis(Lij,0,-1)\n",
    "    #b = np.moveaxis(b,0,-1)\n",
    "    #meanVelGrad = np.moveaxis(meanVelGrad,0,-1)\n",
    "    #Sij = np.moveaxis(Sij,0,-1)\n",
    "    #omega = np.moveaxis(omega,0,-1)\n",
    "        \n",
    "    return Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K, Reyn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training(direc,ist,nt,stp, delU,nfs,i1,j1):\n",
    "            Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K, Reyn = get_training_data_time(direc,ist,False,False,delU)\n",
    "            print(Gij.shape, Tij.shape)\n",
    "            for i in range(ist+stp,ist+nt,stp):\n",
    "                Gij1, Tij1, meanVelGrad1, b1, Sij1, omega1, Lij1, eps1, K1, Reyn1 = get_training_data_time(direc,i,False,False,delU)\n",
    "                Gij = np.append(Gij,Gij1,axis=0)\n",
    "                Tij = np.append(Tij,Tij1,axis=0)\n",
    "                meanVelGrad = np.append(meanVelGrad,meanVelGrad1,axis=0)\n",
    "                b = np.append(b,b1,axis=0)\n",
    "                Sij = np.append(Sij,Sij1,axis=0)\n",
    "                omega = np.append(omega,omega1,axis=0)\n",
    "                Lij = np.append(Lij,Lij1,axis=0)\n",
    "                eps = np.append(eps,eps1,axis=0)\n",
    "                K = np.append(K,K1,axis=0)\n",
    "                Reyn = np.append(Reyn,Reyn1,axis=0)\n",
    "                \n",
    "           \n",
    "            return Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K , Reyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train,X_test, X_val, Y_train, Y_test, Y_val, which):\n",
    "    \n",
    "    if(which == 'std'):\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_val = sc.transform(X_val)\n",
    "        Y_train = sc.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = sc.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = sc.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'std2'):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_val = sc.transform(X_val)\n",
    "        Y_train = sc.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = sc.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = sc.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'mean'):\n",
    "        meanX   = np.mean(X_train,axis=0)\n",
    "        stdX    = np.std(X_train,axis=0)\n",
    "    \n",
    "        meanY   = np.mean(Y_train)\n",
    "        stdY    = np.std(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train)/meanY\n",
    "        Y_test = (Y_test)/meanY\n",
    "        Y_val   = (Y_val)/meanY\n",
    "        \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/meanX[i]\n",
    "            X_test[:,i] = (X_test[:,i])/meanX[i]\n",
    "            X_val[:,i] = (X_val[:,i])/meanX[i]\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    \n",
    "    if(which=='minmax'):\n",
    "        minX   = np.min(X_train,axis=(0))\n",
    "        maxX    = np.max(X_train,axis=(0))\n",
    "    \n",
    "        minY   = np.min(Y_train)\n",
    "        maxY    = np.max(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train-minY)/(maxY-minY)\n",
    "        Y_test = (Y_test-minY)/(maxY-minY)\n",
    "        Y_val   = (Y_val-minY)/(maxY-minY)\n",
    "        #Y_train = (Y_train)/(maxY-minY)\n",
    "        #Y_test = (Y_test)/(maxY-minY)\n",
    "        #Y_val   = (Y_val)/(maxY-minY)\n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            X_test[:,i] = (X_test[:,i]-minX[i])/(maxX[i]-minX[i])            \n",
    "            X_val[:,i] = (X_val[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='max'):\n",
    "        maxX    = np.max(np.abs(X_train),axis=(0))\n",
    "    \n",
    "        maxY    = np.max(np.abs(Y_train))\n",
    "    \n",
    "        Y_train = (Y_train)/(maxY)\n",
    "        Y_test = (Y_test)/(maxY)\n",
    "        Y_val   = (Y_val)/(maxY)\n",
    "        \n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/(maxX[i])\n",
    "            X_test[:,i] = (X_test[:,i])/(maxX[i])            \n",
    "            X_val[:,i] = (X_val[:,i])/(maxX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'yeo'):\n",
    "            pt = PowerTransformer(standardize=True)\n",
    "            X_train = pt.fit_transform(X_train)            \n",
    "            X_test  = pt.transform(X_test)\n",
    "            X_val   = pt.transform(X_val)\n",
    "            Y_train  = pt.fit_transform(Y_train.reshape(-1,1))            \n",
    "            Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "            Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "            return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'quant'):\n",
    "                pt = QuantileTransformer(output_distribution='normal')\n",
    "                X_train = pt.fit_transform(X_train)\n",
    "                X_test  = pt.transform(X_test)\n",
    "                X_val   = pt.transform(X_val)\n",
    "                Y_train = pt.fit_transform(Y_train.reshape(-1,1))\n",
    "                Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "                Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "                return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='log'):\n",
    "               X_train = do_log(X_train)    \n",
    "               X_test = do_log(X_test)    \n",
    "               X_val = do_log(X_val)\n",
    "               Y_train = do_log2(Y_train)\n",
    "               Y_test = do_log2(Y_test)\n",
    "               Y_val = do_log2(Y_val)\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='exp'):\n",
    "               X_train = X_train**0.3    \n",
    "               X_test = X_test**0.3    \n",
    "               X_val = X_val**0.3\n",
    "               Y_train = Y_train**0.3\n",
    "               Y_test = Y_test**0.3\n",
    "               Y_val = Y_val**0.3\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        X_train = RS.fit_transform(X_train)\n",
    "        X_test = RS.transform(X_test)\n",
    "        X_val = RS.transform(X_val)\n",
    "        Y_train = RS.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = RS.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = RS.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data_all(X, which):\n",
    "    \n",
    "    if(which == 'std'):\n",
    "        sc = StandardScaler()\n",
    "        for i in range(0,3):\n",
    "            for j in range(0,3):\n",
    "                X[:,i,j] = sc.fit_transform(X[:,i,j].reshape(-1,1))[:,0]\n",
    "                \n",
    "        return X\n",
    "    \n",
    "    if(which == 'std2'):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_val = sc.transform(X_val)\n",
    "        Y_train = sc.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = sc.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = sc.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'mean'):\n",
    "        meanX   = np.mean(X_train,axis=0)\n",
    "        stdX    = np.std(X_train,axis=0)\n",
    "    \n",
    "        meanY   = np.mean(Y_train)\n",
    "        stdY    = np.std(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train)/meanY\n",
    "        Y_test = (Y_test)/meanY\n",
    "        Y_val   = (Y_val)/meanY\n",
    "        \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/meanX[i]\n",
    "            X_test[:,i] = (X_test[:,i])/meanX[i]\n",
    "            X_val[:,i] = (X_val[:,i])/meanX[i]\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    \n",
    "    if(which=='minmax'):\n",
    "        minX   = np.min(X_train,axis=(0))\n",
    "        maxX    = np.max(X_train,axis=(0))\n",
    "    \n",
    "        minY   = np.min(Y_train)\n",
    "        maxY    = np.max(Y_train)\n",
    "    \n",
    "        Y_train = (Y_train-minY)/(maxY-minY)\n",
    "        Y_test = (Y_test-minY)/(maxY-minY)\n",
    "        Y_val   = (Y_val-minY)/(maxY-minY)\n",
    "        #Y_train = (Y_train)/(maxY-minY)\n",
    "        #Y_test = (Y_test)/(maxY-minY)\n",
    "        #Y_val   = (Y_val)/(maxY-minY)\n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            X_test[:,i] = (X_test[:,i]-minX[i])/(maxX[i]-minX[i])            \n",
    "            X_val[:,i] = (X_val[:,i]-minX[i])/(maxX[i]-minX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='max'):\n",
    "        maxX    = np.max(np.abs(X_train),axis=(0))\n",
    "    \n",
    "        maxY    = np.max(np.abs(Y_train))\n",
    "    \n",
    "        Y_train = (Y_train)/(maxY)\n",
    "        Y_test = (Y_test)/(maxY)\n",
    "        Y_val   = (Y_val)/(maxY)\n",
    "        \n",
    "    \n",
    "        for i in range(X_train.shape[1]):\n",
    "            X_train[:,i] = (X_train[:,i])/(maxX[i])\n",
    "            X_test[:,i] = (X_test[:,i])/(maxX[i])            \n",
    "            X_val[:,i] = (X_val[:,i])/(maxX[i])\n",
    "            \n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'yeo'):\n",
    "            pt = PowerTransformer(standardize=True)\n",
    "            X_train = pt.fit_transform(X_train)            \n",
    "            X_test  = pt.transform(X_test)\n",
    "            X_val   = pt.transform(X_val)\n",
    "            Y_train  = pt.fit_transform(Y_train.reshape(-1,1))            \n",
    "            Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "            Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "            return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which == 'quant'):\n",
    "                pt = QuantileTransformer(output_distribution='normal')\n",
    "                X_train = pt.fit_transform(X_train)\n",
    "                X_test  = pt.transform(X_test)\n",
    "                X_val   = pt.transform(X_val)\n",
    "                Y_train = pt.fit_transform(Y_train.reshape(-1,1))\n",
    "                Y_test  = pt.transform(Y_test.reshape(-1,1))\n",
    "                Y_val   = pt.transform(Y_val.reshape(-1,1))\n",
    "                return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    \n",
    "    if(which=='log'):\n",
    "               X_train = do_log(X_train)    \n",
    "               X_test = do_log(X_test)    \n",
    "               X_val = do_log(X_val)\n",
    "               Y_train = do_log2(Y_train)\n",
    "               Y_test = do_log2(Y_test)\n",
    "               Y_val = do_log2(Y_val)\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='exp'):\n",
    "               X_train = X_train**0.3    \n",
    "               X_test = X_test**0.3    \n",
    "               X_val = X_val**0.3\n",
    "               Y_train = Y_train**0.3\n",
    "               Y_test = Y_test**0.3\n",
    "               Y_val = Y_val**0.3\n",
    "               X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "\n",
    "               return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        X_train = RS.fit_transform(X_train)\n",
    "        X_test = RS.transform(X_test)\n",
    "        X_val = RS.transform(X_val)\n",
    "        Y_train = RS.fit_transform(Y_train.reshape(-1,1))\n",
    "        Y_test = RS.transform(Y_test.reshape(-1,1))\n",
    "        Y_val = RS.transform(Y_val.reshape(-1,1))\n",
    "        return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inverse_scaling(Y_sc, Y_un, which):\n",
    "    if(which=='std'):\n",
    "        meanY = np.mean(Y_un)\n",
    "        stdY = np.std(Y_un)\n",
    "        return Y_sc*stdY + meanY\n",
    "    if(which=='minmax'):\n",
    "        minY = np.min(Y_un)\n",
    "        maxY = np.max(Y_un)\n",
    "        return Y_sc*(maxY-minY)+minY\n",
    "    if(which=='max'):\n",
    "        maxY = np.max(np.abs(Y_un))\n",
    "        return Y_sc*maxY\n",
    "    \n",
    "    if(which=='median'):\n",
    "        RS = RobustScaler()\n",
    "        RS.fit(Y_un.reshape(-1,1))\n",
    "        return RS.inverse_transform(Y_sc.reshape(-1,1))\n",
    "    if(which == 'yeo'):\n",
    "        pt = PowerTransformer(standardize=True)\n",
    "        Y_train  = pt.fit(Y_un.reshape(-1,1))            \n",
    "        return pt.inverse_transform(Y_sc.reshape(-1,1))\n",
    "    return Y_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts=576\n",
    "np.random.seed(10)\n",
    "nT = [i for i in range(0,100)]\n",
    "np.random.shuffle(nT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i1,j1,nfs):\n",
    "    #nfs = 19\n",
    "    #X, Y, _ = get_training('./data/CaseF_scaled/',0,100,2,80,nfs,i1,j1)\n",
    "    #X1, Y1, _ = get_training('./data/CaseC_scaled/',50,150,3,60,nfs,i1,j1)\n",
    "    X, Y, _ = get_training('./data/new_data/40_scaled/',0,50,1,80,nfs,i1,j1)\n",
    "    X1, Y1, _ = get_training('./data/new_data/60_scaled/',0,50,1,60,nfs,i1,j1)\n",
    "    \n",
    "    \n",
    "    #X, Y, _ = get_CNN_training('./data/50_new_scaled/',0,100,2,100,nfs,i1,j1)\n",
    "    \n",
    "    X = np.append(X,X1,axis=0)\n",
    "    Y = np.append(Y,Y1,axis=0)\n",
    "    #nfs=19\n",
    "    npts=576\n",
    "    X_train = np.zeros((npts*80,nfs))\n",
    "    Y_train = np.zeros((npts*80,1))\n",
    "\n",
    "    X_val = np.zeros((npts*20,nfs))\n",
    "    Y_val = np.zeros((npts*20,1))\n",
    "\n",
    "    for i in range(0,80):\n",
    "        X_train[i*npts:(i+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_train[i*npts:(i+1)*npts] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "    j=0\n",
    "    for i in range(80,100):\n",
    "        X_val[j*npts:(j+1)*npts,:] = X[nT[i]*npts:(nT[i]+1)*npts,:]\n",
    "        Y_val[j*npts:(j+1)*npts] = Y[nT[i]*npts:(nT[i]+1)*npts,None]\n",
    "        j=j+1\n",
    "        \n",
    "    #nfs=19\n",
    "    minY = np.min(Y_train)\n",
    "    maxY = np.max(Y_train)\n",
    "    stdY = np.std(Y_train)\n",
    "    meanY = np.mean(Y_train)\n",
    "    Y_un = np.copy(Y_train)\n",
    "\n",
    "    X_test, Y_test, _ = get_training('./data/new_data/75_scaled/',0,60,6,100,nfs,i1,j1)\n",
    "    #X_test, Y_test, _ = get_CNN_training('./data/CaseE_scaled/',0,80,2,150,nfs,i1,j1)\n",
    "    #X_test, Y_test, _ = get_CNN_training('./data/CaseE_scaled/',0,60,3,150,nfs,i1,j1)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = scale_data(X_train, X_test,  X_val, Y_train, Y_test,  Y_val,'std')\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val, Y_un\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 3, 3) (576, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K , Reyn = get_training('./data/60_scaled/',0,50,50,60,23,0,0)\n",
    "#Gij2, Tij2, meanVelGrad2, b2, Sij2, omega2, Lij2, eps2, K2 , Reyn2 = get_training('./data/new_data/60_scaled/',0,50,10,60,23,0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = eps[:,None,None]\n",
    "K = K[:,None,None]\n",
    "Reyn = Reyn[:,None,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gij = scale_data_all(Gij,'std')\n",
    "Lij = scale_data_all(Lij,'std')\n",
    "b = scale_data_all(b,'std')\n",
    "meanVelGrad = scale_data_all(meanVelGrad,'std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protected_div(x1, x2):\n",
    "    if abs(x2) < 1e-6:\n",
    "        return 1\n",
    "    return x1 / x2\n",
    "\n",
    "def protected_exp(x1):\n",
    "    if abs(x1) > 2:\n",
    "        return 1\n",
    "    return np.exp(x1)\n",
    "def protected_log(x1):\n",
    "    if x1 <= 1:\n",
    "        return 1\n",
    "    return np.log(x1)\n",
    "exp = np.vectorize(protected_exp)\n",
    "log = np.vectorize(protected_log)\n",
    "def mult_three(*args):    \n",
    "    out=1\n",
    "    for i in range(len(args)):\n",
    "        out = out*args[i]      \n",
    "    return out\n",
    "\n",
    "def add_three(*args):    \n",
    "    out=0\n",
    "    for i in range(len(args)):\n",
    "        out = out+args[i]      \n",
    "    return out\n",
    "\n",
    "def matmul(x1,x2):    \n",
    "    if(np.isscalar(x1) or np.isscalar(x2)):\n",
    "        return x2*x2\n",
    "    if(x1.shape[1]==1 or x2.shape[1]==1):\n",
    "        return x1*x2\n",
    "    \n",
    "    \n",
    "    return np.matmul(x1,x2)\n",
    "\n",
    "def transpose(x1):\n",
    "    \n",
    "    if(np.isscalar(x1)):\n",
    "        return x1\n",
    "        \n",
    "    return np.transpose(x1)\n",
    "    \n",
    "\n",
    "def trace(x1):\n",
    "    \n",
    "    if(np.isscalar(x1)):\n",
    "        return x1\n",
    "    return np.trace(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = gep.PrimitiveSet('main', input_names=['B1','B2','B3'])\n",
    "#pset.add_function(operator.add, 2)\n",
    "#pset.add_function(operator.sub, 2)\n",
    "pset.add_function(matmul, 2)\n",
    "pset.add_function(transpose,1)\n",
    "\n",
    "pset.add_rnc_terminal()\n",
    "#pset.add_plasmid_terminal()\n",
    "\n",
    "pset2 = gep.PrimitiveSet('main2', input_names=['T1','T2','T3','eps','K','Reyn'])\n",
    "pset2.add_rnc_terminal()\n",
    "pset2.add_function(matmul, 2)\n",
    "pset2.add_function(transpose, 1)\n",
    "pset2.add_function(trace, 1)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1,))\n",
    "creator.create('Individual', gep.Chromosome, fitness=creator.FitnessMin)\n",
    "\n",
    "h = 8 # head length\n",
    "n_genes = 6\n",
    "toolbox = gep.Toolbox()\n",
    "r=8\n",
    "toolbox.register('rnc_gen', random.uniform, a=-10, b=10)   # each RNC is random integer within [-5, 5]\n",
    "toolbox.register('gene_gen', gep.GenePlasmid, pset=pset, head_length=h,rnc_gen=toolbox.rnc_gen, rnc_array_length=r,pset_plasmid=pset2,head_plasmid=5,n_plasmid=1)\n",
    "#toolbox.register('gene_gen', gep.GeneDc, pset=pset, head_length=h,rnc_gen=toolbox.rnc_gen, rnc_array_length=r)\n",
    "#toolbox.register('plasmid',  gep.Gene, pset=pset, head_length=h)\n",
    "toolbox.register('individual', creator.Individual, gene_gen=toolbox.gene_gen, n_genes=n_genes, linker=add_three)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile utility: which translates an individual into an executable function (Lambda)\n",
    "toolbox.register('compile', gep.compile_plasmids, pset=pset, pset_plasmid=pset2)\n",
    "#toolbox.register('compile', gep.compile_, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual):\n",
    "    \"\"\"Evalute the fitness of an individual: MSE (mean squared error)\"\"\"\n",
    "    func = toolbox.compile(individual)    \n",
    "    Yp = np.array(list(map(func, Tij,meanVelGrad)))     \n",
    "    #print(Yp.shape)\n",
    "    if(Yp.shape!=Gij.shape):\n",
    "        return (1e4,) # Some high value\n",
    "    return abs(np.mean((Gij - Yp) ** 2)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = toolbox.compile(pop[0])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual):\n",
    "    \"\"\"Evalute the fitness of an individual: MSE (mean squared error)\"\"\"\n",
    "    func = toolbox.compile(individual)    \n",
    "    \n",
    "    Yp = np.array(list(map(func, b,meanVelGrad,Lij,b,meanVelGrad,Lij,eps,K,Reyn)))  \n",
    "    #print(Yp.shape)\n",
    "    if(Yp.ndim==1):\n",
    "        Yp = Yp[:,None,None]\n",
    "    return np.mean((Gij - Yp)**2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yp = np.array(list(map(func, b,meanVelGrad,Lij,b,meanVelGrad,Lij)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((Gij - Yp)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxs = np.max(abs(Gij),2)\n",
    "def evaluate_test(individual):\n",
    "    \"\"\"Evalute the fitness of an individual: MSE (mean squared error)\"\"\"\n",
    "    func = toolbox.compile(individual)    \n",
    "    Yp = func(B1,B2,B3,B4,B5,B6,I,T1,T2,T3,T4,T5,T6,I2,detT)\n",
    "    #Yp = func(B1,B2,B3,I,T1,T2,T3)\n",
    "    #Yp = np.array(list(map(func, B1,B2,B3,T1,T2,T3)))     \n",
    "    #print(Yp.shape)\n",
    "    #return np.mean(abs(Gij - Yp)), \n",
    "    #try:\n",
    "    #    pr = Yp[1,1,:]\n",
    "    #except:\n",
    "    #    pr = Yp\n",
    "    pr = Yp*eps[None,None,:]/K[None,None,:]       \n",
    "    \n",
    "    return np.mean((Gij*eps[None,None,:]/K[None,None,:] - pr)**2),  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual):\n",
    "    \"\"\"Evalute the fitness of an individual: MSE (mean squared error)\"\"\"\n",
    "    func = toolbox.compile(individual)    \n",
    "    Yp = np.array(list(map(func, b[:,0]/K,H1[:,0]*tau,\n",
    "                                 H2[:,0]*tau,H3[:,0]*tau,H4[:,0]*tau,\n",
    "                                 H5[:,0]*tau,H6[:,0]*tau,H7[:,0]*tau,\n",
    "                                 H8[:,0]*tau,H9[:,0]*tau)))     \n",
    "    #print(Yp.shape)\n",
    "    #if(Yp.shape!=Gij.shape):\n",
    "    #    return (1e4,) # Some high value\n",
    "    return abs(np.mean((Gij[:,0]*tau - Yp) ** 2)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_linear_scaling(individual):\n",
    "    \"\"\"Evaluate the fitness of an individual with linearly scaled MSE.\n",
    "    Get a and b by minimizing (a*Yp + b - Y)\"\"\"\n",
    "    func = toolbox.compile(individual)\n",
    "    Yp = np.array(list(map(func, b[:,0]/K,H1[:,0]*tau,\n",
    "                                 H2[:,0]*tau,H3[:,0]*tau,H4[:,0]*tau,\n",
    "                                 H5[:,0]*tau,H6[:,0]*tau,H7[:,0]*tau,\n",
    "                                 H8[:,0]*tau,H9[:,0]*tau)))     \n",
    "    Vreal = Gij[:,0]*tau\n",
    "    \n",
    "    if isinstance(Yp, np.ndarray):\n",
    "        Q = np.hstack((np.reshape(Yp, (-1, 1)), np.ones((len(Yp), 1))))\n",
    "        (individual.a, individual.b), residuals, _, _ = np.linalg.lstsq(Q, Vreal, rcond=None)   \n",
    "        # residuals is the sum of squared errors\n",
    "        if residuals.size > 0:\n",
    "            #return residuals[0] / len(Vreal),   # MSE\n",
    "            return np.log(1+residuals[0] / len(Vreal)),   # MSE\n",
    "    \n",
    "    # for the above special cases, the optimal linear scaling is just the mean of true target values\n",
    "    individual.a = 0\n",
    "    individual.b = np.mean(Vreal)\n",
    "    #return np.mean((Vreal - individual.b) ** 2),\n",
    "    return np.log(1+np.mean((Vreal - individual.b) ** 2)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_linear_scaling_tensor(individual):\n",
    "    \"\"\"Evaluate the fitness of an individual with linearly scaled MSE.\n",
    "    Get a and b by minimizing (a*Yp + b - Y)\"\"\"\n",
    "    func = toolbox.compile(individual)\n",
    "    predict = np.array(list(map(func, b,meanVelGrad,Lij,b,meanVelGrad,Lij,eps,K,Reyn)))  \n",
    "\n",
    "    #print(predict.shape)\n",
    "    #Vreal = out\n",
    "    resid = 0\n",
    "    slp = np.zeros((3,3))\n",
    "    intp = np.zeros((3,3))\n",
    "    for i in range(0,3):\n",
    "        for j in range(0,3):            \n",
    "                #print(predict.ndim,i,j)\n",
    "                try:         \n",
    "                    Yp = predict[:,i,j]\n",
    "                except:\n",
    "                    #print(predict.ndim,i,j,predict.shape)\n",
    "                    Yp = predict[:,None]\n",
    "                Q = np.hstack((np.reshape(Yp, (-1, 1)), np.ones((len(Yp), 1))))\n",
    "                (slp[i,j], intp[i,j]), residuals, _, _ = np.linalg.lstsq(Q, Gij[:,i,j], rcond=None)   \n",
    "                individual.a = slp\n",
    "                individual.b = intp\n",
    "                \n",
    "                pr = Yp*slp[i,j]+intp[i,j]\n",
    "                resid = resid + np.mean((abs(Gij[:,i,j]-pr)))\n",
    "    \n",
    "        \n",
    "    return resid,\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Gij[0,0,:]*eps/K\n",
    "def evaluate_linear_scaling(individual):\n",
    "    \"\"\"Evaluate the fitness of an individual with linearly scaled MSE.\n",
    "    Get a and b by minimizing (a*Yp + b - Y)\"\"\"\n",
    "    func = toolbox.compile(individual)\n",
    "    Yp = np.array(list(map(func, S1,S2,S3,S4,S5,S6,S7,S8,\n",
    "                            T1,T2,T3,T4,T5,T6,T7,T8)))     \n",
    "    Vreal = out\n",
    "    Yp = Yp*eps/K\n",
    "    \n",
    "    if isinstance(Yp, np.ndarray):\n",
    "        Q = np.hstack((np.reshape(Yp, (-1, 1)), np.ones((len(Yp), 1))))\n",
    "        (individual.a, individual.b), residuals, _, _ = np.linalg.lstsq(Q, Vreal, rcond=None)   \n",
    "        # residuals is the sum of squared errors\n",
    "        if residuals.size > 0:\n",
    "            return residuals[0] / len(Vreal),   # MSE\n",
    "    \n",
    "    # for the above special cases, the optimal linear scaling is just the mean of true target values\n",
    "    individual.a = 0\n",
    "    individual.b = np.mean(Vreal)\n",
    "    return np.mean((Vreal - individual.b) ** 2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'toolbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d84d1d86e282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#toolbox.register('evaluate', evaluate_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselTournament\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'toolbox' is not defined"
     ]
    }
   ],
   "source": [
    "toolbox.register('evaluate', evaluate)\n",
    "#toolbox.register('evaluate', evaluate_test)\n",
    "toolbox.register('select', tools.selTournament, tournsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. general operators\n",
    "toolbox.register('mut_uniform', gep.mutate_uniform, pset=pset, ind_pb=0.1,pb=0.8)\n",
    "toolbox.register('mut_invert', gep.invert, pb=0.1)\n",
    "toolbox.register('mut_is_transpose', gep.is_transpose, pb=0.1)\n",
    "toolbox.register('mut_ris_transpose', gep.ris_transpose, pb=0.1)\n",
    "#toolbox.register('mut_gene_transpose', gep.gene_transpose, pb=0.1)\n",
    "toolbox.register('cx_1p', gep.crossover_one_point, pb=0.1)\n",
    "#toolbox.register('cx_2p', gep.crossover_two_point, pb=0.3)\n",
    "#toolbox.register('cx_gene', gep.crossover_gene, pb=0.1)\n",
    "\n",
    "# 2. Dc-specific operators\n",
    "toolbox.register('mut_dc', gep.mutate_uniform_dc, ind_pb=0.1, pb=0.5)\n",
    "toolbox.register('mut_invert_dc', gep.invert_dc, pb=0.1)\n",
    "\n",
    "# This doesn't work with plasmid right now\n",
    "#toolbox.register('mut_transpose_dc', gep.transpose_dc, pb=0.1)\n",
    "\n",
    "# for some uniform mutations, we can also assign the ind_pb a string to indicate our expected number of point mutations in an individual\n",
    "toolbox.register('mut_rnc_array_dc', gep.mutate_rnc_array_dc, rnc_gen=toolbox.rnc_gen, ind_pb='0.1p')\n",
    "toolbox.pbs['mut_rnc_array_dc'] = 0.5  # we can also give the probability via the pbs property\n",
    "\n",
    "#Plasmid mutation\n",
    "toolbox.register('mut_unif_plasmid', gep.mutate_uniform_plasmid, pset_plasmid=pset2, ind_pb=0.6,pb=0.5)\n",
    "toolbox.register('mut_move_plasmid', gep.mutate_move_plasmid, ind_pb=0.2,pb=0.2)\n",
    "toolbox.register('mut_rnc_array_plasmid', gep.mutate_rnc_array_plasmid,  rnc_gen=toolbox.rnc_gen,ind_pb=0.4,pb=0.5)\n",
    "#toolbox.register('cx_plasmid', gep.crossover_one_point_plasmid, pb=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# size of population and number of generations\n",
    "bests = []\n",
    "loss = []\n",
    "n_pop = 200\n",
    "n_gen = 100\n",
    "champs = 3\n",
    "for i in range(0,1):\n",
    "    pop = toolbox.population(n=n_pop) # \n",
    "    hof = tools.HallOfFame(champs)   # only record the best three individuals ever found in all generations\n",
    "    pop, log = gep.gep_simple(pop, toolbox, n_generations=n_gen, n_elites=1,\n",
    "                           stats=stats,hall_of_fame=hof, verbose=True)\n",
    "    bests.append(hof[0])\n",
    "    loss.append(log[n_gen-1]['min'])\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop, log = gep.gep_simple(pop, toolbox, n_generations=n_gen, n_elites=1,\n",
    "                           stats=stats,hall_of_fame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs  = np.zeros(n_gen)\n",
    "best  = np.zeros(n_gen)\n",
    "for i in range(0,n_gen):\n",
    "    avgs[i] = log[i]['avg']\n",
    "    best[i] = log[i]['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(avgs)\n",
    "#plt.plot(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYMBOLIC_FUNCTION_MAP = {\n",
    "    operator.and_.__name__: sp.And,\n",
    "    operator.or_.__name__: sp.Or,\n",
    "    operator.not_.__name__: sp.Not,\n",
    "    operator.add.__name__: operator.add,\n",
    "    operator.sub.__name__: operator.sub,\n",
    "    operator.mul.__name__: operator.mul,\n",
    "    operator.neg.__name__: operator.neg,\n",
    "    operator.floordiv.__name__: operator.floordiv,\n",
    "    operator.truediv.__name__: operator.truediv,\n",
    "    'protected_div': operator.truediv,\n",
    "    'protected_exp': sp.functions.elementary.exponential.exp,\n",
    "    'protected_log': sp.functions.elementary.exponential.log,\n",
    "    'protected_log': sp.functions.elementary.exponential.log,\n",
    "    'trace' : sp.expressions.Trace,\n",
    "    'transpose' : sp.expressions.Transpose,\n",
    "    'matmul' : sp.expressions.MatMul,\n",
    "    \n",
    "    \n",
    "    #math.log.__name__: sp.log\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    ind = hof[i]\n",
    "    func = gep.simplify(ind)    \n",
    "    func = ind.a * func + ind.b\n",
    "    print('Symplified best individual {}: '.format(i))\n",
    "    print(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gep.compile_plasmids(hof[0],pset,pset2)\n",
    "#f = gep.compile_(hof[0],pset)\n",
    "#pred = f(B1,B2,B3,B4,B5,B6,B7,B8,B9,B10,I,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10)\n",
    "predict = np.array(list(map(f, b,meanVelGrad,Lij,b,meanVelGrad,Lij,eps,K,Reyn)))  \n",
    "\n",
    "#pred = f(b,meanVelGrad,Lij,b,meanVelGrad,Lij)\n",
    "#pred = f(B1,B2,B3,B4,I)\n",
    "#pred = f(S1,S2,S3,S4,S5,S6,T1,T2,T3,T4,T5,T6)\n",
    "#pred = f(S1,S2,S3,S4,S5,S6,S7,S8,T1,T2,T3,T4,T5,T6,T7,T8)\n",
    "#pred = f(b[:,0]/K,H1[:,0]*tau,H2[:,0]*tau,H3[:,0]*tau,H4[:,0]*tau,H5[:,0]*tau,H6[:,0]*tau,H7[:,0]*tau,H8[:,0]*tau,H9[:,0]*tau)\n",
    "#red = f(S1,S2,S3,S4,T1,T2,T3,T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gep.simplify(hof[0],DEFAULT_SYMBOLIC_FUNCTION_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.trace(Lij,axis1=1,axis2=2)[:,None,None]*(3.0*np.matmul(b,meanVelGrad)) + np.trace(Lij,axis1=1,axis2=2)[:,None,None]*(meanVelGrad-Lij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i1=0\n",
    "j1=0\n",
    "#plt.plot(predict[0:576,i1,j1]*hof[0].a[i1,j1]+hof[0].b[i1,j1])\n",
    "plt.plot(predict[0:576,i1,j1])\n",
    "\n",
    "#plt.plot(test[0:576,0,0]*hof[0].a[0,0]+hof[0].b[0,0])\n",
    "\n",
    "plt.plot(Gij[0:576,i1,j1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gij, Tij, meanVelGrad, b, Sij, omega, Lij, eps, K, basis_vect, loindices = get_training_data('../GLM/100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gij2, Tij2, meanVelGrad2, b2, Sij2, omega2, Lij2, eps2, K2, basis_vect2, loindices2 = get_training_data('../GLM/50/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loindices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(reg, open('lin_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.trace(Gij,axis1=0,axis2=1)*eps/K)\n",
    "#plt.plot(meanVelGrad2[:,0,0]+meanVelGrad2[:,1,1]+meanVelGrad2[:,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_vect=get_basis_vect(b,Sij,omega,meanVelGrad,Reyn,Tij)\n",
    "basis_vect2=get_basis_vect(b2,Sij2,omega2,meanVelGrad2,Reyn2,Tij2)\n",
    "\n",
    "basis_vect = np.moveaxis(basis_vect,0,-2)\n",
    "Gij = np.moveaxis(Gij,0,-1)\n",
    "Tij = np.moveaxis(Tij,0,-1)\n",
    "Lij = np.moveaxis(Lij,0,-1)\n",
    "b = np.moveaxis(b,0,-1)\n",
    "meanVelGrad = np.moveaxis(meanVelGrad,0,-1)\n",
    "\n",
    "\n",
    "basis_vect2 = np.moveaxis(basis_vect2,0,-2)\n",
    "Gij2 = np.moveaxis(Gij2,0,-1)\n",
    "Tij2 = np.moveaxis(Tij2,0,-1)\n",
    "Lij2 = np.moveaxis(Lij2,0,-1)\n",
    "b2 = np.moveaxis(b2,0,-1)\n",
    "meanVelGrad2 = np.moveaxis(meanVelGrad2,0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loindices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = pickle.load(open('lin_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.copy(basis_vect2[:,:,:,0:nfs])\n",
    "Y2 = np.copy(Gij2)\n",
    "data2 = np.reshape(X2,[3*3*K2.shape[0],nfs])    \n",
    "targ2 = np.reshape(Y2,[3*3*K2.shape[0]])\n",
    "score = np.zeros(len(loindices2)-2)\n",
    "for i in range(0,len(loindices2)-2):\n",
    "    pred = reg.predict(data2[loindices2[i]:loindices2[i+1],:])\n",
    "    score[i] = r2_score(targ2[loindices2[i]:loindices2[i+1]],pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(data2)\n",
    "pred = np.reshape(pred,[3,3,K2.shape[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(targ2[loindices2[0]:loindices[1]],pred[loindices2[0]:loindices[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot(score,'-o')\n",
    "plt.plot(pred[0,0,:])\n",
    "plt.plot(Gij2[0,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nfs=18\n",
    "X = np.copy(basis_vect[:,:,:,0:nfs])\n",
    "Y = np.copy(Gij)\n",
    "data = np.reshape(X,[3*3*K.shape[0],nfs])    \n",
    "targ = np.reshape(Y,[3*3*K.shape[0]])\n",
    "\n",
    "#weights = np.ones((3,3,Y.shape[2]))*eps[None,None,:]/K[None,None,:]\n",
    "#weights = np.reshape(weights,[3*3*K.shape[0]])\n",
    "    \n",
    "#weights2 = np.ones((3,3,Y2.shape[2]))*eps2[None,None,:]/K2[None,None,:]\n",
    "#weights2 = np.reshape(weights2,[3*3*K2.shape[0]])\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test  =  train_test_split(data,targ,test_size=0.2,random_state=1)\n",
    "\n",
    "mses = np.zeros(40)\n",
    "for nfs in range(39,40):\n",
    "    print(nfs)\n",
    "    slope = np.zeros((3,3,nfs))\n",
    "    intercept = np.zeros((3,3,nfs))       \n",
    "\n",
    "      \n",
    "    \n",
    "    #reg = LR(normalize=False,fit_intercept=True).fit(data,targ,sample_weight=weights)\n",
    "    #reg = RandomForestRegressor(n_estimators=100,max_depth=10,max_features=0.8).fit(data,targ)\n",
    "    #reg = SVR(kernel='linear').fit(data,targ,sample_weight=weights)\n",
    "    \n",
    "    #reg = Lasso(alpha=0.001,max_iter=1e6,fit_intercept=True,random_state=10).fit(data,targ)\n",
    "    #reg = LassoCV(eps=1e-2,fit_intercept=True,cv=8,random_state=10).fit(data,targ)\n",
    "\n",
    "    #reg = RidgeCV(alphas=(0.5,0.01,0.001,0.0001,0.00005),cv=5).fit(data,targ,sample_weight=weights)\n",
    "    #data_dmatrix = xgb.DMatrix(data=data,label=targ)\n",
    "    reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "    reg.fit(X_train,Y_train)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #mse_t=mean_squared_error(targ,reg.predict(data))\n",
    "    #mse_v=mean_squared_error(targ2,reg.predict(data2))\n",
    "    #mses[nfs]=mse_t\n",
    "    predict = reg.predict(X_test)\n",
    "    sc = reg.score(X_test,Y_test)\n",
    "    sc2 = reg.score(X_train,Y_train)\n",
    "\n",
    "    #predict = np.reshape(predict,[3,3,int(Y_test.shape[0]/9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(Y_test,predict,marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.reshape(predict,[K2.shape[0],3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Y2[0,0,:]*eps2/K2)\n",
    "plt.plot(predict[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps =[0]\n",
    "for i in range(1,22):\n",
    "    imps.append(mses[i-1]-mses[i])\n",
    "imps[1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in imps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(range(0,17),imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nfs=18\n",
    "mses = np.zeros(37)\n",
    "for nfs in range(1,37):\n",
    "    print(nfs)\n",
    "    slope = np.zeros((3,3,nfs))\n",
    "    intercept = np.zeros((3,3,nfs))       \n",
    "\n",
    "      \n",
    "    X = np.zeros((3,K.shape[0],nfs))\n",
    "    X2 = np.zeros((3,K2.shape[0],nfs))\n",
    "    Y = np.zeros((3,K.shape[0]))\n",
    "    Y2 = np.zeros((3,K2.shape[0]))\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        X[i,:,:] = basis_vect[i,i,:,0:nfs]\n",
    "        X2[i,:,:] = basis_vect2[i,i,:,0:nfs]\n",
    "        Y[i,:] = Gij[i,i,:]\n",
    "        Y2[i,:] = Gij2[i,i,:]\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    #X = np.copy(basis_vect[0:+1,0:2,:,0:nfs])\n",
    "    #Y = np.copy(Gij[0:1,0:2,:])\n",
    "    #X2 = np.copy(basis_vect2[0:1,0:2,:,0:nfs])\n",
    "    #Y2 = np.copy(Gij2[0:1,0:2,:])\n",
    "    \n",
    "    \n",
    "\n",
    "    data = np.reshape(X,[3*K.shape[0],nfs])\n",
    "    data2 = np.reshape(X2,[3*K2.shape[0],nfs])\n",
    "    \n",
    "    targ = np.reshape(Y,[3*K.shape[0]])\n",
    "    targ2 = np.reshape(Y2,[3*K2.shape[0]])\n",
    "\n",
    "    weights = np.ones((1,3,K.shape[0]))*eps[None,None,:]/K[None,None,:]\n",
    "    weights = np.reshape(weights,[3*K.shape[0]])\n",
    "    \n",
    "    weights2 = np.ones((1,3,K2.shape[0]))*eps2[None,None,:]/K2[None,None,:]\n",
    "    weights2 = np.reshape(weights2,[3*K2.shape[0]])\n",
    "     \n",
    "    #reg = LR(normalize=False,fit_intercept=True).fit(data,targ,sample_weight=weights)\n",
    "    \n",
    "    #reg = Lasso(alpha=0.0001,max_iter=1e6,fit_intercept=True,random_state=10).fit(data,targ)\n",
    "    #reg = LassoCV(eps=1e-4,max_iter=1e6,fit_intercept=True,cv=8,random_state=10).fit(data,targ)\n",
    "\n",
    "    reg = RidgeCV(alphas=(0.01,0.001,0.0001,0.00005,0.00001,1e-6,5e-6,1e-7),cv=5).fit(data,targ,sample_weight=weights)\n",
    "\n",
    "    mse_t=mean_squared_error(targ,reg.predict(data))\n",
    "    mse_v=mean_squared_error(targ2,reg.predict(data2))\n",
    "    mses[nfs-1]=mse_t\n",
    "    predict = reg.predict(data2)\n",
    "    sc = reg.score(data2,targ2,sample_weight=weights2)\n",
    "    predict = np.reshape(predict,[1,3,K2.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps =[0]\n",
    "for i in range(1,34):\n",
    "    imps.append(mses[i-1]-mses[i])\n",
    "#imps[1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Gij2[2,2,:])\n",
    "plt.plot(predict[0,2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = 10\n",
    "slope = np.zeros((3,3,nfs))\n",
    "predict = np.zeros((3,3,K2.shape[0]))\n",
    "sc = np.zeros((3,3))\n",
    "mse_t=0\n",
    "mse_v=0\n",
    "\n",
    "#X = basis_vect[:,:,:,0:nfs]*eps[None,None,:,None]/K[None,None,:,None]\n",
    "#Y = Gij*eps[None,None,:]/K[None,None,:]\n",
    "\n",
    "X = np.copy(basis_vect[:,:,:,0:nfs])\n",
    "Y = np.copy(Gij)\n",
    "\n",
    "#X2 = basis_vect2[:,:,:,0:nfs]*eps2[None,None,:,None]/K2[None,None,:,None]\n",
    "#Y2 = Gij2*eps2[None,None,:]/K2[None,None,:]\n",
    "\n",
    "X2 = np.copy(basis_vect2[:,:,:,0:nfs])\n",
    "Y2 = np.copy(Gij2)\n",
    "\n",
    "r2sc = np.zeros((3,3))\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        \n",
    "        \n",
    "        #reg = LR(fit_intercept=False).fit(X[i,j,:,0:nfs]*eps[:,None]/K[:,None],Y[i,j,:]*eps/K)\n",
    "        #reg = LassoCV(eps=1e-6,max_iter=1000000,cv=4).fit(basis_vect[i,j,:,0:nfs],Gij[i,j,:])\n",
    "        \n",
    "        #reg = RidgeCV(alphas=(0.1,0.01,0.001,0.0001,0.00005,0.00001,1e-6),cv=10).fit(X[i,j,:,0:nfs],Y[i,j,:])\n",
    "        slope[i,j,:]=reg.coef_\n",
    "\n",
    "        mse_t = mse_t + mean_squared_error(Y[i,j,:],reg.predict(X[i,j,:,0:nfs]))\n",
    "        \n",
    "        predict[i,j,:] = reg.predict(X2[i,j,:,0:nfs]*eps2[:,None]/K2[:,None])\n",
    "        r2sc[i,j] = r2_score(Y2[i,j,:]*eps2/K2,predict[i,j,:]*eps2/K2)\n",
    "        mse_v = mse_v + mean_squared_error(Y2[i,j,:],reg.predict(X2[i,j,:,0:nfs]))\n",
    "        sc[i,j] = reg.score(X2[i,j,:,0:nfs],Y2[i,j,:],sample_weight=eps2/K2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope[:,:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.reshape(Gij2,[3*3*K2.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.reshape(predict,[3*3*K2.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(t,p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        plt.subplot(3,3,i*3+j+1) \n",
    "        \n",
    "        #plt.plot(Gij2[i,j,:]*eps2/K2)        \n",
    "        #plt.plot(predict[i,j,:]*eps2/K2)\n",
    "        \n",
    "        #plt.plot(Gij[i,j,:]*eps/K)        \n",
    "        #plt.plot(predict[i,j,:]*eps/K)\n",
    "        \n",
    "        \n",
    "        #plt.scatter(Gij[i,j,:]*eps/K,predict[i,j,:]*eps/K,marker='.')\n",
    "        Y2 = np.reshape(Y_test,[3,3,int(Y_test.shape[0]/9)])\n",
    "        #plt.plot(Y2[i,j,:])\n",
    "        #plt.plot(predict[i,j,:])\n",
    "        \n",
    "        plt.scatter(Y2[i,j,:],predict[i,j,:],marker='.')        \n",
    "        #plt.plot(Gij[i,j,:]*eps/K)\n",
    "        #plt.plot(LIPM[i,j,:])\n",
    "        \n",
    "        plt.locator_params(axis='y', nbins=4)\n",
    "        plt.locator_params(axis='x', nbins=3)\n",
    "        plt.title(str(i+1)+','+str(j+1))\n",
    "        \n",
    "        plt.gca().get_yaxis().set_major_formatter(ticker.FormatStrFormatter('%0.0e'))\n",
    "        plt.gca().get_xaxis().set_major_formatter(ticker.FormatStrFormatter('%0.0e'))\n",
    "        plt.grid(alpha=0.2)\n",
    "        #if(i==0 and j==0):\n",
    "        #    plt.legend(('DNS','Model'))\n",
    "        plt.subplots_adjust(wspace=0.6)\n",
    "        plt.subplots_adjust(hspace=0.6)\n",
    "        #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        #plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        #x = np.linspace(min(Gij[i,j,:]*eps/K),max(Gij[i,j,:]*eps/K),10)        \n",
    "        \n",
    "        #plt.plot(x,x,'k--')\n",
    "#plt.savefig('Gij_linear_reg.png',dpi=300,bbox_inches = \"tight\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gijpred = predict*eps2[None,None,:]/K2[None,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIPM2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSM = np.zeros((3,3,K2.shape[0]))\n",
    "RSLIPM = np.zeros((3,3,K2.shape[0]))\n",
    "\n",
    "for i in range(0,K2.shape[0]):\n",
    "    RSM[:,:,i]  = np.matmul(Gijpred[:,:,i],Tij2[:,:,i]*K2[i]) + np.transpose(np.matmul(Gijpred[:,:,i],Tij2[:,:,i]*K2[i]))\n",
    "    RSLIPM[:,:,i]  = np.matmul(LIPM2[:,:,i],Tij2[:,:,i]*K2[i]) + np.transpose(np.matmul(LIPM2[:,:,i],Tij2[:,:,i]*K2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "loend=211\n",
    "hiend=365\n",
    "plt.plot(RSM[2,1,:])\n",
    "plt.plot(RSLIPM[2,1,:])\n",
    "plt.plot(ps[loend:hiend,7]-pt[loend:hiend,7]-epsij[loend:hiend,7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.loadtxt('../GLM/50/press_strain_219.dat')\n",
    "pt = np.loadtxt('../GLM/50/press_trans_219.dat')\n",
    "epsij = np.loadtxt('../GLM/50/epsij_219.dat')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIPM_model(C0,CIPM,alpha2,alpha3,beta1,beta2,beta3,gama5,gama6,b,Tij,meanVelGrad,eps,K,lambdaij):\n",
    "    pred = np.zeros((3,3,K.shape[0]))\n",
    "    for i in range(0,K.shape[0]):        \n",
    "        P = - 0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) + np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))\n",
    "        B3 = np.matmul(np.matmul(b[:,:,i],b[:,:,i]),b[:,:,i])\n",
    "        \n",
    "        alpha1 = -(0.5+3.0/4*C0)+3.0*alpha2*np.trace(B3)+0.5*CIPM*P #P is non dim so no omega here\n",
    "        \n",
    "        pred[:,:,i] = alpha1*np.eye(3,3)+alpha2*b[:,:,i] + alpha3*np.matmul(b[:,:,i],b[:,:,i]) + beta1*np.eye(3,3)*np.trace(meanVelGrad[:,:,i]) + \\\n",
    "        beta2*meanVelGrad[:,:,i] + beta3*np.transpose(meanVelGrad[:,:,i]) + gama5*np.matmul(b[:,:,i],meanVelGrad[:,:,i]) + \\\n",
    "        gama6*np.matmul(b[:,:,i],np.transpose(meanVelGrad[:,:,i]))\n",
    "        pred[:,:,i] = pred[:,:,i]*eps[i]/K[i]\n",
    "        pred[:,:,i] = pred[:,:,i]+0.5*C0*eps[i]/K[i]*lambdaij[:,:,i]\n",
    "    return pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lij.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIPM  = LIPM_model(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b,Tij,meanVelGrad,eps,K,Lij)\n",
    "LIPM2 = LIPM_model(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b2,Tij2,meanVelGrad2,eps2,K2,Lij2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_LIPM(C0,CIPM,alpha2,alpha3,beta1,beta2,beta3,gama5,gama6,b,Tij,meanVelGrad):\n",
    "        basis_vect = np.zeros((b.shape[2],3,3,10))\n",
    "        for i in range(0,b.shape[2]):\n",
    "            basis_vect[i,:,:,0]=np.eye(3,3)\n",
    "            basis_vect[i,:,:,1]=b[:,:,i]\n",
    "            basis_vect[i,:,:,2]=np.matmul(b[:,:,i],b[:,:,i])\n",
    "            basis_vect[i,:,:,3]=np.trace(meanVelGrad[:,:,i])*np.eye(3,3)        \n",
    "            basis_vect[i,:,:,4]=meanVelGrad[:,:,i]\n",
    "            basis_vect[i,:,:,5]=np.transpose(meanVelGrad[:,:,i])\n",
    "            basis_vect[i,:,:,6]=np.matmul(b[:,:,i],meanVelGrad[:,:,i])\n",
    "            basis_vect[i,:,:,7]=np.matmul(b[:,:,i],np.transpose(meanVelGrad[:,:,i]))\n",
    "            basis_vect[i,:,:,8]=np.trace(np.matmul(np.matmul(b[:,:,i],b[:,:,i]),b[:,:,i]))*np.eye(3,3)\n",
    "            basis_vect[i,:,:,9]=- 0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) +\\\n",
    "                                np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))*np.eye(3,3)\n",
    "        basis_vect = np.moveaxis(basis_vect,0,-2)\n",
    "        return basis_vect\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_LIPM = get_basis_LIPM(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b,Tij,meanVelGrad)\n",
    "basis_LIPM2 = get_basis_LIPM(2.1,0.6,3.5,-3*3.5,-0.2,0.8,-0.2,0.6,-0.6,b2,Tij2,meanVelGrad2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P= -0.5*np.trace(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i])) +\\\n",
    "                                np.transpose(np.matmul(Tij[:,:,i],np.transpose(meanVelGrad[:,:,i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
